# cuplyr

#### dplyr backend for GPU acceleration via RAPIDS cuDF

[![Open In
Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/bbtheo/cuplyr/blob/install/notebooks/install_cuplyr.ipynb)

cuplyr implements a dplyr backend powered by [RAPIDS
cuDF](https://github.com/rapidsai/cudf), NVIDIA’s GPU DataFrame library.
Write standard dplyr code, execute on GPU hardware.

``` r
library(cuplyr)

tbl_gpu(sales_data, lazy = TRUE) |>
  filter(year >= 2020, amount > 0) |>
  mutate(revenue = amount * price) |>
  group_by(region, quarter) |>
  summarise(total = sum(revenue)) |>
  inner_join(regions, by = "region") |>
  arrange(desc(total)) |>
  collect()
```

## About

cuplyr translates dplyr operations into cuDF execution on NVIDIA GPUs.
It follows the same backend pattern as dbplyr: write standard R code,
execute on GPU hardware. This approach can provide significant speedups
on larger datasets (typically \>1M rows) without requiring major code
changes.

**Built on [RAPIDS cuDF](https://rapids.ai/)**: cuDF is an open-source
GPU DataFrame library developed by NVIDIA’s RAPIDS team. It provides
optimized CUDA kernels for data manipulation operations, backed by
Apache Arrow’s columnar memory format. cuplyr provides an R interface to
this execution engine.

## Status

**v0.1.0**

This is experimental software under active development. Breaking changes
should be expected.

### Supported operations

**Data manipulation** -
[`filter()`](https://rdrr.io/r/stats/filter.html) – row filtering with
comparison and logical operators - `select()` – column selection and
reordering - `mutate()` – column transformations and arithmetic -
`arrange()` – row sorting with `desc()` support, NA handling follows
dplyr conventions - `group_by()` + `summarise()` – grouped aggregations
(`sum`, `mean`, `min`, `max`, `n`) - `left_join()`, `right_join()`,
`inner_join()`, `full_join()` – GPU joins on key columns - `collect()` –
transfer results back to R - `compute()` – execute lazy operations, keep
on GPU - `tbl_gpu(..., lazy = TRUE)` – enable lazy evaluation with AST
optimization

### Lazy evaluation

Lazy mode defers execution until `collect()` or `compute()`, enabling
automatic optimizations: - Projection pruning (drop unused columns
early) - Filter pushdown (move filters closer to data sources) - Mutate
fusion (combine consecutive transformations)

``` r
# Enable globally
options(cuplyr.exec_mode = "lazy")

# Or per-table
tbl_gpu(data, lazy = TRUE)
```

### Supported column types

| R Type           | GPU Type               |
|------------------|------------------------|
| numeric (double) | FLOAT64                |
| integer          | INT32                  |
| character        | STRING                 |
| logical          | BOOL8                  |
| Date             | TIMESTAMP_DAYS         |
| POSIXct          | TIMESTAMP_MICROSECONDS |
| factor           | INT32 (codes)          |

### Not yet implemented

- Complex joins with `join_by()`
- Window functions
- String operations
- Multi-GPU support

Contributions and feedback are welcome.

## Architecture

- **R layer**: S3 methods implementing dplyr generics
- **AST optimizer**: Projection pruning, filter pushdown, operation
  fusion
- **Native bindings**: Rcpp interface to libcudf C++ API
- **Execution**: cuDF GPU kernels via libcudf
- **Memory**: GPU-resident data with automatic cleanup via R garbage
  collection

## Installation

### Which path is right for me?

| I want to…                         | Do this                               |
|------------------------------------|---------------------------------------|
| **Try it out** (no local GPU)      | [Open in Colab](#try-on-google-colab) |
| **Use it** (I have an NVIDIA GPU)  | [Quick install](#quick-install)       |
| **Contribute** (modify C++/R code) | [Developer setup](#developer-setup)   |

### Requirements

| Component      | Version                             |
|----------------|-------------------------------------|
| NVIDIA GPU     | Compute Capability \>= 7.0 (Volta+) |
| CUDA Toolkit   | \>= 12.2                            |
| RAPIDS libcudf | \>= 25.12                           |
| R              | \>= 4.3                             |
| OS             | Linux x86_64 only                   |

### Try on Google Colab

The fastest way to try cuplyr — no local setup required:

[![Open In
Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/bbtheo/cuplyr/blob/install/notebooks/install_cuplyr.ipynb)

### Quick install

**Option A: One-liner** (auto-detects pixi, conda, or system CUDA)

``` bash
git clone https://github.com/bbtheo/cuplyr.git && cd cuplyr && ./install.sh
```

**Option B: From R** (if you have CUDA + cuDF on your system)

``` r
# Install R dependencies first
install.packages(c("Rcpp", "dplyr", "rlang", "vctrs", "pillar", "glue", "cli", "tidyselect", "tibble"))

# Then from the cuplyr directory:
cuplyr::install_cuplyr(method = "system")
```

**Option C: Using pixi** (reproducible, manages all CUDA/RAPIDS deps)

``` bash
# Install pixi: curl -fsSL https://pixi.sh/install.sh | bash
git clone https://github.com/bbtheo/cuplyr.git
cd cuplyr
pixi run install
```

### Verify installation

``` r
library(cuplyr)
verify_installation()
# Or check dependencies first:
check_deps()
```

### Troubleshooting

``` r
# Full diagnostics for bug reports
diagnostics()
```

### Developer setup

See [CONTRIBUTING.md](CONTRIBUTING.md) for the contributor workflow
using `pixi shell`. GitHub Actions trigger/run instructions are in
[docs/github-actions-runbook.md](docs/github-actions-runbook.md).

## Performance

Benchmark code lives in `benchmark/benchmark.R`.

Benchmarks on 25 million rows (synthetic taxi data, median of 10
iterations):

| Operation | dplyr | data.table | DuckDB | cuplyr | cuplyr vs dplyr | cuplyr vs data.table | cuplyr vs DuckDB |
|----|----|----|----|----|----|----|----|
| Group & Summarise | 310.5 ms | 190.0 ms | 67.0 ms | 4.0 ms | **77.6x** | **47.5x** | **16.7x** |
| Filter | 444.0 ms | 479.0 ms | 585.0 ms | 11.0 ms | **40.4x** | **43.5x** | **53.2x** |
| Complete Workflow | 1237.0 ms | 574.5 ms | 126.5 ms | 20.0 ms | **61.9x** | **28.7x** | **6.3x** |

*Complete workflow: filter + mutate + group_by + summarise*

**Hardware**: Intel Core i9-12900K (16 cores), NVIDIA RTX 5070 (12 GB
VRAM)

## Acknowledgments

This project is built on [RAPIDS cuDF](https://github.com/rapidsai/cudf)
by NVIDIA and the RAPIDS AI team.

------------------------------------------------------------------------

**License**: Apache 2.0

**Maintainer**: [@bbtheo](https://github.com/bbtheo)

**Documentation**: `DEVELOPER_GUIDE.md`

# Package index

## All functions

- [`arrange(`*`<tbl_gpu>`*`)`](arrange.tbl_gpu.md) : Arrange rows of a
  GPU table by column values
- [`as_eager()`](as_eager.md) : Switch to eager execution mode
- [`as_lazy()`](as_lazy.md) : Switch to lazy execution mode
- [`as_tbl_gpu()`](as_tbl_gpu.md) : Coerce to a GPU table
- [`bind_cols()`](bind_cols.md) : Bind multiple data frames/tables by
  column
- [`bind_rows()`](bind_rows.md) : Bind multiple data frames/tables by
  row
- [`check_deps()`](check_deps.md) : Check cuplyr dependencies
- [`collapse(`*`<tbl_gpu>`*`)`](collapse.tbl_gpu.md) : Create a subquery
  barrier without executing
- [`collect(`*`<tbl_gpu>`*`)`](collect.tbl_gpu.md) : Transfer GPU table
  data back to R
- [`compute(`*`<tbl_gpu>`*`)`](compute.tbl_gpu.md) : Force computation
  of pending GPU operations
- [`detect_environment()`](detect_environment.md) : Detect the runtime
  environment
- [`diagnostics()`](diagnostics.md) : System diagnostics for cuplyr
- [`dim(`*`<tbl_gpu>`*`)`](dim.tbl_gpu.md) : Get dimensions of a GPU
  table
- [`filter(`*`<tbl_gpu>`*`)`](filter.tbl_gpu.md) : Filter rows of a GPU
  table
- [`gpu_details()`](gpu_details.md) : Get detailed GPU information
- [`gpu_gc()`](gpu_gc.md) : Force GPU memory cleanup
- [`gpu_memory_state()`](gpu_memory_state.md) : Get GPU memory snapshot
- [`gpu_memory_usage()`](gpu_memory_usage.md) : Estimate GPU memory
  usage of a tbl_gpu object
- [`gpu_object_info()`](gpu_object_info.md) : Get detailed information
  about a GPU table object
- [`gpu_size_comparison()`](gpu_size_comparison.md) : Compare R object
  size vs GPU data size
- [`group_by(`*`<tbl_gpu>`*`)`](group_by.tbl_gpu.md) : Group a GPU table
  by one or more columns
- [`group_vars(`*`<tbl_gpu>`*`)`](group_vars.tbl_gpu.md) : Get grouping
  variables from a GPU table
- [`groups(`*`<tbl_gpu>`*`)`](groups.tbl_gpu.md) : Get grouping
  information from a GPU table
- [`has_gpu()`](has_gpu.md) : Check GPU availability
- [`has_pending_ops()`](has_pending_ops.md) : Check if a tbl_gpu has
  pending lazy operations
- [`infer_schema()`](infer_schema.md) : Infer output schema from an AST
  node
- [`install_cuplyr()`](install_cuplyr.md) : Install cuplyr from source
- [`is_lazy()`](is_lazy.md) : Check if a tbl_gpu uses lazy execution
- [`is_tbl_gpu()`](is_tbl_gpu.md) : Test if an object is a GPU table
- [`mutate(`*`<tbl_gpu>`*`)`](mutate.tbl_gpu.md) : Create or modify
  columns in a GPU table
- [`` `names<-`( ``*`<tbl_gpu>`*`)`](names-set-.tbl_gpu.md) : Set column
  names of a GPU table
- [`names(`*`<tbl_gpu>`*`)`](names.tbl_gpu.md) : Get column names of a
  GPU table
- [`select(`*`<tbl_gpu>`*`)`](select.tbl_gpu.md) : Select columns from a
  GPU table
- [`show_gpu()`](show_gpu.md) : Display GPU information
- [`show_query()`](show_query.md) : Show pending operations for a lazy
  tbl_gpu
- [`summarise(`*`<tbl_gpu>`*`)`](summarise.tbl_gpu.md)
  [`summarize(`*`<tbl_gpu>`*`)`](summarise.tbl_gpu.md) : Summarise
  groups in a GPU table
- [`tbl_gpu()`](tbl_gpu.md) : Create a GPU-backed data frame
- [`ungroup(`*`<tbl_gpu>`*`)`](ungroup.tbl_gpu.md) : Remove grouping
  from a GPU table
- [`verify_gpu_data()`](verify_gpu_data.md) : Verify that data resides
  on GPU
- [`verify_installation()`](verify_installation.md) : Verify cuplyr
  installation

# Articles

### All vignettes

- [Complex Data Analysis with cuplyr](complex-analysis.md):
- [Getting Started with cuplyr](getting-started.md):
- [Query Optimization in cuplyr](query-optimization.md):
