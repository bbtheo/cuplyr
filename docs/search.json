[{"path":"https://bbtheo.github.io/cuplyr/AGENTS.html","id":null,"dir":"","previous_headings":"","what":"cuplyr Agent Notes","title":"cuplyr Agent Notes","text":"repo mixes R C++ (Rcpp) GPU-backed dplyr-like operations using libcudf. trickiest parts build tooling, GPU availability, keeping R-level schemas aligned GPU types.","code":""},{"path":[]},{"path":"https://bbtheo.github.io/cuplyr/AGENTS.html","id":"fast-editrun-loop","dir":"","previous_headings":"Local Dev (pixi)","what":"Fast edit/run loop","title":"cuplyr Agent Notes","text":"pixi run configure (CUDA/cudf paths change). Edit code. pixi run install (full rebuild) pixi run load-dev (fast reload R). Spot-check R (e.g., gpu_details(), tbl_gpu(mtcars)).","code":""},{"path":"https://bbtheo.github.io/cuplyr/AGENTS.html","id":"when-to-use-each-task","dir":"","previous_headings":"Local Dev (pixi)","what":"When to use each task","title":"cuplyr Agent Notes","text":"pixi run load-dev: tight inner loop R changes quick checks. pixi run install: C++ changes exports changed. pixi run dev: suspect stale artifacts (clean + rebuild). pixi run test: always run implementing feature (requires GPU).","code":""},{"path":"https://bbtheo.github.io/cuplyr/AGENTS.html","id":"core-data-structures","dir":"","previous_headings":"","what":"Core Data Structures","title":"cuplyr Agent Notes","text":"tbl_gpu list ptr (externalptr), schema (names + types), groups, exec_mode (\"eager\"/\"lazy\"), lazy_ops (AST node NULL).","code":""},{"path":"https://bbtheo.github.io/cuplyr/AGENTS.html","id":"type-mappings-r---gpu","dir":"","previous_headings":"","what":"Type Mappings (R -> GPU)","title":"cuplyr Agent Notes","text":"logical -> BOOL8 integer -> INT32 double -> FLOAT64 character -> STRING Date -> TIMESTAMP_DAYS POSIXct -> TIMESTAMP_MICROSECONDS factor -> INT32 (codes ) integer64 -> FLOAT64 (precision loss > 2^53, warn)","code":""},{"path":"https://bbtheo.github.io/cuplyr/AGENTS.html","id":"current-c-layout-split-from-transfercpp","dir":"","previous_headings":"","what":"Current C++ Layout (split from transfer.cpp)","title":"cuplyr Agent Notes","text":"src/transfer_io.cpp: R <-> GPU conversion, collect/head/df_to_gpu. src/ops_filter.cpp: filter operations mask handling. src/ops_compare.cpp: comparison ops used summarise temp columns. src/ops_mutate.cpp: mutate copy/replace ops. src/ops_select.cpp: select operations. src/ops_groupby.cpp: summarise/groupby logic. src/gpu_info.cpp: device availability/info. src/cuda_utils.hpp: check_cuda() helper. src/ops_common.hpp: shared operator mapping helpers. src/gpu_table.hpp: pointer ownership helpers cudf::table.","code":""},{"path":"https://bbtheo.github.io/cuplyr/AGENTS.html","id":"r-entry-points","dir":"","previous_headings":"","what":"R Entry Points","title":"cuplyr Agent Notes","text":"R/tbl-gpu.R: tbl_gpu() constructor + schema metadata. R/mutate.R, R/filter.R, R/select.R, R/arrange.R, R/summarise.R: dplyr verbs. R/collect.R: pulls data back R warns INT64 precision. R/gpu-memory.R: memory reporting GC helpers. R/utils.R: shared helpers (type mapping, wrap_gpu_call() clearer GPU errors).","code":""},{"path":"https://bbtheo.github.io/cuplyr/AGENTS.html","id":"known-sharp-edges-things-that-were-hard","dir":"","previous_headings":"","what":"Known Sharp Edges (things that were hard)","title":"cuplyr Agent Notes","text":"cudf header names differ version. bitmask_allocation_size_bytes lives cudf/null_mask.hpp environment. Avoid cudf/bitmask.hpp. R type vs GPU type mismatch can silently break results. Keep gpu_type_from_r() df_to_gpu() sync (logical/Date/POSIXct especially). GPU detected common CI local dev. Tests use skip_if_no_gpu(); don’t remove . Rcpp exports need regeneration moving/adding functions: run Rcpp::compileAttributes() devtools::document(). INT64 precision: gpu_collect() returns doubles; warn values exceed 2^53. Memory growth: GPU op tends allocate new tables. Replacement mutate paths optimized, GC still matters. Join memory warnings: joins estimate output size warn close available GPU memory; actual allocation can still fail. String columns: Arrow-style storage (offsets + char data). slicing, offsets chars must kept Join ordering: cuDF join outputs unordered; stable-sort join maps left_map (right_map) src/ops_join.cpp match dplyr. Join unmatched rows: cuDF uses JoinNoMatch sentinel; gather treats negatives wraparound. Current fix sanitizes join maps CPU (replace nrows) gather uses out_of_bounds_policy::NULLIFY. cuDF gather API: environment’s cudf::gather signature negative_index_policy. Join headers: join APIs live cudf/join/join.hpp env (cudf/join.hpp).","code":""},{"path":"https://bbtheo.github.io/cuplyr/AGENTS.html","id":"debugging-local-build-failures","dir":"","previous_headings":"","what":"Debugging Local Build Failures","title":"cuplyr Agent Notes","text":"cudf header can’t found, check pixi environment paths src/Makevars. Run pixi run configure updating CUDA/cudf libs. Use rg --files -g '*bitmask*' $CONDA_PREFIX/include/cudf locate moved headers. Join build errors: confirm #include <cudf/join/join.hpp> avoid device-side Thrust unless compiling nvcc.","code":""},{"path":"https://bbtheo.github.io/cuplyr/AGENTS.html","id":"adding-new-gpu-ops-local-loop","dir":"","previous_headings":"","what":"Adding New GPU Ops (local loop)","title":"cuplyr Agent Notes","text":"Implement appropriate src/ops_*.cpp file. Add // [[Rcpp::export]] function. Run Rcpp::compileAttributes() regenerate R/RcppExports.R + src/RcppExports.cpp. Add R wrapper R/*.R tests tests/testthat/.","code":""},{"path":"https://bbtheo.github.io/cuplyr/AGENTS.html","id":"when-you-touch-types-local-loop","dir":"","previous_headings":"","what":"When You Touch Types (local loop)","title":"cuplyr Agent Notes","text":"Update schema: R/utils.R (gpu_type_from_r). Update collect/head conversion new cudf types. Add tests round-trip behavior.","code":""},{"path":"https://bbtheo.github.io/cuplyr/AGENTS.html","id":"joins-ast--optimizer-notes","dir":"","previous_headings":"","what":"Joins (AST + optimizer notes)","title":"cuplyr Agent Notes","text":"Lazy joins build ast_join two inputs; source pointers attached via set_ast_source_ptr() lowering. infer_schema.ast_join uses build_join_schema() R/join.R. Inner: left--> left, right--> right. Left: left-pushed. Right: right-pushed. Full: side-pushdown. Projection/dead-column pruning across joins uses build_join_output_info() map output columns back left/right sources. Right join implemented via swapped left join + column reorder; ensure desired column names exist gpu_select.","code":""},{"path":"https://bbtheo.github.io/cuplyr/AGENTS.html","id":"code-review-quick-checklist-saves-time","dir":"","previous_headings":"","what":"Code Review Quick Checklist (saves time)","title":"cuplyr Agent Notes","text":"Type alignment: R/utils.R src/transfer_io.cpp must agree type mapping. Head/collect parity: type supported gpu_collect(), ensure gpu_head() uses conversion path. Arrange semantics: Confirm stable sort support libcudf, NA ordering, group-prepend behavior R/arrange.R. Rcpp exports: new C++ functions exist, verify R/RcppExports.R src/RcppExports.cpp updated. Tests: New verb features matching tests/testthat/test-*.R coverage use skip_if_no_gpu(). Joins: Verify left-table order, right-key dropping (keep = FALSE drops right keys even names differ), join pushdown rules.","code":""},{"path":"https://bbtheo.github.io/cuplyr/AGENTS.html","id":"bugfix-workflow","dir":"","previous_headings":"","what":"Bugfix Workflow","title":"cuplyr Agent Notes","text":"Test-first (STRICT): bug reported, always add failing test reproduces implementing fix. test passes unexpectedly, revert fix, confirm failure, re-apply.","code":""},{"path":"https://bbtheo.github.io/cuplyr/AGENTS.html","id":"recent-session-notes","dir":"","previous_headings":"","what":"Recent Session Notes","title":"cuplyr Agent Notes","text":"Exec mode field: tbl_gpu now includes exec_mode; tests/structure checks must allow (see helper updates). Exec mode propagation: constructors created verbs now explicitly carry forward .data$exec_mode (avoid option/env-driven mode drift). lazy_ops invariant: pending work NULL (list()). Legacy empty-list values normalized NULL new_tbl_gpu() compute(). lazy_ops validation: non-empty invalid lazy_ops objects now fail fast clear error compute/optimizer paths. Bind generic fallback: bind_rows.default / bind_cols.default now delegate dplyr non-tbl_gpu inputs; tbl_gpu methods remain GPU-backed. Lazy vs eager tests: Added cross-mode comparisons using tibble::as_tibble() avoid rownames/class mismatches. Filter parsing: Boolean literal fast-path avoids eval_tidy without data mask prevent name-collision bugs. Mutate parsing: Supports left-associative +/- chains (e.g., + b + c) lowering sequential ops. Optimizer barriers: Barrier reattachment uses helper avoid R copy--modify pitfalls. Benchmarking: benchmark/benchmark_memory.R compares lazy vs eager memory/time using synthetic taxi data. Filter pushdown benchmark: benchmark/benchmark_filter_pushdown.R compares auto vs manual filter placement reports GPU memory deltas. Join tests: tests/testthat/test-join.R includes eager/lazy joins, multi-key, renamed keys, edge-case comparisons vs base dplyr.","code":""},{"path":"https://bbtheo.github.io/cuplyr/CLAUDE.html","id":null,"dir":"","previous_headings":"","what":"cuplyr – Notes for Coding Agents","title":"cuplyr – Notes for Coding Agents","text":"GPU-backed dplyr API R C++/Rcpp bindings libcudf.","code":""},{"path":[]},{"path":"https://bbtheo.github.io/cuplyr/CLAUDE.html","id":"core-data-structures","dir":"","previous_headings":"Quick Reference","what":"Core Data Structures","title":"cuplyr – Notes for Coding Agents","text":"","code":"# tbl_gpu structure (R/tbl-gpu.R) list(   ptr = <externalptr>,           # XPtr to cudf::table   schema = list(     names = c(\"col1\", \"col2\"),   # column names     types = c(\"FLOAT64\", \"INT32\") # GPU type strings   ),   groups = c(\"col1\"),            # group_by columns (can be empty)   exec_mode = \"eager\",           # \"eager\" or \"lazy\"   lazy_ops = list()              # AST for lazy evaluation )"},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":"https://bbtheo.github.io/cuplyr/CLAUDE.html","id":"workflow","dir":"","previous_headings":"Local Dev (pixi)","what":"Workflow","title":"cuplyr – Notes for Coding Agents","text":"Edit code pixi run install (C++ changed) pixi run load-dev (R ) Test R: tbl_gpu(mtcars) |> filter(mpg > 20) |> collect() pixi run test","code":""},{"path":[]},{"path":"https://bbtheo.github.io/cuplyr/CLAUDE.html","id":"step-1-c-implementation-srcops_verbcpp","dir":"","previous_headings":"Implementing a New dplyr Verb","what":"Step 1: C++ Implementation (src/ops_<verb>.cpp)","title":"cuplyr – Notes for Coding Agents","text":"","code":"#include \"gpu_table.hpp\" #include \"cuda_utils.hpp\" #include <cudf/...>  // operation-specific headers #include <Rcpp.h>  using namespace Rcpp;  // [[Rcpp::export]] SEXP gpu_<verb>(SEXP xptr, /* params */) {     using namespace cuplyr;      // 1. Get table view     Rcpp::XPtr<GpuTablePtr> ptr(xptr);     cudf::table_view view = get_table_view(ptr);      // 2. Validate inputs     if (col_idx < 0 || col_idx >= view.num_columns()) {         Rcpp::stop(\"Column index out of bounds: %d\", col_idx);     }      // 3. Perform cuDF operation     auto result = cudf::some_operation(view, ...);      // 4. Return new table     return make_gpu_table_xptr(std::move(result)); }"},{"path":"https://bbtheo.github.io/cuplyr/CLAUDE.html","id":"step-2-r-wrapper-rverbr","dir":"","previous_headings":"Implementing a New dplyr Verb","what":"Step 2: R Wrapper (R/<verb>.R)","title":"cuplyr – Notes for Coding Agents","text":"","code":"#' @export #' @importFrom dplyr <verb> <verb>.tbl_gpu <- function(.data, ...) {   # 1. Capture expressions   dots <- rlang::enquos(...)   if (length(dots) == 0) return(.data)    # 2. Parse expressions (verb-specific)   for (i in seq_along(dots)) {     expr <- dots[[i]]     expr_text <- rlang::quo_text(expr)     # ... parse and validate   }    # 3. Convert column names to 0-based indices   col_idx <- match(col_name, .data$schema$names) - 1L    # 4. Call C++ function   new_ptr <- gpu_<verb>(.data$ptr, col_idx, ...)    # 5. Return new tbl_gpu (preserves schema/groups unless modified)   new_tbl_gpu(     ptr = new_ptr,     schema = .data$schema,  # or modified schema     groups = .data$groups   ) }"},{"path":"https://bbtheo.github.io/cuplyr/CLAUDE.html","id":"step-3-update-exports","dir":"","previous_headings":"Implementing a New dplyr Verb","what":"Step 3: Update Exports","title":"cuplyr – Notes for Coding Agents","text":"NAMESPACE (add lines): Rcpp exports (run manually add): manually add : - src/RcppExports.cpp: function declaration + wrapper + CallEntries entry - R/RcppExports.R: R wrapper function","code":"S3method(<verb>,tbl_gpu) importFrom(dplyr,<verb>) Rcpp::compileAttributes()"},{"path":"https://bbtheo.github.io/cuplyr/CLAUDE.html","id":"step-4-tests-teststestthattest-verbr","dir":"","previous_headings":"Implementing a New dplyr Verb","what":"Step 4: Tests (tests/testthat/test-<verb>.R)","title":"cuplyr – Notes for Coding Agents","text":"","code":"test_that(\"<verb>() basic case works\", {   skip_if_no_gpu()    df <- data.frame(x = c(1, 2, 3))   gpu_df <- tbl_gpu(df)    result <- gpu_df |>     dplyr::<verb>(...) |>     collect()    expect_equal(result$x, expected) })"},{"path":[]},{"path":"https://bbtheo.github.io/cuplyr/CLAUDE.html","id":"lazy-mode-mechanics","dir":"","previous_headings":"AST & Lazy Evaluation","what":"Lazy Mode Mechanics","title":"cuplyr – Notes for Coding Agents","text":"Lazy tables defer execution building AST $lazy_ops Operations return new tbl_gpu updated AST, GPU work collect() triggers AST lowering execution","code":""},{"path":"https://bbtheo.github.io/cuplyr/CLAUDE.html","id":"optimizer-passes","dir":"","previous_headings":"AST & Lazy Evaluation","what":"Optimizer Passes","title":"cuplyr – Notes for Coding Agents","text":"optimizer transforms AST execution. Pass order matters: build_join_output_info() maps output columns back left/right sources Dead columns dropped expensive operations Guards: max 8 expressions, max 4 intermediates, max 3 reuses Uses topological sort dependent expressions Walks root leaves tracking required columns Empty mutate nodes eliminated Pushes across mutate predicates don’t depend outputs Inner join: left-predicates -> left, right--> right Left join: left-predicates pushed Right join: right-predicates pushed Full join: side-pushdown allowed Collects consecutive filter chains Sorts estimated_cost field Max 4 simple predicates fusion","code":""},{"path":"https://bbtheo.github.io/cuplyr/CLAUDE.html","id":"join-specific-notes","dir":"","previous_headings":"AST & Lazy Evaluation","what":"Join-Specific Notes","title":"cuplyr – Notes for Coding Agents","text":"Lazy joins build ast_join two inputs Source pointers attached via set_ast_source_ptr() lowering Schema inference: infer_schema.ast_join uses build_join_schema() R/join.R Right join: implemented via swapped left join + column reorder Ensure desired column names exist calling gpu_select","code":""},{"path":"https://bbtheo.github.io/cuplyr/CLAUDE.html","id":"optimizer-barriers","dir":"","previous_headings":"AST & Lazy Evaluation","what":"Optimizer Barriers","title":"cuplyr – Notes for Coding Agents","text":"Barrier reattachment uses helper avoid R copy--modify pitfalls careful modifying AST nodes place","code":""},{"path":[]},{"path":"https://bbtheo.github.io/cuplyr/CLAUDE.html","id":"expression-parsing-r-side","dir":"","previous_headings":"Common Patterns","what":"Expression Parsing (R side)","title":"cuplyr – Notes for Coding Agents","text":"","code":"# Capture unevaluated expressions dots <- rlang::enquos(...)  # Get expression text expr_text <- rlang::quo_text(expr)  # Get raw expression raw_expr <- rlang::quo_get_expr(expr)  # Check if symbol (bare column name) if (is.symbol(raw_expr)) col_name <- as.character(raw_expr)  # Check if call (function application) if (is.call(raw_expr)) {   fn_name <- as.character(raw_expr[[1]])  # e.g., \"desc\", \"-\"   arg <- raw_expr[[2]]                     # first argument }"},{"path":"https://bbtheo.github.io/cuplyr/CLAUDE.html","id":"column-index-conversion","dir":"","previous_headings":"Common Patterns","what":"Column Index Conversion","title":"cuplyr – Notes for Coding Agents","text":"","code":"# R uses 1-based, C++ uses 0-based col_idx_r <- match(col_name, .data$schema$names)  # 1-based, NA if not found col_idx_cpp <- col_idx_r - 1L                      # 0-based for C++"},{"path":"https://bbtheo.github.io/cuplyr/CLAUDE.html","id":"validation-patterns-c","dir":"","previous_headings":"Common Patterns","what":"Validation Patterns (C++)","title":"cuplyr – Notes for Coding Agents","text":"","code":"// Bounds check if (col_idx < 0 || col_idx >= view.num_columns()) {     Rcpp::stop(\"Column index out of bounds: %d (table has %d columns)\",                col_idx, view.num_columns()); }  // NA check in LogicalVector if (LogicalVector::is_na(value[i])) {     Rcpp::stop(\"NA values not allowed in parameter\"); }  // Row count limit (int32 for indices) if (view.num_rows() > static_cast<cudf::size_type>(INT32_MAX)) {     Rcpp::stop(\"Table too large (max ~2.1 billion rows)\"); }"},{"path":[]},{"path":"https://bbtheo.github.io/cuplyr/CLAUDE.html","id":"environment-specific-cudf-issues","dir":"","previous_headings":"Known Issues & Sharp Edges","what":"Environment-Specific cuDF Issues","title":"cuplyr – Notes for Coding Agents","text":"Header locations differ version: bitmask_allocation_size_bytes cudf/null_mask.hpp, cudf/bitmask.hpp Join headers: Use <cudf/join/join.hpp>, <cudf/join.hpp> cuDF gather API: environment’s cudf::gather negative_index_policy parameter Avoid device-side Thrust unless compiling nvcc","code":""},{"path":"https://bbtheo.github.io/cuplyr/CLAUDE.html","id":"type-consistency","dir":"","previous_headings":"Known Issues & Sharp Edges","what":"Type Consistency","title":"cuplyr – Notes for Coding Agents","text":"R schema types MUST match actual GPU column types. changing type handling: - Update R/utils.R::gpu_type_from_r() - Update src/transfer_io.cpp::df_to_gpu() - Update tests round-trip behavior","code":""},{"path":"https://bbtheo.github.io/cuplyr/CLAUDE.html","id":"string-column-operations","dir":"","previous_headings":"Known Issues & Sharp Edges","what":"String Column Operations","title":"cuplyr – Notes for Coding Agents","text":"String columns use offset-based storage (Apache Arrow format): - col.child(0) = offsets column (int32, n+1 elements) - col.data<char>() = concatenated character data - slicing (e.g., head), must slice offsets chars correctly","code":""},{"path":"https://bbtheo.github.io/cuplyr/CLAUDE.html","id":"memory-semantics","dir":"","previous_headings":"Known Issues & Sharp Edges","what":"Memory Semantics","title":"cuplyr – Notes for Coding Agents","text":"ops allocate new tables (immutable design) Peak memory sorting: ~2x table size Use gpu_memory_state() monitor GC frees GPU memory via pointer release","code":""},{"path":"https://bbtheo.github.io/cuplyr/CLAUDE.html","id":"grouping-behavior","dir":"","previous_headings":"Known Issues & Sharp Edges","what":"Grouping Behavior","title":"cuplyr – Notes for Coding Agents","text":"group_by() sets metadata ($groups), GPU work Groups applied summarise() arrange(.by_group=TRUE) prepends group columns sort keys Preserve $groups returning new tbl_gpu unless ungrouping","code":""},{"path":"https://bbtheo.github.io/cuplyr/CLAUDE.html","id":"join-ordering--unmatched-rows","dir":"","previous_headings":"Known Issues & Sharp Edges","what":"Join Ordering & Unmatched Rows","title":"cuplyr – Notes for Coding Agents","text":"cuDF join outputs unordered: stable-sort join maps left_map (right_map) src/ops_join.cpp match dplyr JoinNoMatch sentinel: cuDF uses sentinel values; gather treats negatives wraparound Current fix: Sanitize join maps CPU (replace nrows) gather, use out_of_bounds_policy::NULLIFY Right key dropping: keep = FALSE drops right keys even names differ","code":""},{"path":"https://bbtheo.github.io/cuplyr/CLAUDE.html","id":"filter-parsing","dir":"","previous_headings":"Known Issues & Sharp Edges","what":"Filter Parsing","title":"cuplyr – Notes for Coding Agents","text":"Boolean literal fast-path avoids eval_tidy without data mask prevent name-collision bugs","code":""},{"path":"https://bbtheo.github.io/cuplyr/CLAUDE.html","id":"mutate-parsing","dir":"","previous_headings":"Known Issues & Sharp Edges","what":"Mutate Parsing","title":"cuplyr – Notes for Coding Agents","text":"Supports left-associative +/- chains (e.g., + b + c) lowering sequential ops","code":""},{"path":"https://bbtheo.github.io/cuplyr/CLAUDE.html","id":"bind-operations","dir":"","previous_headings":"Known Issues & Sharp Edges","what":"Bind Operations","title":"cuplyr – Notes for Coding Agents","text":"bind_rows() computes unified schema via compute_unified_schema() Type promotion hierarchy: BOOL8 < INT32 < INT64 < FLOAT64; STRING widest Missing columns filled nulls via gpu_make_null_column() bind_cols() uses vctrs::vec_as_names() name repair available operations materialize lazy tables binding","code":""},{"path":"https://bbtheo.github.io/cuplyr/CLAUDE.html","id":"debugging-build-failures","dir":"","previous_headings":"","what":"Debugging Build Failures","title":"cuplyr – Notes for Coding Agents","text":"cudf header can’t found, check pixi environment paths src/Makevars Run pixi run configure updating CUDA/cudf libs Use rg --files -g '*bitmask*' $CONDA_PREFIX/include/cudf locate moved headers Join build errors: confirm #include <cudf/join/join.hpp> avoid device-side Thrust unless compiling nvcc GPU detected common CI local dev; tests use skip_if_no_gpu() Rcpp exports need regeneration moving/adding functions: run Rcpp::compileAttributes() devtools::document()","code":""},{"path":[]},{"path":"https://bbtheo.github.io/cuplyr/CLAUDE.html","id":"available-helpers-teststestthathelper-r","dir":"","previous_headings":"Testing","what":"Available Helpers (tests/testthat/helper-*.R)","title":"cuplyr – Notes for Coding Agents","text":"","code":"skip_if_no_gpu()           # Skip test if no GPU available expect_valid_tbl_gpu(x)    # Check tbl_gpu structure (allows exec_mode field) expect_data_on_gpu(x)      # Verify data is on GPU gc_gpu()                   # Force GPU garbage collection gpu_memory_snapshot()      # Get memory state for comparison"},{"path":"https://bbtheo.github.io/cuplyr/CLAUDE.html","id":"test-pattern","dir":"","previous_headings":"Testing","what":"Test Pattern","title":"cuplyr – Notes for Coding Agents","text":"","code":"test_that(\"operation handles edge case\", {   skip_if_no_gpu()    # Setup   df <- data.frame(...)   gpu_df <- tbl_gpu(df)    # Execute   result <- gpu_df |> some_operation() |> collect()    # Assert   expect_equal(result$col, expected) })"},{"path":"https://bbtheo.github.io/cuplyr/CLAUDE.html","id":"lazy-vs-eager-cross-mode-testing","dir":"","previous_headings":"Testing","what":"Lazy vs Eager Cross-Mode Testing","title":"cuplyr – Notes for Coding Agents","text":"Use tibble::as_tibble() avoid rownames/class mismatches comparing:","code":"expect_equal(    as_tibble(eager_result),   as_tibble(lazy_result) )"},{"path":"https://bbtheo.github.io/cuplyr/CLAUDE.html","id":"code-review-checklist","dir":"","previous_headings":"","what":"Code Review Checklist","title":"cuplyr – Notes for Coding Agents","text":"merging, verify: - [ ] Type alignment: R/utils.R src/transfer_io.cpp agree type mapping - [ ] Head/collect parity: type supported gpu_collect(), ensure gpu_head() uses conversion path - [ ] Arrange semantics: Stable sort support, NA ordering, group-prepend behavior - [ ] Rcpp exports: new C++ functions exist, R/RcppExports.R src/RcppExports.cpp updated - [ ] Tests: New features matching tests/testthat/test-*.R coverage skip_if_no_gpu() - [ ] Joins: Left-table order preserved, right-key dropping correct, pushdown rules followed - [ ] Binds: Type promotion correct, null columns missing, lazy tables materialized","code":""},{"path":"https://bbtheo.github.io/cuplyr/CLAUDE.html","id":"development-mandates","dir":"","previous_headings":"","what":"Development Mandates","title":"cuplyr – Notes for Coding Agents","text":"Test-first bugfixes (STRICT): bug reported, always add failing test reproduces implementing fix. test passes unexpectedly, revert fix, confirm failure, re-apply. Run tests every feature (STRICT): implementing feature fix, always run pixi run test considering work complete. skip step. tests fail, fix issue moving .","code":""},{"path":[]},{"path":[]},{"path":"https://bbtheo.github.io/cuplyr/DEVELOPER_GUIDE.html","id":"complete-developer-reference-and-implementation-blueprint","dir":"","previous_headings":"","what":"Complete Developer Reference and Implementation Blueprint","title":"cuplyr: GPU-Accelerated dplyr Backend via libcudf","text":"Version: 1.0.0 Target RAPIDS Version: 25.12+ (stable), guidance 26.x Target CUDA Toolkit: 12.x Target R Version: 4.3+ Status note: Sections marked Roadmap describe planned architecture implemented current codebase. current implementation executes eagerly (AST optimizer).","code":""},{"path":"https://bbtheo.github.io/cuplyr/DEVELOPER_GUIDE.html","id":"table-of-contents","dir":"","previous_headings":"","what":"Table of Contents","title":"cuplyr: GPU-Accelerated dplyr Backend via libcudf","text":"Scope & Audience Goals & Acceptance Criteria High-Level Architecture Detailed Mapping Table Representations & Types Binding Strategy & C++ Glue Build System & Packaging Minimal Working Prototype Roadmap: Lazy Translation & AST Approach (Implemented) Testing & Validation Debugging, Logging & Observability Performance & Optimization Interoperability Packaging, Distribution & Licensing Example User Workflows Security & Safety Maintenance & Migration Deliverables Checklist Search Keywords & Resources","code":""},{"path":[]},{"path":"https://bbtheo.github.io/cuplyr/DEVELOPER_GUIDE.html","id":"target-audience","dir":"","previous_headings":"1. Scope & Audience","what":"Target Audience","title":"cuplyr: GPU-Accelerated dplyr Backend via libcudf","text":"guide written : - Experienced R package authors familiar S3/S4 OOP, Rcpp cpp11, R’s build system - C++ developers CUDA toolchain experience - Data engineers familiar dplyr internals backend implementations (e.g., dbplyr, dtplyr)","code":""},{"path":[]},{"path":"https://bbtheo.github.io/cuplyr/DEVELOPER_GUIDE.html","id":"version-detection-script","dir":"","previous_headings":"1. Scope & Audience","what":"Version Detection Script","title":"cuplyr: GPU-Accelerated dplyr Backend via libcudf","text":"","code":"#!/bin/bash # detect_rapids_version.sh - Query current RAPIDS/libcudf version  echo \"=== System Check ===\" echo \"CUDA Toolkit:\" nvcc --version 2>/dev/null || echo \"nvcc not found\"  echo -e \"\\nDriver Version:\" nvidia-smi --query-gpu=driver_version --format=csv,noheader 2>/dev/null || echo \"nvidia-smi not found\"  echo -e \"\\nGPU Compute Capability:\" nvidia-smi --query-gpu=compute_cap --format=csv,noheader 2>/dev/null  echo -e \"\\nRAIDS libcudf (conda):\" conda list libcudf 2>/dev/null | grep libcudf || echo \"Not installed via conda\"  echo -e \"\\nRAIDS libcudf (pip):\" pip show libcudf-cu12 2>/dev/null | grep Version || echo \"Not installed via pip\"  echo -e \"\\nR Version:\" R --version | head -1"},{"path":[]},{"path":"https://bbtheo.github.io/cuplyr/DEVELOPER_GUIDE.html","id":"migration-steps-when-versions-change","dir":"","previous_headings":"1. Scope & Audience","what":"Migration Steps When Versions Change","title":"cuplyr: GPU-Accelerated dplyr Backend via libcudf","text":"Check RAPIDS release notes https://docs.rapids.ai/notices/rsn/ Update Dockerfile base image tag Run configure script detect new include/lib paths Rebuild package R CMD INSTALL --preclean Run full test suite catch ABI breaks Update DESCRIPTION SystemRequirements field","code":""},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":"https://bbtheo.github.io/cuplyr/DEVELOPER_GUIDE.html","id":"id_3-high-level-architecture","dir":"","previous_headings":"","what":"3. High-Level Architecture","title":"cuplyr: GPU-Accelerated dplyr Backend via libcudf","text":"","code":"┌─────────────────────────────────────────────────────────────────┐ │                         R User Code                              │ │  tbl_gpu(df) %>% filter(x > 10) %>% group_by(g) %>% summarise() │ └─────────────────────────────────────────────────────────────────┘                                 │                                 ▼ ┌─────────────────────────────────────────────────────────────────┐ │                      R API Layer (S3)                            │ │  • tbl_gpu class constructor                                     │ │  • dplyr verb S3 methods (filter.tbl_gpu, mutate.tbl_gpu, ...)  │ │  • print/format methods via pillar                               │ │  • collect() / compute() materialization                         │ └─────────────────────────────────────────────────────────────────┘                                 │                                 ▼ ┌─────────────────────────────────────────────────────────────────┐ │                   Translation Layer (AST)                        │ │  • Capture quosures from dplyr verbs                            │ │  • Build operation AST (lazy pipeline, planned)                 │ │  • Query optimization (predicate pushdown, projection pruning)  │ │  • Lower AST nodes to libcudf operation sequence                │ └─────────────────────────────────────────────────────────────────┘                                 │                                 ▼ ┌─────────────────────────────────────────────────────────────────┐ │                    Native Layer (C++/Rcpp)                       │ │  • Rcpp::XPtr wrappers for cudf::table                          │ │  • GPU memory management (RAII via unique_ptr)                  │ │  • libcudf API calls (sort, filter, groupby, join)              │ │  • Arrow C Data Interface for zero-copy interop                 │ └─────────────────────────────────────────────────────────────────┘                                 │                                 ▼ ┌─────────────────────────────────────────────────────────────────┐ │                      libcudf (RAPIDS)                            │ │  • cudf::column, cudf::table, cudf::table_view                  │ │  • GPU kernels for data operations                              │ │  • RMM (RAPIDS Memory Manager) for allocations                  │ └─────────────────────────────────────────────────────────────────┘                                 │                                 ▼ ┌─────────────────────────────────────────────────────────────────┐ │                         CUDA Runtime                             │ │                         NVIDIA GPU                               │ └─────────────────────────────────────────────────────────────────┘"},{"path":[]},{"path":"https://bbtheo.github.io/cuplyr/DEVELOPER_GUIDE.html","id":"r-layer","dir":"","previous_headings":"3. High-Level Architecture > Component Responsibilities","what":"R Layer","title":"cuplyr: GPU-Accelerated dplyr Backend via libcudf","text":"Export user-facing API: tbl_gpu(), as_tbl_gpu(), collect(), compute() Implement dplyr S3 generics tbl_gpu class Use vctrs type coercion pillar pretty printing Capture expressions quosures using rlang","code":""},{"path":"https://bbtheo.github.io/cuplyr/DEVELOPER_GUIDE.html","id":"translation-layer","dir":"","previous_headings":"3. High-Level Architecture > Component Responsibilities","what":"Translation Layer","title":"cuplyr: GPU-Accelerated dplyr Backend via libcudf","text":"Convert R expressions internal AST representation Map R functions libcudf equivalents Perform optimizations execution Eager execution implemented; lazy/AST mode roadmap ","code":""},{"path":"https://bbtheo.github.io/cuplyr/DEVELOPER_GUIDE.html","id":"native-layer","dir":"","previous_headings":"3. High-Level Architecture > Component Responsibilities","what":"Native Layer","title":"cuplyr: GPU-Accelerated dplyr Backend via libcudf","text":"Wrap std::unique_ptr<cudf::table> Rcpp::XPtr Implement C++ functions callable R via .Call() Handle GPU memory lifecycle RAII Provide Arrow C Data Interface export/import","code":""},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":"https://bbtheo.github.io/cuplyr/DEVELOPER_GUIDE.html","id":"the-tbl_gpu-s3-class","dir":"","previous_headings":"5. Representations & Types","what":"The tbl_gpu S3 Class","title":"cuplyr: GPU-Accelerated dplyr Backend via libcudf","text":"","code":"# Class structure # A tbl_gpu object contains: # - ptr: Rcpp::XPtr to cudf::table (currently always materialized) # - schema: list(names = character(), types = character()) # - lazy_ops: reserved for future lazy/AST work (unused today) # - groups: character vector of grouping column names  new_tbl_gpu <- function(ptr = NULL, schema = list(), lazy_ops = list(), groups = character()) { structure( list(   ptr = ptr,   schema = schema,   lazy_ops = lazy_ops,   groups = groups ), class = c(\"tbl_gpu\", \"tbl_lazy\", \"tbl\") ) }  # Validator validate_tbl_gpu <- function(x) { stopifnot( is.list(x), inherits(x, \"tbl_gpu\"), is.list(x$schema), is.character(x$schema$names), is.character(x$schema$types), is.list(x$lazy_ops), is.character(x$groups) ) x }  # Constructor (user-facing) tbl_gpu <- function(data, ...) { UseMethod(\"tbl_gpu\") }  tbl_gpu.data.frame <- function(data, ...) { # Transfer to GPU ptr <- .Call(`_cuplyr_df_to_gpu`, data) schema <- list( names = names(data), types = vapply(data, function(col) gpu_type_from_r(col), character(1)) ) new_tbl_gpu(ptr = ptr, schema = schema) }  tbl_gpu.tbl_gpu <- function(data, ...) { data }"},{"path":[]},{"path":"https://bbtheo.github.io/cuplyr/DEVELOPER_GUIDE.html","id":"gpu-type-detection","dir":"","previous_headings":"5. Representations & Types","what":"GPU Type Detection","title":"cuplyr: GPU-Accelerated dplyr Backend via libcudf","text":"Current implementation notes: - Factors transferred INT32 (levels preserved). - integer64 columns ingested df_to_gpu(); must pre-cast. - INT64 columns collected R returned numeric warning values exceed 2^53.","code":"gpu_type_from_r <- function(x) { if (is.logical(x)) return(\"BOOL8\") if (is.integer(x)) return(\"INT32\") if (is.double(x)) { if (inherits(x, \"Date\")) return(\"TIMESTAMP_DAYS\") if (inherits(x, \"POSIXct\")) return(\"TIMESTAMP_MICROSECONDS\") return(\"FLOAT64\") } if (is.character(x)) return(\"STRING\") if (is.factor(x)) return(\"INT32\")  # factor levels not preserved on GPU if (inherits(x, \"integer64\")) return(\"INT64\")  # ingestion not implemented in C++ stop(\"Unsupported type: \", typeof(x)) }  r_type_from_gpu <- function(gpu_type) { switch(gpu_type, \"BOOL8\" = logical(), \"INT32\" = integer(), \"INT64\" = double(),  # precision warning for values > 2^53 \"FLOAT32\" = double(), \"FLOAT64\" = double(), \"STRING\" = character(), \"TIMESTAMP_DAYS\" = vctrs::new_date(), \"TIMESTAMP_MICROSECONDS\" = vctrs::new_datetime(), stop(\"Unsupported GPU type: \", gpu_type) ) }"},{"path":"https://bbtheo.github.io/cuplyr/DEVELOPER_GUIDE.html","id":"nanull-handling","dir":"","previous_headings":"5. Representations & Types","what":"NA/NULL Handling","title":"cuplyr: GPU-Accelerated dplyr Backend via libcudf","text":"libcudf uses validity bitmasks (Arrow-style) 0 bit indicates NULL. Semantic differences document: - R’s NA logical → cudf NULL (third value) - R’s NA_integer_ → cudf NULL INT32 column - R’s NA_real_ (NaN) → Preserved NaN, separate NULL - R’s NA_character_ → cudf NULL STRING column","code":"// C++ side: Check for nulls bool has_nulls = column.has_nulls(); cudf::size_type null_count = column.null_count();  // R side: Convert NA handling // R's NA is automatically mapped to cudf NULL via our transfer functions"},{"path":"https://bbtheo.github.io/cuplyr/DEVELOPER_GUIDE.html","id":"type-promotion-rules","dir":"","previous_headings":"5. Representations & Types","what":"Type Promotion Rules","title":"cuplyr: GPU-Accelerated dplyr Backend via libcudf","text":"Follow R’s type promotion, implemented transfer time:","code":"# Promotion hierarchy (lowest to highest) # logical < integer < double # integer64 is separate branch  promote_types <- function(type1, type2) { hierarchy <- c(\"BOOL8\" = 1, \"INT32\" = 2, \"INT64\" = 3, \"FLOAT64\" = 4) if (hierarchy[type1] >= hierarchy[type2]) type1 else type2 }"},{"path":[]},{"path":"https://bbtheo.github.io/cuplyr/DEVELOPER_GUIDE.html","id":"recommended-approach-rcpp-with-xptr","dir":"","previous_headings":"6. Binding Strategy & C++ Glue","what":"Recommended Approach: Rcpp with XPtr","title":"cuplyr: GPU-Accelerated dplyr Backend via libcudf","text":"recommend Rcpp cpp11 project : 1. Better documented patterns external pointers 2. Existing examples CUDA integration 3. Mature finalizer support GPU memory cleanup","code":""},{"path":"https://bbtheo.github.io/cuplyr/DEVELOPER_GUIDE.html","id":"external-pointer-wrapper-pattern","dir":"","previous_headings":"6. Binding Strategy & C++ Glue","what":"External Pointer Wrapper Pattern","title":"cuplyr: GPU-Accelerated dplyr Backend via libcudf","text":"","code":"// src/gpu_table.hpp #ifndef CUPLYR_GPU_TABLE_HPP #define CUPLYR_GPU_TABLE_HPP  #include <Rcpp.h> #include <cudf/table/table.hpp> #include <cudf/table/table_view.hpp> #include <memory>  namespace cuplyr {  // Wrap cudf::table in a shared_ptr for R interop using GpuTablePtr = std::shared_ptr<cudf::table>;  // Custom destructor that ensures GPU cleanup inline void release_gpu_table(GpuTablePtr* ptr) {     if (ptr != nullptr) {         // Reset triggers cudf::table destructor, freeing GPU memory         ptr->reset();         delete ptr;     } }  // Create XPtr with custom destructor inline Rcpp::XPtr<GpuTablePtr> make_gpu_table_xptr(std::unique_ptr<cudf::table> tbl) {     // Convert unique_ptr to shared_ptr for R ownership     auto* sptr = new GpuTablePtr(std::move(tbl));     return Rcpp::XPtr<GpuTablePtr>(sptr, true);  // true = register destructor }  // Extract table_view from XPtr (non-owning view) inline cudf::table_view get_table_view(Rcpp::XPtr<GpuTablePtr> xptr) {     if (!xptr || !(*xptr)) {         Rcpp::stop(\"GPU table pointer is NULL\");     }     return (*xptr)->view(); }  // Get mutable table reference inline cudf::table& get_table_ref(Rcpp::XPtr<GpuTablePtr> xptr) {     if (!xptr || !(*xptr)) {         Rcpp::stop(\"GPU table pointer is NULL\");     }     return **xptr; }  } // namespace cuplyr  #endif // CUPLYR_GPU_TABLE_HPP"},{"path":"https://bbtheo.github.io/cuplyr/DEVELOPER_GUIDE.html","id":"data-transfer-r-dataframe--gpu","dir":"","previous_headings":"6. Binding Strategy & C++ Glue","what":"Data Transfer: R data.frame → GPU","title":"cuplyr: GPU-Accelerated dplyr Backend via libcudf","text":"","code":"// src/transfer_io.cpp #include \"gpu_table.hpp\" #include <cudf/column/column_factories.hpp> #include <cudf/types.hpp> #include <cudf/utilities/type_dispatcher.hpp> #include <rmm/device_buffer.hpp> #include <rmm/mr/device/per_device_resource.hpp>  #include <Rcpp.h>  using namespace Rcpp; using namespace cudf;  namespace cuplyr {  // Create GPU column from R numeric vector std::unique_ptr<column> numeric_to_gpu(NumericVector x) {     size_type n = x.size();      // Allocate device memory     rmm::device_buffer data(n * sizeof(double),                             rmm::cuda_stream_default,                             rmm::mr::get_current_device_resource());      // Copy from host to device     cudaMemcpy(data.data(), &x[0], n * sizeof(double), cudaMemcpyHostToDevice);      // Handle NAs by creating validity mask     rmm::device_buffer null_mask;     size_type null_count = 0;      // Check for NAs     std::vector<uint8_t> validity(bitmask_allocation_size_bytes(n), 0xFF);     for (size_type i = 0; i < n; ++i) {         if (NumericVector::is_na(x[i])) {             // Clear bit i             validity[i / 8] &= ~(1 << (i % 8));             null_count++;         }     }      if (null_count > 0) {         null_mask = rmm::device_buffer(validity.data(), validity.size(),                                        rmm::cuda_stream_default,                                        rmm::mr::get_current_device_resource());     }      return std::make_unique<column>(         data_type{type_id::FLOAT64},         n,         std::move(data),         std::move(null_mask),         null_count     ); }  // Create GPU column from R integer vector std::unique_ptr<column> integer_to_gpu(IntegerVector x) {     size_type n = x.size();      rmm::device_buffer data(n * sizeof(int32_t),                             rmm::cuda_stream_default,                             rmm::mr::get_current_device_resource());      cudaMemcpy(data.data(), &x[0], n * sizeof(int32_t), cudaMemcpyHostToDevice);      // Handle NAs     rmm::device_buffer null_mask;     size_type null_count = 0;     std::vector<uint8_t> validity(bitmask_allocation_size_bytes(n), 0xFF);      for (size_type i = 0; i < n; ++i) {         if (IntegerVector::is_na(x[i])) {             validity[i / 8] &= ~(1 << (i % 8));             null_count++;         }     }      if (null_count > 0) {         null_mask = rmm::device_buffer(validity.data(), validity.size(),                                        rmm::cuda_stream_default,                                        rmm::mr::get_current_device_resource());     }      return std::make_unique<column>(         data_type{type_id::INT32},         n,         std::move(data),         std::move(null_mask),         null_count     ); }  // Create GPU column from R character vector std::unique_ptr<column> character_to_gpu(CharacterVector x) {     size_type n = x.size();      // Convert to std::vector<std::string> for cudf factory     std::vector<std::string> strings(n);     std::vector<bool> valids(n, true);      for (size_type i = 0; i < n; ++i) {         if (CharacterVector::is_na(x[i])) {             valids[i] = false;             strings[i] = \"\";         } else {             strings[i] = as<std::string>(x[i]);         }     }      // Use cudf factory function     auto host_span = cudf::host_span<std::string const>(strings.data(), strings.size());     auto valid_span = cudf::host_span<bool const>(valids.data(), valids.size());      return cudf::make_strings_column(host_span, valid_span); }  } // namespace cuplyr  // [[Rcpp::export]] SEXP df_to_gpu(DataFrame df) {     using namespace cuplyr;      int ncol = df.size();     CharacterVector names = df.names();      std::vector<std::unique_ptr<cudf::column>> columns;     columns.reserve(ncol);      for (int i = 0; i < ncol; ++i) {         SEXP col = df[i];          switch (TYPEOF(col)) {             case REALSXP:                 columns.push_back(numeric_to_gpu(col));                 break;             case INTSXP:                 columns.push_back(integer_to_gpu(col));                 break;             case STRSXP:                 columns.push_back(character_to_gpu(col));                 break;             case LGLSXP:                 // Convert logical to integer then to BOOL8                 columns.push_back(integer_to_gpu(as<IntegerVector>(col)));                 break;             default:                 Rcpp::stop(\"Unsupported column type at index %d\", i);         }     }      auto tbl = std::make_unique<cudf::table>(std::move(columns));     return make_gpu_table_xptr(std::move(tbl)); }"},{"path":"https://bbtheo.github.io/cuplyr/DEVELOPER_GUIDE.html","id":"gpu--r-dataframe-transfer","dir":"","previous_headings":"6. Binding Strategy & C++ Glue","what":"GPU → R data.frame Transfer","title":"cuplyr: GPU-Accelerated dplyr Backend via libcudf","text":"","code":"// src/transfer_io.cpp (continued)  // [[Rcpp::export]] DataFrame gpu_to_df(SEXP xptr, CharacterVector names) {     using namespace cuplyr;      Rcpp::XPtr<GpuTablePtr> ptr(xptr);     cudf::table_view view = get_table_view(ptr);      int ncol = view.num_columns();     size_type nrow = view.num_rows();      List result(ncol);      for (int i = 0; i < ncol; ++i) {         cudf::column_view col = view.column(i);         cudf::type_id type = col.type().id();          switch (type) {             case cudf::type_id::FLOAT64: {                 NumericVector out(nrow);                 cudaMemcpy(&out[0], col.data<double>(),                           nrow * sizeof(double), cudaMemcpyDeviceToHost);                 // Handle nulls                 if (col.has_nulls()) {                     // Download validity mask and set NAs                     std::vector<uint8_t> validity(bitmask_allocation_size_bytes(nrow));                     cudaMemcpy(validity.data(), col.null_mask(),                               validity.size(), cudaMemcpyDeviceToHost);                     for (size_type j = 0; j < nrow; ++j) {                         if (!((validity[j/8] >> (j%8)) & 1)) {                             out[j] = NA_REAL;                         }                     }                 }                 result[i] = out;                 break;             }             case cudf::type_id::INT32: {                 IntegerVector out(nrow);                 cudaMemcpy(&out[0], col.data<int32_t>(),                           nrow * sizeof(int32_t), cudaMemcpyDeviceToHost);                 if (col.has_nulls()) {                     std::vector<uint8_t> validity(bitmask_allocation_size_bytes(nrow));                     cudaMemcpy(validity.data(), col.null_mask(),                               validity.size(), cudaMemcpyDeviceToHost);                     for (size_type j = 0; j < nrow; ++j) {                         if (!((validity[j/8] >> (j%8)) & 1)) {                             out[j] = NA_INTEGER;                         }                     }                 }                 result[i] = out;                 break;             }             case cudf::type_id::STRING: {                 // String columns require special handling                 auto str_col = cudf::strings_column_view(col);                 CharacterVector out(nrow);                 // Use cudf utility to get strings as host vector                 // This is simplified - real implementation would use                 // cudf::strings::detail functions                 result[i] = out;                 break;             }             default:                 Rcpp::stop(\"Unsupported column type for GPU->R transfer\");         }     }      result.names() = names;     result.attr(\"class\") = \"data.frame\";     result.attr(\"row.names\") = IntegerVector::create(NA_INTEGER, -nrow);      return result; }"},{"path":"https://bbtheo.github.io/cuplyr/DEVELOPER_GUIDE.html","id":"implementing-filter-in-c","dir":"","previous_headings":"6. Binding Strategy & C++ Glue","what":"Implementing filter() in C++","title":"cuplyr: GPU-Accelerated dplyr Backend via libcudf","text":"","code":"// src/filter.cpp #include \"gpu_table.hpp\" #include <cudf/stream_compaction.hpp> #include <cudf/binaryop.hpp> #include <cudf/column/column_factories.hpp> #include <cudf/scalar/scalar_factories.hpp>  // [[Rcpp::export]] SEXP gpu_filter_gt(SEXP xptr, int col_idx, double value) {     using namespace cuplyr;      Rcpp::XPtr<GpuTablePtr> ptr(xptr);     cudf::table_view view = get_table_view(ptr);      // Get the column to filter on (0-indexed)     cudf::column_view filter_col = view.column(col_idx);      // Create scalar for comparison     auto scalar = cudf::make_numeric_scalar(cudf::data_type{cudf::type_id::FLOAT64});     scalar->set_valid_async(true);     static_cast<cudf::numeric_scalar<double>*>(scalar.get())->set_value(value);      // Create boolean mask: col > value     auto mask = cudf::binary_operation(         filter_col,         *scalar,         cudf::binary_operator::GREATER,         cudf::data_type{cudf::type_id::BOOL8}     );      // Apply boolean mask to filter table     auto result = cudf::apply_boolean_mask(view, mask->view());      return make_gpu_table_xptr(std::move(result)); }  // More flexible filter with expression support // [[Rcpp::export]] SEXP gpu_filter_mask(SEXP tbl_xptr, SEXP mask_xptr, int mask_col_idx) {     using namespace cuplyr;      Rcpp::XPtr<GpuTablePtr> tbl_ptr(tbl_xptr);     Rcpp::XPtr<GpuTablePtr> mask_ptr(mask_xptr);      cudf::table_view tbl_view = get_table_view(tbl_ptr);     cudf::table_view mask_view = get_table_view(mask_ptr);      // Get boolean column from mask table     cudf::column_view bool_mask = mask_view.column(mask_col_idx);      auto result = cudf::apply_boolean_mask(tbl_view, bool_mask);     return make_gpu_table_xptr(std::move(result)); }"},{"path":"https://bbtheo.github.io/cuplyr/DEVELOPER_GUIDE.html","id":"compilation-setup","dir":"","previous_headings":"6. Binding Strategy & C++ Glue","what":"Compilation Setup","title":"cuplyr: GPU-Accelerated dplyr Backend via libcudf","text":"","code":"# src/Makevars.in (template - configure will generate Makevars)  # Paths set by configure CUDA_HOME = @CUDA_HOME@ CUDF_INCLUDE = @CUDF_INCLUDE@ CUDF_LIB = @CUDF_LIB@ RMM_INCLUDE = @RMM_INCLUDE@  # Compiler settings CXX_STD = CXX17 PKG_CXXFLAGS = -I$(CUDF_INCLUDE) -I$(RMM_INCLUDE) -I$(CUDA_HOME)/include \\                -DFMT_HEADER_ONLY $(SHLIB_OPENMP_CXXFLAGS)  PKG_LIBS = -L$(CUDF_LIB) -lcudf -L$(CUDA_HOME)/lib64 -lcudart \\            $(SHLIB_OPENMP_CXXFLAGS) -Wl,-rpath,$(CUDF_LIB)  # Ensure nvcc is not used for R package compilation # All CUDA code is in libcudf; we only link against it"},{"path":[]},{"path":"https://bbtheo.github.io/cuplyr/DEVELOPER_GUIDE.html","id":"quick-start-with-pixi-recommended","dir":"","previous_headings":"7. Build System & Packaging","what":"Quick Start with pixi (Recommended)","title":"cuplyr: GPU-Accelerated dplyr Backend via libcudf","text":"recommended way set development environment using pixi, provides fast, reproducible dependency management RAPIDS C++ libraries. One-time setup: Development workflow (local loop): Available pixi tasks: pixi.lock file ensures reproducible builds across machines. Commit version control. Header drift note: environment bitmask_allocation_size_bytes lives cudf/null_mask.hpp. cudf header missing, search include tree $CONDA_PREFIX/include/cudf.","code":"# Install pixi curl -fsSL https://pixi.sh/install.sh | bash  # Install direnv for auto-activation (optional but recommended) sudo pacman -S direnv  # Arch # or: sudo apt install direnv  # Ubuntu/Debian  # Add to ~/.bashrc or ~/.zshrc echo 'eval \"$(direnv hook bash)\"' >> ~/.bashrc source ~/.bashrc  # In the project directory direnv allow . cd cuplyr                    # Environment auto-activates via direnv  pixi run configure          # Regenerate Makevars when paths change pixi run install            # Rebuild package after C++ changes pixi run load-dev           # Fast reload for R-only changes pixi run test               # Run test suite pixi run bench              # Run benchmarks pixi run check              # R CMD check"},{"path":"https://bbtheo.github.io/cuplyr/DEVELOPER_GUIDE.html","id":"description-file","dir":"","previous_headings":"7. Build System & Packaging","what":"DESCRIPTION File","title":"cuplyr: GPU-Accelerated dplyr Backend via libcudf","text":"","code":"Package: cuplyr Title: GPU-Accelerated Data Manipulation with dplyr Syntax Version: 0.0.1 Authors@R: c(     person(\"Theo\", \"Blauberg\", email = \"theo.blauberg@outlook.com\", role = c(\"aut\", \"cre\")),     person(\"RAPIDS Team\", role = \"cph\", comment = \"libcudf library\")   ) Description: Provides a dplyr backend that executes operations on NVIDIA GPUs     using the RAPIDS libcudf library. Supports filter, select, mutate, arrange,     group_by, summarise, and join operations with familiar tidyverse syntax     while achieving significant speedups on large datasets. License: Apache License (>= 2) URL: https://github.com/bbtheo/cuplyr BugReports: https://github.com/bbtheo/cuplyr/issues Encoding: UTF-8 Roxygen: list(markdown = TRUE) RoxygenNote: 7.3.3 SystemRequirements:     NVIDIA GPU with Compute Capability >= 6.0,     CUDA Toolkit >= 12.0,     RAPIDS libcudf >= 25.12 Depends:     R (>= 4.3.0) Imports:     Rcpp (>= 1.0.12),     dplyr (>= 1.1.0),     rlang (>= 1.1.0),     vctrs (>= 0.6.0),     pillar (>= 1.9.0),     glue (>= 1.6.0),     cli (>= 3.6.0),     tidyselect (>= 1.2.0),     tibble (>= 3.2.0) Suggests:     testthat (>= 3.0.0),     bench,     arrow,     nanoarrow,     bit64,     reticulate LinkingTo:     Rcpp Config/testthat/edition: 3 NeedsCompilation: yes"},{"path":"https://bbtheo.github.io/cuplyr/DEVELOPER_GUIDE.html","id":"namespace-file","dir":"","previous_headings":"7. Build System & Packaging","what":"NAMESPACE File","title":"cuplyr: GPU-Accelerated dplyr Backend via libcudf","text":"","code":"# Generated by roxygen2: do not edit by hand  # Generated by roxygen2: do not edit by hand  S3method(\"names<-\",tbl_gpu) S3method(collect,tbl_gpu) S3method(dim,tbl_gpu) S3method(filter,tbl_gpu) S3method(group_by,tbl_gpu) S3method(group_vars,tbl_gpu) S3method(groups,tbl_gpu) S3method(mutate,tbl_gpu) S3method(names,tbl_gpu) S3method(print,tbl_gpu) S3method(select,tbl_gpu) S3method(summarise,tbl_gpu) S3method(summarize,tbl_gpu) S3method(tbl_gpu,data.frame) S3method(tbl_gpu,tbl_gpu) S3method(ungroup,tbl_gpu) export(as_tbl_gpu) export(gpu_details) export(gpu_memory_state) export(gpu_memory_usage) export(gpu_object_info) export(gpu_size_comparison) export(has_gpu) export(is_tbl_gpu) export(show_gpu) export(tbl_gpu) export(verify_gpu_data) importFrom(Rcpp,sourceCpp) importFrom(dplyr,collect) importFrom(dplyr,filter) importFrom(dplyr,group_by) importFrom(dplyr,group_vars) importFrom(dplyr,groups) importFrom(dplyr,mutate) importFrom(dplyr,select) importFrom(dplyr,summarise) importFrom(dplyr,summarize) importFrom(dplyr,ungroup) importFrom(rlang,\"%||%\") useDynLib(cuplyr, .registration = TRUE)"},{"path":"https://bbtheo.github.io/cuplyr/DEVELOPER_GUIDE.html","id":"configure-script","dir":"","previous_headings":"7. Build System & Packaging","what":"Configure Script","title":"cuplyr: GPU-Accelerated dplyr Backend via libcudf","text":"","code":"#!/bin/bash # configure - Detect CUDA and libcudf, generate src/Makevars  echo \"Configuring cuplyr...\"  # Default paths CUDA_HOME=\"${CUDA_HOME:-/usr/local/cuda}\" CUDF_HOME=\"${CUDF_HOME:-}\" CONDA_PREFIX=\"${CONDA_PREFIX:-}\"  # Function to find libcudf find_cudf() {     # Try conda environment first     if [ -n \"$CONDA_PREFIX\" ] && [ -f \"$CONDA_PREFIX/include/cudf/cudf.hpp\" ]; then         echo \"$CONDA_PREFIX\"         return 0     fi      # Try common installation paths     for path in /usr/local /opt/rapids /usr; do         if [ -f \"$path/include/cudf/cudf.hpp\" ]; then             echo \"$path\"             return 0         fi     done      # Check if CUDF_HOME is set     if [ -n \"$CUDF_HOME\" ] && [ -f \"$CUDF_HOME/include/cudf/cudf.hpp\" ]; then         echo \"$CUDF_HOME\"         return 0     fi      return 1 }  # Detect CUDA if [ ! -d \"$CUDA_HOME\" ]; then     # Try to find CUDA     for cuda_path in /usr/local/cuda /opt/cuda /usr/lib/cuda; do         if [ -d \"$cuda_path\" ] && [ -f \"$cuda_path/include/cuda.h\" ]; then             CUDA_HOME=\"$cuda_path\"             break         fi     done fi  if [ ! -f \"$CUDA_HOME/include/cuda.h\" ]; then     echo \"ERROR: CUDA not found. Please set CUDA_HOME environment variable.\"     echo \"       Example: export CUDA_HOME=/usr/local/cuda\"     exit 1 fi  echo \"Found CUDA at: $CUDA_HOME\" echo \"CUDA version: $($CUDA_HOME/bin/nvcc --version | grep release | awk '{print $6}')\"  # Detect libcudf CUDF_PREFIX=$(find_cudf) if [ -z \"$CUDF_PREFIX\" ]; then     echo \"ERROR: libcudf not found. Please install RAPIDS or set CUDF_HOME.\"     echo \"\"     echo \"Installation options:\"     echo \"  1. Conda: conda install -c rapidsai -c conda-forge -c nvidia libcudf\"     echo \"  2. Pip:   pip install libcudf-cu12\"     echo \"  3. Set:   export CUDF_HOME=/path/to/cudf\"     exit 1 fi  CUDF_INCLUDE=\"$CUDF_PREFIX/include\" CUDF_LIB=\"$CUDF_PREFIX/lib\"  echo \"Found libcudf at: $CUDF_PREFIX\"  # Check for RMM (RAPIDS Memory Manager) if [ -f \"$CUDF_PREFIX/include/rmm/rmm.hpp\" ]; then     RMM_INCLUDE=\"$CUDF_PREFIX/include\" else     RMM_INCLUDE=\"$CUDF_INCLUDE\" fi  # Verify libcudf shared library exists if [ ! -f \"$CUDF_LIB/libcudf.so\" ]; then     echo \"WARNING: libcudf.so not found in $CUDF_LIB\"     echo \"         Package may fail to load at runtime.\" fi  # Generate Makevars from template sed -e \"s|@CUDA_HOME@|$CUDA_HOME|g\" \\     -e \"s|@CUDF_INCLUDE@|$CUDF_INCLUDE|g\" \\     -e \"s|@CUDF_LIB@|$CUDF_LIB|g\" \\     -e \"s|@RMM_INCLUDE@|$RMM_INCLUDE|g\" \\     src/Makevars.in > src/Makevars  echo \"\" echo \"Configuration complete. Generated src/Makevars:\" cat src/Makevars echo \"\" echo \"Run 'R CMD INSTALL .' to build the package.\""},{"path":"https://bbtheo.github.io/cuplyr/DEVELOPER_GUIDE.html","id":"dockerfile","dir":"","previous_headings":"7. Build System & Packaging","what":"Dockerfile","title":"cuplyr: GPU-Accelerated dplyr Backend via libcudf","text":"","code":"# Dockerfile for cuplyr development and CI # Based on RAPIDS CUDA 12 developer image  ARG RAPIDS_VERSION=25.12 ARG CUDA_VERSION=12.5 ARG UBUNTU_VERSION=22.04  FROM nvcr.io/nvidia/rapidsai/base:${RAPIDS_VERSION}-cuda${CUDA_VERSION}-py3.11-amd64  LABEL maintainer=\"your@email.com\" LABEL description=\"cuplyr development environment with RAPIDS libcudf\"  # Install system dependencies RUN apt-get update && apt-get install -y --no-install-recommends \\     software-properties-common \\     dirmngr \\     gnupg \\     libcurl4-openssl-dev \\     libssl-dev \\     libxml2-dev \\     libfontconfig1-dev \\     libharfbuzz-dev \\     libfribidi-dev \\     libfreetype6-dev \\     libpng-dev \\     libtiff5-dev \\     libjpeg-dev \\     && rm -rf /var/lib/apt/lists/*  # Add R repository and install R RUN wget -qO- https://cloud.r-project.org/bin/linux/ubuntu/marutter_pubkey.asc | \\     gpg --dearmor -o /usr/share/keyrings/r-project.gpg && \\     echo \"deb [signed-by=/usr/share/keyrings/r-project.gpg] https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/\" > \\     /etc/apt/sources.list.d/r-project.list && \\     apt-get update && \\     apt-get install -y --no-install-recommends \\     r-base \\     r-base-dev \\     && rm -rf /var/lib/apt/lists/*  # Install R package dependencies RUN R -e \"install.packages(c( \\     'Rcpp', 'dplyr', 'rlang', 'vctrs', 'pillar', 'glue', 'cli', \\     'testthat', 'bench', 'arrow', 'nanoarrow', 'bit64', 'reticulate', \\     'devtools', 'roxygen2', 'pkgdown' \\ ), repos='https://cloud.r-project.org')\"  # Set environment variables for cuplyr build ENV CUDA_HOME=/usr/local/cuda ENV CUDF_HOME=/opt/conda ENV LD_LIBRARY_PATH=/opt/conda/lib:${LD_LIBRARY_PATH}  # Create working directory WORKDIR /cuplyr  # Copy package source COPY . /cuplyr  # Configure and build RUN chmod +x configure && \\     ./configure && \\     R CMD INSTALL .  # Run tests by default CMD [\"R\", \"-e\", \"testthat::test_package('cuplyr')\"]"},{"path":"https://bbtheo.github.io/cuplyr/DEVELOPER_GUIDE.html","id":"github-actions-ci","dir":"","previous_headings":"7. Build System & Packaging","what":"GitHub Actions CI","title":"cuplyr: GPU-Accelerated dplyr Backend via libcudf","text":"","code":"# .github/workflows/ci.yml name: CI  on:   push:     branches: [main, develop]   pull_request:     branches: [main]  jobs:   build:     runs-on: ubuntu-latest     container:       image: nvcr.io/nvidia/rapidsai/base:25.12-cuda12.5-py3.11-amd64       options: --gpus all      steps:       - uses: actions/checkout@v4        - name: Install R         run: |           apt-get update           apt-get install -y software-properties-common           wget -qO- https://cloud.r-project.org/bin/linux/ubuntu/marutter_pubkey.asc | \\             gpg --dearmor -o /usr/share/keyrings/r-project.gpg           echo \"deb [signed-by=/usr/share/keyrings/r-project.gpg] https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/\" > \\             /etc/apt/sources.list.d/r-project.list           apt-get update           apt-get install -y r-base r-base-dev libcurl4-openssl-dev libssl-dev libxml2-dev        - name: Install R dependencies         run: |           R -e \"install.packages(c('Rcpp', 'dplyr', 'rlang', 'vctrs', 'pillar', 'glue', 'cli', 'testthat', 'bench'), repos='https://cloud.r-project.org')\"        - name: Configure         run: |           export CUDA_HOME=/usr/local/cuda           export CUDF_HOME=/opt/conda           chmod +x configure           ./configure        - name: Build package         run: R CMD build .        - name: Check package         run: R CMD check cuplyr_*.tar.gz --no-manual        - name: Install package         run: R CMD INSTALL cuplyr_*.tar.gz        - name: Run tests         run: R -e \"testthat::test_package('cuplyr')\"    benchmark:     needs: build     runs-on: ubuntu-latest     container:       image: nvcr.io/nvidia/rapidsai/base:25.12-cuda12.5-py3.11-amd64       options: --gpus all      steps:       - uses: actions/checkout@v4        - name: Setup (same as build job)         run: |           # ... same setup steps ...           echo \"Setup complete\"        - name: Run benchmarks         run: |           R -e \"source('inst/benchmarks/run_benchmarks.R')\"        - name: Upload benchmark results         uses: actions/upload-artifact@v4         with:           name: benchmark-results           path: inst/benchmarks/results/"},{"path":[]},{"path":"https://bbtheo.github.io/cuplyr/DEVELOPER_GUIDE.html","id":"directory-structure","dir":"","previous_headings":"8. Minimal Working Prototype","what":"Directory Structure","title":"cuplyr: GPU-Accelerated dplyr Backend via libcudf","text":"","code":"cuplyr/ ├── DESCRIPTION ├── NAMESPACE ├── LICENSE ├── configure ├── R/ │   ├── zzz.R │   ├── tbl-gpu.R │   ├── collect.R │   ├── filter.R │   ├── mutate.R │   ├── select.R │   ├── group-by.R │   ├── summarise.R │   ├── gpu.R │   ├── gpu-memory.R │   ├── print.R │   └── utils.R ├── src/ │   ├── Makevars.in │   ├── gpu_table.hpp │   ├── cuda_utils.hpp │   ├── ops_common.hpp │   ├── transfer_io.cpp │   ├── ops_filter.cpp │   ├── ops_compare.cpp │   ├── ops_mutate.cpp │   ├── ops_select.cpp │   ├── ops_groupby.cpp │   ├── gpu_info.cpp │   └── RcppExports.cpp ├── inst/ │   ├── docker/ │   │   └── Dockerfile ├── tests/ │   └── testthat/ │       ├── test-basic.R │       ├── test-filter.R │       ├── test-mutate.R │       └── helper-cuplyr.R └── man/     └── (generated by roxygen2)"},{"path":"https://bbtheo.github.io/cuplyr/DEVELOPER_GUIDE.html","id":"rzzzr---package-load-hook","dir":"","previous_headings":"8. Minimal Working Prototype","what":"R/zzz.R - Package Load Hook","title":"cuplyr: GPU-Accelerated dplyr Backend via libcudf","text":"","code":"#' @useDynLib cuplyr, .registration = TRUE #' @importFrom Rcpp sourceCpp NULL  .onLoad <- function(libname, pkgname) {   # Check GPU availability   gpu_ok <- tryCatch(     gpu_is_available(),     error = function(e) FALSE   )    # Set package options   op <- options()   op.cuplyr <- list(     cuplyr.verbose = FALSE,     cuplyr.lazy = TRUE,     cuplyr.gpu_available = gpu_ok   )   toset <- !(names(op.cuplyr) %in% names(op))   if (any(toset)) options(op.cuplyr[toset])    invisible() }  .onAttach <- function(libname, pkgname) {   info <- tryCatch(gpu_info(), error = function(e) list(available = FALSE))    if (isTRUE(info$available)) {     total_gb <- round(info$total_memory / 1e9, 1)     free_gb <- round(info$free_memory / 1e9, 1)      msg <- paste0(       \"cuplyr: GPU-accelerated data manipulation\\n\",       \"GPU: \", info$name, \" (\", info$compute_capability, \")\\n\",       \"Memory: \", free_gb, \" GB free / \", total_gb, \" GB total\"     )   } else {     msg <- paste0(       \"cuplyr: GPU-accelerated data manipulation\\n\",       \"WARNING: No GPU detected. Package will not function correctly.\"     )   }    packageStartupMessage(msg) }"},{"path":"https://bbtheo.github.io/cuplyr/DEVELOPER_GUIDE.html","id":"rtbl-gpur---core-class","dir":"","previous_headings":"8. Minimal Working Prototype","what":"R/tbl-gpu.R - Core Class","title":"cuplyr: GPU-Accelerated dplyr Backend via libcudf","text":"","code":"#' Create a GPU-backed tibble #' #' @param data A data frame to transfer to GPU memory #' @param ... Additional arguments (unused) #' @return A `tbl_gpu` object #' @export #' @examples #' if (interactive()) { #'   df <- data.frame(x = 1:1000, y = rnorm(1000)) #'   gpu_df <- tbl_gpu(df) #'   gpu_df #' } tbl_gpu <- function(data, ...) {   UseMethod(\"tbl_gpu\") }  #' @export tbl_gpu.data.frame <- function(data, ...) {   # Transfer to GPU   ptr <- .Call(`_cuplyr_df_to_gpu`, data)    schema <- list(     names = names(data),     types = vapply(data, gpu_type_from_r, character(1))   )    new_tbl_gpu(ptr = ptr, schema = schema) }  #' @export tbl_gpu.tbl_gpu <- function(data, ...) {   data }  # Internal constructor new_tbl_gpu <- function(ptr = NULL,                         schema = list(names = character(), types = character()),                         lazy_ops = list(),                         groups = character()) {   structure(     list(       ptr = ptr,       schema = schema,       lazy_ops = lazy_ops,       groups = groups     ),     class = c(\"tbl_gpu\", \"tbl_lazy\", \"tbl\")   ) }  #' @export is_tbl_gpu <- function(x) {   inherits(x, \"tbl_gpu\") }  #' @export as_tbl_gpu <- function(x, ...) {   tbl_gpu(x, ...) }  # Print method #' @export print.tbl_gpu <- function(x, ..., n = 10) {   cat(\"# A GPU tibble: \")    if (is.null(x$ptr)) {     cat(\"[lazy, not materialized]\\n\")     cat(\"# Schema: \", paste(x$schema$names, collapse = \", \"), \"\\n\")     cat(\"# Operations pending: \", length(x$lazy_ops), \"\\n\")   } else {     dims <- dim(x)     cat(format(dims[1], big.mark = \",\"), \" x \", dims[2], \"\\n\", sep = \"\")      if (length(x$groups) > 0) {       cat(\"# Groups: \", paste(x$groups, collapse = \", \"), \"\\n\")     }      # Show first n rows     preview <- head(collect(x), n)     print(tibble::as_tibble(preview))      if (dims[1] > n) {       cat(\"# ... with \", format(dims[1] - n, big.mark = \",\"),           \" more rows\\n\", sep = \"\")     }   }    invisible(x) }  #' @export dim.tbl_gpu <- function(x) {   if (is.null(x$ptr)) {     c(NA_integer_, length(x$schema$names))   } else {     .Call(`_cuplyr_gpu_dim`, x$ptr)   } }  #' @export names.tbl_gpu <- function(x) {   x$schema$names }  #' @export `names<-.tbl_gpu` <- function(x, value) {   x$schema$names <- value   x }  # Type helper gpu_type_from_r <- function(x) {   if (is.logical(x)) return(\"BOOL8\")   if (is.integer(x)) return(\"INT32\")   if (is.double(x)) {     if (inherits(x, \"Date\")) return(\"TIMESTAMP_DAYS\")     if (inherits(x, \"POSIXct\")) return(\"TIMESTAMP_MICROSECONDS\")     return(\"FLOAT64\")   }   if (is.character(x)) return(\"STRING\")   if (is.factor(x)) return(\"INT32\")   if (inherits(x, \"integer64\")) return(\"INT64\")   \"UNKNOWN\" }"},{"path":"https://bbtheo.github.io/cuplyr/DEVELOPER_GUIDE.html","id":"rfilterr","dir":"","previous_headings":"8. Minimal Working Prototype","what":"R/filter.R","title":"cuplyr: GPU-Accelerated dplyr Backend via libcudf","text":"","code":"#' @importFrom dplyr filter #' @export filter.tbl_gpu <- function(.data, ..., .preserve = FALSE) {   dots <- rlang::enquos(...)    if (length(dots) == 0) return(.data)    result <- .data   for (expr in dots) {     result <- filter_one(result, expr)   }    result }  filter_one <- function(.data, expr) {   expr_chr <- rlang::quo_text(expr)    eval_result <- tryCatch({     rlang::eval_tidy(expr)   }, error = function(e) NULL)    if (!is.null(eval_result) && is.logical(eval_result)) {     return(filter_logical(.data, eval_result))   }    ops <- c(\"==\", \"!=\", \">=\", \"<=\", \">\", \"<\")   op_found <- NULL   for (op in ops) {     if (grepl(op, expr_chr, fixed = TRUE)) {       op_found <- op       break     }   }    if (is.null(op_found)) {     stop(\"filter() only supports comparisons: ==, !=, >, >=, <, <=\",          call. = FALSE)   }    parts <- strsplit(expr_chr, op_found, fixed = TRUE)[[1]]   lhs <- trimws(parts[1])   rhs <- trimws(parts[2])    lhs_idx <- tryCatch(col_index(.data, lhs), error = function(e) NULL)   rhs_idx <- tryCatch(col_index(.data, rhs), error = function(e) NULL)    if (is.null(lhs_idx)) {     stop(\"Column '\", lhs, \"' not found.\", call. = FALSE)   }    if (!is.null(rhs_idx)) {     new_ptr <- gpu_filter_col(.data$ptr, lhs_idx, op_found, rhs_idx)   } else {     value <- tryCatch(eval(parse(text = rhs)), error = function(e) {       stop(\"Cannot parse value: \", rhs, call. = FALSE)     })     new_ptr <- gpu_filter_scalar(.data$ptr, lhs_idx, op_found, as.double(value))   }    new_tbl_gpu(ptr = new_ptr, schema = .data$schema, groups = .data$groups) }"},{"path":"https://bbtheo.github.io/cuplyr/DEVELOPER_GUIDE.html","id":"rcollectr","dir":"","previous_headings":"8. Minimal Working Prototype","what":"R/collect.R","title":"cuplyr: GPU-Accelerated dplyr Backend via libcudf","text":"","code":"#' @export collect.tbl_gpu <- function(x, ...) {   if (is.null(x$ptr)) {     stop(\"Cannot collect: GPU table pointer is NULL.\", call. = FALSE)   }    df <- gpu_collect(x$ptr, x$schema$names)   result <- tibble::as_tibble(df)    if (any(x$schema$types == \"INT64\")) {     int64_cols <- which(x$schema$types == \"INT64\")     for (col_idx in int64_cols) {       col_name <- x$schema$names[col_idx]       values <- result[[col_name]]       if (is.numeric(values) && any(abs(values) > 2^53, na.rm = TRUE)) {         warning(           \"INT64 values may lose precision when collected into R numeric vectors.\",           call. = FALSE         )         break       }     }   }    result }"},{"path":"https://bbtheo.github.io/cuplyr/DEVELOPER_GUIDE.html","id":"rcppexportscpp---registration","dir":"","previous_headings":"8. Minimal Working Prototype","what":"RcppExports.cpp - Registration","title":"cuplyr: GPU-Accelerated dplyr Backend via libcudf","text":"Registration auto-generated Rcpp. hand-written src/init.cpp. Whenever add move // [[Rcpp::export]] functions, run:","code":"Rcpp::compileAttributes()"},{"path":"https://bbtheo.github.io/cuplyr/DEVELOPER_GUIDE.html","id":"teststestthat-examples","dir":"","previous_headings":"8. Minimal Working Prototype","what":"tests/testthat/ (examples)","title":"cuplyr: GPU-Accelerated dplyr Backend via libcudf","text":"","code":"test_that(\"tbl_gpu can be created from data.frame\", {   skip_if_no_gpu()    df <- data.frame(x = 1:5, y = 6:10)   gpu_df <- tbl_gpu(df)    expect_valid_tbl_gpu(gpu_df)   expect_equal(dim(gpu_df), c(5L, 2L)) })  test_that(\"filter works with simple comparisons\", {   skip_if_no_gpu()    df <- data.frame(x = 1:10, y = 11:20)   gpu_df <- tbl_gpu(df)    result <- collect(dplyr::filter(gpu_df, x > 5))   expected <- dplyr::filter(df, x > 5)    expect_equal(result$x, expected$x)   expect_equal(result$y, expected$y) })"},{"path":"https://bbtheo.github.io/cuplyr/DEVELOPER_GUIDE.html","id":"id_9-roadmap-lazy-translation--ast-approach-not-implemented","dir":"","previous_headings":"","what":"9. Roadmap: Lazy Translation & AST Approach (Not Implemented)","title":"cuplyr: GPU-Accelerated dplyr Backend via libcudf","text":"section forward-looking design. current codebase ship AST files (R/ast.R, R/optimizer.R, R/lower.R) execute lazily. Keep notes future work .","code":""},{"path":"https://bbtheo.github.io/cuplyr/DEVELOPER_GUIDE.html","id":"ast-node-definitions","dir":"","previous_headings":"9. Roadmap: Lazy Translation & AST Approach (Not Implemented)","what":"AST Node Definitions","title":"cuplyr: GPU-Accelerated dplyr Backend via libcudf","text":"","code":"# R/ast.R - Internal AST representation  # Base AST node ast_node <- function(type, ...) {   structure(     list(type = type, ...),     class = c(paste0(\"ast_\", type), \"ast_node\")   ) }  # Operation nodes ast_filter <- function(predicates) {   ast_node(\"filter\", predicates = predicates) }  ast_select <- function(columns) {   ast_node(\"select\", columns = columns) }  ast_mutate <- function(expressions) {   ast_node(\"mutate\", expressions = expressions) }  ast_arrange <- function(columns, descending) {   ast_node(\"arrange\", columns = columns, descending = descending) }  ast_group_by <- function(columns) {   ast_node(\"group_by\", columns = columns) }  ast_summarise <- function(aggregations) {   ast_node(\"summarise\", aggregations = aggregations) }  ast_join <- function(type, right_table, by) {   ast_node(\"join\", join_type = type, right = right_table, by = by) }  # Expression nodes (for predicates and computations) ast_binary_op <- function(op, left, right) {   ast_node(\"binary_op\", operator = op, left = left, right = right) }  ast_column_ref <- function(name) {   ast_node(\"column_ref\", name = name) }  ast_literal <- function(value) {   ast_node(\"literal\", value = value) }  ast_function_call <- function(fn, args) {   ast_node(\"function_call\", fn = fn, args = args) }"},{"path":"https://bbtheo.github.io/cuplyr/DEVELOPER_GUIDE.html","id":"expression-parser","dir":"","previous_headings":"9. Roadmap: Lazy Translation & AST Approach (Not Implemented)","what":"Expression Parser","title":"cuplyr: GPU-Accelerated dplyr Backend via libcudf","text":"","code":"# R/parse_expr.R - Parse R expressions to AST  parse_expr_to_ast <- function(expr, env = parent.frame()) {   if (is.symbol(expr)) {     # Column reference     return(ast_column_ref(as.character(expr)))   }    if (is.atomic(expr) && length(expr) == 1) {     # Literal value     return(ast_literal(expr))   }    if (is.call(expr)) {     fn <- as.character(expr[[1]])      # Binary operators     if (fn %in% c(\"+\", \"-\", \"*\", \"/\", \"^\", \"%%\", \"%/%\",                   \">\", \">=\", \"<\", \"<=\", \"==\", \"!=\",                   \"&\", \"|\")) {       left <- parse_expr_to_ast(expr[[2]], env)       right <- parse_expr_to_ast(expr[[3]], env)       return(ast_binary_op(fn, left, right))     }      # Unary operators     if (fn == \"!\" && length(expr) == 2) {       return(ast_node(\"unary_op\", operator = \"!\", operand = parse_expr_to_ast(expr[[2]], env)))     }      # Function calls     args <- lapply(expr[-1], parse_expr_to_ast, env = env)     return(ast_function_call(fn, args))   }    cli::cli_abort(\"Cannot parse expression: {deparse(expr)}\") }  # Convert quosure to AST quosure_to_ast <- function(quo) {   expr <- rlang::quo_get_expr(quo)   env <- rlang::quo_get_env(quo)   parse_expr_to_ast(expr, env) }"},{"path":"https://bbtheo.github.io/cuplyr/DEVELOPER_GUIDE.html","id":"query-optimizer","dir":"","previous_headings":"9. Roadmap: Lazy Translation & AST Approach (Not Implemented)","what":"Query Optimizer","title":"cuplyr: GPU-Accelerated dplyr Backend via libcudf","text":"","code":"# R/optimizer.R - AST optimization passes  optimize_ast <- function(ops) {   ops <- push_down_filters(ops)   ops <- push_down_projections(ops)   ops <- fuse_consecutive_filters(ops)   ops }  # Predicate pushdown: move filters earlier in pipeline push_down_filters <- function(ops) {   if (length(ops) < 2) return(ops)    result <- list()   pending_filters <- list()    for (op in ops) {     if (op$type == \"filter\") {       # Collect filter predicates       pending_filters <- c(pending_filters, op$predicates)     } else if (op$type %in% c(\"select\", \"mutate\")) {       # Can push filters before select/mutate if columns exist       if (length(pending_filters) > 0) {         # Check which predicates can be pushed         pushable <- vapply(pending_filters, function(pred) {           cols <- extract_column_refs(pred)           # All referenced columns must exist before this op           TRUE  # Simplified - real implementation checks column existence         }, logical(1))          if (any(pushable)) {           result <- c(result, list(ast_filter(pending_filters[pushable])))           pending_filters <- pending_filters[!pushable]         }       }       result <- c(result, list(op))     } else {       # Flush pending filters       if (length(pending_filters) > 0) {         result <- c(result, list(ast_filter(pending_filters)))         pending_filters <- list()       }       result <- c(result, list(op))     }   }    # Flush remaining filters   if (length(pending_filters) > 0) {     result <- c(result, list(ast_filter(pending_filters)))   }    result }  # Projection pushdown: only read needed columns push_down_projections <- function(ops) {   # Analyze which columns are used by each operation   # Remove unused columns early   ops  # Placeholder - full implementation tracks column usage }  # Fuse consecutive filters into single operation fuse_consecutive_filters <- function(ops) {   if (length(ops) < 2) return(ops)    result <- list()   i <- 1    while (i <= length(ops)) {     if (ops[[i]]$type == \"filter\") {       # Collect consecutive filters       predicates <- ops[[i]]$predicates       while (i < length(ops) && ops[[i + 1]]$type == \"filter\") {         i <- i + 1         predicates <- c(predicates, ops[[i]]$predicates)       }       result <- c(result, list(ast_filter(predicates)))     } else {       result <- c(result, list(ops[[i]]))     }     i <- i + 1   }    result }  # Extract column references from AST node extract_column_refs <- function(node) {   if (inherits(node, \"ast_column_ref\")) {     return(node$name)   }   if (is.list(node)) {     unlist(lapply(node, extract_column_refs))   } else {     character(0)   } }"},{"path":"https://bbtheo.github.io/cuplyr/DEVELOPER_GUIDE.html","id":"lowering-ast-to-libcudf-calls","dir":"","previous_headings":"9. Roadmap: Lazy Translation & AST Approach (Not Implemented)","what":"Lowering AST to libcudf Calls","title":"cuplyr: GPU-Accelerated dplyr Backend via libcudf","text":"","code":"# R/lower.R - Convert AST to libcudf operations  lower_to_cudf <- function(tbl, ops) {   if (getOption(\"cuplyr.verbose\", FALSE)) {     message(\"cuplyr: Lowering \", length(ops), \" operations to libcudf\")   }    for (op in ops) {     tbl <- lower_op(tbl, op)   }    tbl }  lower_op <- function(tbl, op) {   if (getOption(\"cuplyr.verbose\", FALSE)) {     message(\"  -> \", op$type)   }    switch(op$type,     \"filter\" = lower_filter(tbl, op),     \"select\" = lower_select(tbl, op),     \"mutate\" = lower_mutate(tbl, op),     \"arrange\" = lower_arrange(tbl, op),     \"group_by\" = lower_group_by(tbl, op),     \"summarise\" = lower_summarise(tbl, op),     \"join\" = lower_join(tbl, op),     cli::cli_abort(\"Cannot lower operation: {op$type}\")   ) }  lower_filter <- function(tbl, op) {   # Build combined boolean mask from all predicates   mask_ptr <- NULL    for (pred in op$predicates) {     pred_mask <- evaluate_predicate(tbl, pred)     if (is.null(mask_ptr)) {       mask_ptr <- pred_mask     } else {       # AND masks together       mask_ptr <- .Call(`_cuplyr_gpu_and_masks`, mask_ptr, pred_mask)     }   }    new_ptr <- .Call(`_cuplyr_gpu_apply_mask`, tbl$ptr, mask_ptr)    new_tbl_gpu(     ptr = new_ptr,     schema = tbl$schema,     groups = tbl$groups   ) }  evaluate_predicate <- function(tbl, pred) {   if (inherits(pred, \"ast_binary_op\")) {     left <- evaluate_expr(tbl, pred$left)     right <- evaluate_expr(tbl, pred$right)      op_code <- switch(pred$operator,       \">\" = 1L, \">=\" = 2L, \"<\" = 3L, \"<=\" = 4L,       \"==\" = 5L, \"!=\" = 6L,       \"&\" = 7L, \"|\" = 8L,       cli::cli_abort(\"Unsupported predicate operator: {pred$operator}\")     )      .Call(`_cuplyr_gpu_binary_op`, left, right, op_code)   } else {     cli::cli_abort(\"Cannot evaluate predicate: {class(pred)[1]}\")   } }  evaluate_expr <- function(tbl, expr) {   if (inherits(expr, \"ast_column_ref\")) {     col_idx <- match(expr$name, tbl$schema$names) - 1L     .Call(`_cuplyr_gpu_get_column`, tbl$ptr, col_idx)   } else if (inherits(expr, \"ast_literal\")) {     .Call(`_cuplyr_gpu_scalar`, expr$value)   } else if (inherits(expr, \"ast_binary_op\")) {     left <- evaluate_expr(tbl, expr$left)     right <- evaluate_expr(tbl, expr$right)     op_code <- match(expr$operator, c(\"+\", \"-\", \"*\", \"/\", \"^\", \"%%\", \"%/%\"))     .Call(`_cuplyr_gpu_binary_op`, left, right, op_code)   } else {     cli::cli_abort(\"Cannot evaluate expression: {class(expr)[1]}\")   } }"},{"path":"https://bbtheo.github.io/cuplyr/DEVELOPER_GUIDE.html","id":"verbose-mode-output-example","dir":"","previous_headings":"9. Roadmap: Lazy Translation & AST Approach (Not Implemented)","what":"Verbose Mode Output Example","title":"cuplyr: GPU-Accelerated dplyr Backend via libcudf","text":"","code":"> options(cuplyr.verbose = TRUE) > tbl_gpu(df) %>% filter(x > 10, y < 50) %>% mutate(z = x + y) %>% collect()  cuplyr: Executing 2 lazy operations cuplyr: Optimizing AST...   -> Fused 2 filter predicates cuplyr: Lowering 2 operations to libcudf   -> filter      cudf::binary_operation(col[0], scalar(10), GREATER) -> mask1      cudf::binary_operation(col[1], scalar(50), LESS) -> mask2      cudf::binary_operation(mask1, mask2, BITWISE_AND) -> mask_final      cudf::apply_boolean_mask(table, mask_final)   -> mutate      cudf::binary_operation(col[0], col[1], ADD) -> new_col      append column to table # A tibble: 3 x 3       x     y     z   <dbl> <dbl> <dbl> 1    15    30    45 2    20    40    60 3    25    45    70"},{"path":[]},{"path":[]},{"path":"https://bbtheo.github.io/cuplyr/DEVELOPER_GUIDE.html","id":"teststestthathelper-cuplyrr","dir":"","previous_headings":"10. Testing & Validation","what":"tests/testthat/helper-cuplyr.R","title":"cuplyr: GPU-Accelerated dplyr Backend via libcudf","text":"","code":"# Test helper functions  skip_if_no_gpu <- function() {   skip_if_not(     getOption(\"cuplyr.gpu_available\", FALSE),     \"No GPU available for testing\"   ) }  # Compare GPU and CPU results with tolerance expect_gpu_cpu_equal <- function(gpu_result, cpu_result, tolerance = 1e-10) {   gpu_df <- if (is_tbl_gpu(gpu_result)) collect(gpu_result) else gpu_result   cpu_df <- if (inherits(cpu_result, \"data.frame\")) cpu_result else as.data.frame(cpu_result)    expect_equal(nrow(gpu_df), nrow(cpu_df))   expect_equal(ncol(gpu_df), ncol(cpu_df))   expect_equal(names(gpu_df), names(cpu_df))    for (col in names(gpu_df)) {     if (is.numeric(gpu_df[[col]])) {       expect_equal(gpu_df[[col]], cpu_df[[col]], tolerance = tolerance,                    label = paste(\"Column\", col))     } else {       expect_equal(gpu_df[[col]], cpu_df[[col]], label = paste(\"Column\", col))     }   } }  # Generate test data make_test_df <- function(n = 1000, seed = 42) {   set.seed(seed)   data.frame(     int_col = sample(1:100, n, replace = TRUE),     dbl_col = rnorm(n, mean = 50, sd = 10),     chr_col = sample(letters[1:10], n, replace = TRUE),     grp_col = sample(LETTERS[1:5], n, replace = TRUE),     stringsAsFactors = FALSE   ) }"},{"path":"https://bbtheo.github.io/cuplyr/DEVELOPER_GUIDE.html","id":"teststestthattest-filterr","dir":"","previous_headings":"10. Testing & Validation","what":"tests/testthat/test-filter.R","title":"cuplyr: GPU-Accelerated dplyr Backend via libcudf","text":"","code":"test_that(\"filter with > works correctly\", {   skip_if_no_gpu()    df <- make_test_df(1000)   gpu_df <- tbl_gpu(df)    gpu_result <- gpu_df %>% filter(int_col > 50)   cpu_result <- df %>% dplyr::filter(int_col > 50)    expect_gpu_cpu_equal(gpu_result, cpu_result) })  test_that(\"filter with multiple conditions works\", {   skip_if_no_gpu()    df <- make_test_df(1000)   gpu_df <- tbl_gpu(df)    gpu_result <- gpu_df %>% filter(int_col > 25, int_col < 75)   cpu_result <- df %>% dplyr::filter(int_col > 25, int_col < 75)    expect_gpu_cpu_equal(gpu_result, cpu_result) })  test_that(\"filter handles NA values correctly\", {   skip_if_no_gpu()    df <- data.frame(     x = c(1, NA, 3, 4, NA, 6),     y = c(10, 20, NA, 40, 50, NA)   )   gpu_df <- tbl_gpu(df)    # Filter should exclude NA comparisons (like R)   gpu_result <- gpu_df %>% filter(x > 2) %>% collect()   cpu_result <- df %>% dplyr::filter(x > 2)    expect_equal(nrow(gpu_result), nrow(cpu_result))   expect_equal(gpu_result$x, cpu_result$x) })  test_that(\"filter on empty result returns empty table\", {   skip_if_no_gpu()    df <- data.frame(x = 1:10)   gpu_df <- tbl_gpu(df)    result <- gpu_df %>% filter(x > 100) %>% collect()    expect_equal(nrow(result), 0)   expect_equal(names(result), \"x\") })"},{"path":"https://bbtheo.github.io/cuplyr/DEVELOPER_GUIDE.html","id":"teststestthattest-integrationr","dir":"","previous_headings":"10. Testing & Validation","what":"tests/testthat/test-integration.R","title":"cuplyr: GPU-Accelerated dplyr Backend via libcudf","text":"","code":"test_that(\"complex pipeline matches dplyr\", {   skip_if_no_gpu()    df <- make_test_df(10000)   gpu_df <- tbl_gpu(df)    gpu_result <- gpu_df %>%     filter(int_col > 20) %>%     mutate(computed = dbl_col * 2) %>%     group_by(grp_col) %>%     summarise(       mean_val = mean(computed),       count = n()     ) %>%     arrange(grp_col) %>%     collect()    cpu_result <- df %>%     dplyr::filter(int_col > 20) %>%     dplyr::mutate(computed = dbl_col * 2) %>%     dplyr::group_by(grp_col) %>%     dplyr::summarise(       mean_val = mean(computed),       count = dplyr::n(),       .groups = \"drop\"     ) %>%     dplyr::arrange(grp_col)    expect_gpu_cpu_equal(gpu_result, cpu_result, tolerance = 1e-6) })  test_that(\"join operations match dplyr\", {   skip_if_no_gpu()    left_df <- data.frame(     key = c(1, 2, 3, 4, 5),     val_left = c(\"a\", \"b\", \"c\", \"d\", \"e\")   )   right_df <- data.frame(     key = c(2, 3, 4, 6, 7),     val_right = c(\"x\", \"y\", \"z\", \"w\", \"v\")   )    gpu_left <- tbl_gpu(left_df)   gpu_right <- tbl_gpu(right_df)    # Left join   gpu_result <- gpu_left %>%     left_join(gpu_right, by = \"key\") %>%     collect()    cpu_result <- left_df %>%     dplyr::left_join(right_df, by = \"key\")    expect_gpu_cpu_equal(gpu_result, cpu_result)    # Inner join   gpu_result <- gpu_left %>%     inner_join(gpu_right, by = \"key\") %>%     collect()    cpu_result <- left_df %>%     dplyr::inner_join(right_df, by = \"key\")    expect_gpu_cpu_equal(gpu_result, cpu_result) })"},{"path":"https://bbtheo.github.io/cuplyr/DEVELOPER_GUIDE.html","id":"benchmark-script","dir":"","previous_headings":"10. Testing & Validation","what":"Benchmark Script","title":"cuplyr: GPU-Accelerated dplyr Backend via libcudf","text":"","code":"# inst/benchmarks/run_benchmarks.R  library(cuplyr) library(dplyr) library(bench)  # Configuration sizes <- c(1e5, 1e6, 1e7, 1e8) results <- list()  cat(\"cuplyr Benchmark Suite\\n\") cat(\"=====================\\n\\n\")  for (n in sizes) {   cat(sprintf(\"Dataset size: %s rows\\n\", format(n, big.mark = \",\")))    # Generate data   set.seed(42)   df <- data.frame(     x = runif(n),     y = runif(n),     g = sample(letters[1:26], n, replace = TRUE)   )    gpu_df <- tbl_gpu(df)    # Benchmark filter   bm_filter <- bench::mark(     cpu = df %>% filter(x > 0.5),     gpu = gpu_df %>% filter(x > 0.5) %>% collect(),     check = FALSE,     min_iterations = 5   )    # Benchmark group_by + summarise   bm_group <- bench::mark(     cpu = df %>% group_by(g) %>% summarise(mean_x = mean(x), .groups = \"drop\"),     gpu = gpu_df %>% group_by(g) %>% summarise(mean_x = mean(x)) %>% collect(),     check = FALSE,     min_iterations = 5   )    # Benchmark arrange   bm_sort <- bench::mark(     cpu = df %>% arrange(x),     gpu = gpu_df %>% arrange(x) %>% collect(),     check = FALSE,     min_iterations = 5   )    results[[as.character(n)]] <- list(     filter = bm_filter,     group_by = bm_group,     arrange = bm_sort   )    cat(sprintf(\"  filter:   CPU %.2fs, GPU %.2fs (%.1fx speedup)\\n\",               as.numeric(bm_filter$median[1]),               as.numeric(bm_filter$median[2]),               as.numeric(bm_filter$median[1]) / as.numeric(bm_filter$median[2])))    cat(sprintf(\"  group_by: CPU %.2fs, GPU %.2fs (%.1fx speedup)\\n\",               as.numeric(bm_group$median[1]),               as.numeric(bm_group$median[2]),               as.numeric(bm_group$median[1]) / as.numeric(bm_group$median[2])))    cat(sprintf(\"  arrange:  CPU %.2fs, GPU %.2fs (%.1fx speedup)\\n\",               as.numeric(bm_sort$median[1]),               as.numeric(bm_sort$median[2]),               as.numeric(bm_sort$median[1]) / as.numeric(bm_sort$median[2])))    cat(\"\\n\")    # Clean up GPU memory   rm(gpu_df)   gc() }  # Save results saveRDS(results, \"inst/benchmarks/results/benchmark_results.rds\") cat(\"Results saved to inst/benchmarks/results/benchmark_results.rds\\n\")"},{"path":[]},{"path":"https://bbtheo.github.io/cuplyr/DEVELOPER_GUIDE.html","id":"verbose-mode-implementation","dir":"","previous_headings":"11. Debugging, Logging & Observability","what":"Verbose Mode Implementation","title":"cuplyr: GPU-Accelerated dplyr Backend via libcudf","text":"","code":"# R/logging.R  #' Enable verbose logging #' #' @param enabled Logical, whether to enable verbose mode #' @export cuplyr_verbose <- function(enabled = TRUE) {   options(cuplyr.verbose = enabled)   if (enabled) {     message(\"cuplyr: Verbose mode enabled\")   }   invisible(enabled) }  # Internal logging function log_cuplyr <- function(..., level = \"INFO\") {   if (!getOption(\"cuplyr.verbose\", FALSE)) return(invisible())    timestamp <- format(Sys.time(), \"%H:%M:%S.%OS3\")   msg <- paste0(\"[cuplyr \", timestamp, \" \", level, \"] \", ...)   message(msg) }  log_op <- function(op_name, ...) {   log_cuplyr(\"OP: \", op_name, \" - \", ...) }  log_cudf_call <- function(fn_name, ...) {   log_cuplyr(\"CUDF: \", fn_name, \"(\", paste(..., sep = \", \"), \")\") }"},{"path":"https://bbtheo.github.io/cuplyr/DEVELOPER_GUIDE.html","id":"ast-dump-function","dir":"","previous_headings":"11. Debugging, Logging & Observability","what":"AST Dump Function","title":"cuplyr: GPU-Accelerated dplyr Backend via libcudf","text":"","code":"# R/debug.R  #' Print the AST for a lazy tbl_gpu #' #' @param x A tbl_gpu object #' @param indent Current indentation level (internal) #' @export dump_ast <- function(x, indent = 0) {   if (!is_tbl_gpu(x)) {     cli::cli_abort(\"x must be a tbl_gpu object\")   }    prefix <- strrep(\"  \", indent)    cat(prefix, \"tbl_gpu [\\n\", sep = \"\")   cat(prefix, \"  schema: \", paste(x$schema$names, collapse = \", \"), \"\\n\", sep = \"\")   cat(prefix, \"  types:  \", paste(x$schema$types, collapse = \", \"), \"\\n\", sep = \"\")    if (length(x$groups) > 0) {     cat(prefix, \"  groups: \", paste(x$groups, collapse = \", \"), \"\\n\", sep = \"\")   }    cat(prefix, \"  materialized: \", !is.null(x$ptr), \"\\n\", sep = \"\")    if (length(x$lazy_ops) > 0) {     cat(prefix, \"  lazy_ops:\\n\", sep = \"\")     for (i in seq_along(x$lazy_ops)) {       dump_ast_node(x$lazy_ops[[i]], indent + 2, i)     }   }    cat(prefix, \"]\\n\", sep = \"\")   invisible(x) }  dump_ast_node <- function(node, indent, index = NULL) {   prefix <- strrep(\"  \", indent)   idx_str <- if (!is.null(index)) paste0(\"[\", index, \"] \") else \"\"    cat(prefix, idx_str, node$op, \"\\n\", sep = \"\")    if (node$op == \"filter\") {     for (pred in node$args) {       cat(prefix, \"  predicate: \", deparse(rlang::quo_get_expr(pred)), \"\\n\", sep = \"\")     }   } else if (node$op == \"select\") {     cat(prefix, \"  columns: \", paste(node$args, collapse = \", \"), \"\\n\", sep = \"\")   } else if (node$op == \"mutate\") {     for (nm in names(node$args)) {       cat(prefix, \"  \", nm, \" = \", deparse(rlang::quo_get_expr(node$args[[nm]])), \"\\n\", sep = \"\")     }   } else if (node$op == \"arrange\") {     cat(prefix, \"  columns: \", paste(node$args$columns, collapse = \", \"), \"\\n\", sep = \"\")     cat(prefix, \"  desc: \", paste(node$args$desc, collapse = \", \"), \"\\n\", sep = \"\")   } else if (node$op == \"group_by\") {     cat(prefix, \"  groups: \", paste(node$args, collapse = \", \"), \"\\n\", sep = \"\")   } else if (node$op == \"summarise\") {     for (nm in names(node$args)) {       cat(prefix, \"  \", nm, \" = \", deparse(rlang::quo_get_expr(node$args[[nm]])), \"\\n\", sep = \"\")     }   } }"},{"path":"https://bbtheo.github.io/cuplyr/DEVELOPER_GUIDE.html","id":"gpu-memory-diagnostics","dir":"","previous_headings":"11. Debugging, Logging & Observability","what":"GPU Memory Diagnostics","title":"cuplyr: GPU-Accelerated dplyr Backend via libcudf","text":"","code":"# R/diagnostics.R  #' Get GPU information and memory status #' #' @return A list with GPU device information #' @export gpu_info <- function() {   info <- .Call(`_cuplyr_gpu_info`)   structure(info, class = \"cuplyr_gpu_info\") }  #' @export print.cuplyr_gpu_info <- function(x, ...) {   cat(\"GPU Device Information\\n\")   cat(\"======================\\n\")   cat(\"Device:       \", x$name, \"\\n\")   cat(\"Compute Cap:  \", x$compute_capability, \"\\n\")   cat(\"Memory Total: \", format_bytes(x$memory_total), \"\\n\")   cat(\"Memory Free:  \", format_bytes(x$memory_free), \"\\n\")   cat(\"Memory Used:  \", format_bytes(x$memory_total - x$memory_free), \"\\n\")   cat(\"Utilization:  \", sprintf(\"%.1f%%\", 100 * (1 - x$memory_free / x$memory_total)), \"\\n\")   invisible(x) }  format_bytes <- function(bytes) {   if (bytes >= 1e9) {     sprintf(\"%.2f GB\", bytes / 1e9)   } else if (bytes >= 1e6) {     sprintf(\"%.2f MB\", bytes / 1e6)   } else {     sprintf(\"%.2f KB\", bytes / 1e3)   } }  #' Monitor GPU memory during pipeline execution #' #' @param expr Expression to evaluate #' @return Result of expression, with memory stats printed #' @export with_gpu_monitor <- function(expr) {   before <- gpu_info()   on.exit({     after <- gpu_info()     cat(\"\\nGPU Memory Delta:\\n\")     cat(\"  Before: \", format_bytes(before$memory_free), \" free\\n\")     cat(\"  After:  \", format_bytes(after$memory_free), \" free\\n\")     cat(\"  Change: \", format_bytes(before$memory_free - after$memory_free), \"\\n\")   })   force(expr) }"},{"path":"https://bbtheo.github.io/cuplyr/DEVELOPER_GUIDE.html","id":"c-gpu-info-implementation","dir":"","previous_headings":"11. Debugging, Logging & Observability","what":"C++ GPU Info Implementation","title":"cuplyr: GPU-Accelerated dplyr Backend via libcudf","text":"","code":"// src/diagnostics.cpp #include <Rcpp.h> #include <cuda_runtime.h>  // [[Rcpp::export]] Rcpp::List gpu_info_impl() {     int device;     cudaGetDevice(&device);      cudaDeviceProp prop;     cudaGetDeviceProperties(&prop, device);      size_t free_mem, total_mem;     cudaMemGetInfo(&free_mem, &total_mem);      return Rcpp::List::create(         Rcpp::Named(\"name\") = std::string(prop.name),         Rcpp::Named(\"compute_capability\") = std::to_string(prop.major) + \".\" + std::to_string(prop.minor),         Rcpp::Named(\"memory_total\") = static_cast<double>(total_mem),         Rcpp::Named(\"memory_free\") = static_cast<double>(free_mem),         Rcpp::Named(\"multiprocessors\") = prop.multiProcessorCount,         Rcpp::Named(\"max_threads_per_block\") = prop.maxThreadsPerBlock     ); }"},{"path":"https://bbtheo.github.io/cuplyr/DEVELOPER_GUIDE.html","id":"example-verbose-output","dir":"","previous_headings":"11. Debugging, Logging & Observability","what":"Example Verbose Output","title":"cuplyr: GPU-Accelerated dplyr Backend via libcudf","text":"","code":"> options(cuplyr.verbose = TRUE) > df <- data.frame(x = 1:1e6, y = runif(1e6), g = sample(letters, 1e6, TRUE)) > result <- tbl_gpu(df) %>% +   filter(x > 500000) %>% +   group_by(g) %>% +   summarise(mean_y = mean(y)) %>% +   collect()  [cuplyr 14:23:15.123 INFO] OP: tbl_gpu - Transferring 1000000 x 3 data.frame to GPU [cuplyr 14:23:15.456 INFO] CUDF: creating table with 3 columns [cuplyr 14:23:15.457 INFO] OP: filter - Adding lazy operation [cuplyr 14:23:15.457 INFO] OP: group_by - Adding lazy operation [cuplyr 14:23:15.457 INFO] OP: summarise - Adding lazy operation [cuplyr 14:23:15.458 INFO] OP: collect - Materializing lazy pipeline [cuplyr 14:23:15.458 INFO] Optimizing 3 operations... [cuplyr 14:23:15.458 INFO] CUDF: binary_operation(col[0], scalar(500000), GREATER) [cuplyr 14:23:15.512 INFO] CUDF: apply_boolean_mask(table, mask) [cuplyr 14:23:15.534 INFO] CUDF: groupby::groupby(keys=[2]) [cuplyr 14:23:15.535 INFO] CUDF: groupby::aggregate(mean on col[1]) [cuplyr 14:23:15.589 INFO] CUDF: Transferring result 26 x 2 to R"},{"path":[]},{"path":"https://bbtheo.github.io/cuplyr/DEVELOPER_GUIDE.html","id":"kernel-fusion-strategy","dir":"","previous_headings":"12. Performance & Optimization Guidance","what":"Kernel Fusion Strategy","title":"cuplyr: GPU-Accelerated dplyr Backend via libcudf","text":"Minimize GPU kernel launches fusing operations:","code":"// src/fused_ops.cpp // Example: Fused filter + mutate  #include \"gpu_table.hpp\" #include <cudf/stream_compaction.hpp> #include <cudf/binaryop.hpp> #include <cudf/transform.hpp>  // Instead of separate filter then mutate, compute both in one pass // [[Rcpp::export]] SEXP gpu_filter_mutate_fused(     SEXP xptr,     int filter_col,     double filter_val,     int mutate_col,     double mutate_factor ) {     using namespace cuplyr;      Rcpp::XPtr<GpuTablePtr> ptr(xptr);     cudf::table_view view = get_table_view(ptr);      // Create filter mask     auto scalar = cudf::make_numeric_scalar(cudf::data_type{cudf::type_id::FLOAT64});     static_cast<cudf::numeric_scalar<double>*>(scalar.get())->set_value(filter_val);      auto mask = cudf::binary_operation(         view.column(filter_col),         *scalar,         cudf::binary_operator::GREATER,         cudf::data_type{cudf::type_id::BOOL8}     );      // Apply filter     auto filtered = cudf::apply_boolean_mask(view, mask->view());      // Now apply mutation on filtered data (smaller, more efficient)     auto factor_scalar = cudf::make_numeric_scalar(cudf::data_type{cudf::type_id::FLOAT64});     static_cast<cudf::numeric_scalar<double>*>(factor_scalar.get())->set_value(mutate_factor);      auto new_col = cudf::binary_operation(         filtered->view().column(mutate_col),         *factor_scalar,         cudf::binary_operator::MUL,         cudf::data_type{cudf::type_id::FLOAT64}     );      // Build result table with new column appended     std::vector<std::unique_ptr<cudf::column>> result_cols;     for (cudf::size_type i = 0; i < filtered->num_columns(); ++i) {         result_cols.push_back(std::make_unique<cudf::column>(filtered->view().column(i)));     }     result_cols.push_back(std::move(new_col));      auto result = std::make_unique<cudf::table>(std::move(result_cols));     return make_gpu_table_xptr(std::move(result)); }"},{"path":"https://bbtheo.github.io/cuplyr/DEVELOPER_GUIDE.html","id":"memory-copy-minimization","dir":"","previous_headings":"12. Performance & Optimization Guidance","what":"Memory Copy Minimization","title":"cuplyr: GPU-Accelerated dplyr Backend via libcudf","text":"","code":"# R/performance.R  # BAD: Multiple round-trips bad_example <- function(df) {   gpu <- tbl_gpu(df)   filtered <- gpu %>% filter(x > 10) %>% collect()  # GPU -> CPU   gpu2 <- tbl_gpu(filtered)                          # CPU -> GPU   result <- gpu2 %>% mutate(y = x * 2) %>% collect() # GPU -> CPU   result }  # GOOD: Stay on GPU, single collect at end good_example <- function(df) {   tbl_gpu(df) %>%     filter(x > 10) %>%     mutate(y = x * 2) %>%     collect()  # Only one GPU -> CPU transfer }"},{"path":"https://bbtheo.github.io/cuplyr/DEVELOPER_GUIDE.html","id":"chunking-large-datasets","dir":"","previous_headings":"12. Performance & Optimization Guidance","what":"Chunking Large Datasets","title":"cuplyr: GPU-Accelerated dplyr Backend via libcudf","text":"","code":"#' Process large datasets in chunks #' #' @param df Large data frame #' @param chunk_size Number of rows per chunk #' @param fn Function to apply to each chunk (receives tbl_gpu) #' @return Combined results #' @export gpu_chunked <- function(df, chunk_size = 1e7, fn) {   n <- nrow(df)   n_chunks <- ceiling(n / chunk_size)    results <- vector(\"list\", n_chunks)    for (i in seq_len(n_chunks)) {     start_row <- (i - 1) * chunk_size + 1     end_row <- min(i * chunk_size, n)      chunk <- df[start_row:end_row, , drop = FALSE]     gpu_chunk <- tbl_gpu(chunk)      results[[i]] <- fn(gpu_chunk) %>% collect()      # Force cleanup     rm(gpu_chunk)     gc()   }    dplyr::bind_rows(results) }  # Usage # result <- gpu_chunked(huge_df, chunk_size = 5e6, function(chunk) { #   chunk %>% filter(x > 10) %>% group_by(g) %>% summarise(n = n()) # })"},{"path":"https://bbtheo.github.io/cuplyr/DEVELOPER_GUIDE.html","id":"multi-gpu-considerations","dir":"","previous_headings":"12. Performance & Optimization Guidance","what":"Multi-GPU Considerations","title":"cuplyr: GPU-Accelerated dplyr Backend via libcudf","text":"","code":"# R/multi_gpu.R  #' Set active GPU device #' #' @param device_id Integer device ID (0-indexed) #' @export set_gpu_device <- function(device_id) {   .Call(`_cuplyr_set_device`, as.integer(device_id))   invisible(device_id) }  #' Get number of available GPUs #' #' @return Integer count of GPUs #' @export gpu_count <- function() {   .Call(`_cuplyr_device_count`) }  #' Distribute work across multiple GPUs #' #' @param df Data frame to process #' @param fn Processing function #' @param n_gpus Number of GPUs to use (default: all available) #' @return Combined results #' @export gpu_parallel <- function(df, fn, n_gpus = gpu_count()) {   n <- nrow(df)   chunk_size <- ceiling(n / n_gpus)    # Use parallel package for multi-GPU   results <- parallel::mclapply(seq_len(n_gpus), function(gpu_id) {     set_gpu_device(gpu_id - 1)  # 0-indexed      start_row <- (gpu_id - 1) * chunk_size + 1     end_row <- min(gpu_id * chunk_size, n)      chunk <- df[start_row:end_row, , drop = FALSE]     gpu_chunk <- tbl_gpu(chunk)      fn(gpu_chunk) %>% collect()   }, mc.cores = n_gpus)    dplyr::bind_rows(results) }"},{"path":"https://bbtheo.github.io/cuplyr/DEVELOPER_GUIDE.html","id":"when-to-fall-back-to-cpu","dir":"","previous_headings":"12. Performance & Optimization Guidance","what":"When to Fall Back to CPU","title":"cuplyr: GPU-Accelerated dplyr Backend via libcudf","text":"","code":"# Decision heuristics for GPU vs CPU  should_use_gpu <- function(df, operation) {   n <- nrow(df)    # Small data: CPU is often faster due to transfer overhead   if (n < 10000) {     return(FALSE)   }    # String-heavy operations may not benefit as much   string_cols <- sum(vapply(df, is.character, logical(1)))   if (string_cols > ncol(df) / 2 && operation %in% c(\"mutate\", \"filter\")) {     # String operations have less GPU speedup     if (n < 100000) return(FALSE)   }    # Check available GPU memory   info <- gpu_info()   estimated_size <- object.size(df) * 1.5  # Rough GPU overhead   if (estimated_size > info$memory_free * 0.8) {     warning(\"Data may exceed GPU memory, consider chunking\")   }    TRUE }"},{"path":"https://bbtheo.github.io/cuplyr/DEVELOPER_GUIDE.html","id":"custom-cuda-kernels-advanced","dir":"","previous_headings":"12. Performance & Optimization Guidance","what":"Custom CUDA Kernels (Advanced)","title":"cuplyr: GPU-Accelerated dplyr Backend via libcudf","text":"operations libcudf, can write custom kernels:","code":"// src/custom_kernels.cu // NOTE: This file requires nvcc compilation  #include <cuda_runtime.h>  // Example: Custom kernel for a specialized operation __global__ void custom_transform_kernel(     const double* input,     double* output,     int n,     double param1,     double param2 ) {     int idx = blockIdx.x * blockDim.x + threadIdx.x;     if (idx < n) {         // Custom computation         output[idx] = input[idx] * param1 + param2 * sqrt(input[idx]);     } }  extern \"C\" void launch_custom_transform(     const double* input,     double* output,     int n,     double param1,     double param2 ) {     int block_size = 256;     int num_blocks = (n + block_size - 1) / block_size;     custom_transform_kernel<<<num_blocks, block_size>>>(         input, output, n, param1, param2     );     cudaDeviceSynchronize(); }"},{"path":[]},{"path":"https://bbtheo.github.io/cuplyr/DEVELOPER_GUIDE.html","id":"arrow-c-data-interface","dir":"","previous_headings":"13. Interoperability","what":"Arrow C Data Interface","title":"cuplyr: GPU-Accelerated dplyr Backend via libcudf","text":"","code":"# R/arrow_interop.R  #' Export tbl_gpu to Arrow format (zero-copy when possible) #' #' @param x A tbl_gpu object #' @return A nanoarrow array stream #' @export as_nanoarrow_array_stream.tbl_gpu <- function(x, ...) {   if (length(x$lazy_ops) > 0) {     x <- compute(x)   }    # Get Arrow C Data Interface pointers from GPU table   arrow_ptrs <- .Call(`_cuplyr_export_to_arrow`, x$ptr)    # Wrap in nanoarrow   nanoarrow::nanoarrow_pointer_import(     arrow_ptrs$schema_ptr,     arrow_ptrs$array_ptr   ) }  #' Import from Arrow to GPU #' #' @param stream A nanoarrow array stream or Arrow Table #' @return A tbl_gpu object #' @export tbl_gpu.nanoarrow_array_stream <- function(data, ...) {   # Export Arrow C Data Interface pointers   schema_ptr <- nanoarrow::nanoarrow_pointer_export(data)    # Import to GPU via cudf's Arrow integration   gpu_ptr <- .Call(`_cuplyr_import_from_arrow`, schema_ptr)    # Build schema from Arrow metadata   schema <- extract_schema_from_arrow(data)     new_tbl_gpu(ptr = gpu_ptr, schema = schema) }  #' Convert Arrow Table to GPU #' #' @param data An Arrow Table #' @return A tbl_gpu object #' @export tbl_gpu.ArrowTabular <- function(data, ...) {   # Use Arrow's C Data Interface   stream <- arrow::as_record_batch_reader(data)   tbl_gpu(nanoarrow::as_nanoarrow_array_stream(stream)) }"},{"path":"https://bbtheo.github.io/cuplyr/DEVELOPER_GUIDE.html","id":"c-arrow-integration","dir":"","previous_headings":"13. Interoperability","what":"C++ Arrow Integration","title":"cuplyr: GPU-Accelerated dplyr Backend via libcudf","text":"","code":"// src/arrow_interop.cpp #include \"gpu_table.hpp\" #include <cudf/interop.hpp> #include <nanoarrow/nanoarrow.h>  // Export cudf table to Arrow C Data Interface // [[Rcpp::export]] Rcpp::List export_to_arrow(SEXP xptr) {     using namespace cuplyr;      Rcpp::XPtr<GpuTablePtr> ptr(xptr);     cudf::table_view view = get_table_view(ptr);      // Allocate Arrow structures     ArrowSchema* schema = new ArrowSchema;     ArrowArray* array = new ArrowArray;      // Use cudf's Arrow export (copies data to host)     // Note: For true zero-copy, would need CUDA-aware Arrow     auto arrow_table = cudf::to_arrow(view);      // Export to C interface     arrow::ExportRecordBatch(*arrow_table->ToRecordBatch(0).ValueOrDie(),                              array, schema);      return Rcpp::List::create(         Rcpp::Named(\"schema_ptr\") = Rcpp::XPtr<ArrowSchema>(schema),         Rcpp::Named(\"array_ptr\") = Rcpp::XPtr<ArrowArray>(array)     ); }  // Import from Arrow C Data Interface // [[Rcpp::export]] SEXP import_from_arrow(SEXP schema_xptr, SEXP array_xptr) {     Rcpp::XPtr<ArrowSchema> schema(schema_xptr);     Rcpp::XPtr<ArrowArray> array(array_xptr);      // Import to Arrow C++ then to cudf     auto result = arrow::ImportRecordBatch(array.get(), schema.get());     if (!result.ok()) {         Rcpp::stop(\"Failed to import Arrow data: %s\", result.status().message());     }      auto arrow_table = arrow::Table::FromRecordBatches({result.ValueOrDie()});     auto cudf_table = cudf::from_arrow(*arrow_table.ValueOrDie());      return cuplyr::make_gpu_table_xptr(std::move(cudf_table)); }"},{"path":"https://bbtheo.github.io/cuplyr/DEVELOPER_GUIDE.html","id":"reticulate-bridge-to-python-rapids","dir":"","previous_headings":"13. Interoperability","what":"Reticulate Bridge to Python RAPIDS","title":"cuplyr: GPU-Accelerated dplyr Backend via libcudf","text":"","code":"# R/python_bridge.R  #' Call Python cudf when C++ API is insufficient #' #' @param gpu_tbl A tbl_gpu object #' @param py_code Python code to execute (has access to 'df' variable) #' @return A tbl_gpu object #' @export gpu_python <- function(gpu_tbl, py_code) {   if (!requireNamespace(\"reticulate\", quietly = TRUE)) {     cli::cli_abort(\"Package 'reticulate' is required for Python bridge\")   }    # Ensure Python cudf is available   if (!reticulate::py_module_available(\"cudf\")) {     cli::cli_abort(\"Python cudf module not found. Install with: pip install cudf-cu12\")   }    # Export to Arrow, import in Python   arrow_stream <- as_nanoarrow_array_stream(gpu_tbl)    reticulate::py_run_string(\" import cudf import pyarrow as pa \")    # Transfer via Arrow IPC (temporary - real impl would use shared memory)   temp_file <- tempfile(fileext = \".arrow\")   arrow::write_ipc_file(     arrow::as_arrow_table(arrow_stream),     temp_file   )    reticulate::py$df <- reticulate::py_eval(     sprintf(\"cudf.read_feather('%s')\", temp_file)   )    # Execute user code   reticulate::py_run_string(py_code)    # Get result back   result_py <- reticulate::py$df    # Convert back to R via Arrow   result_arrow <- reticulate::py_eval(\"df.to_arrow()\")    # Clean up   unlink(temp_file)    # Return as tbl_gpu   tbl_gpu(result_arrow) }  # Example usage: # result <- gpu_python(my_tbl, \" #   df = df.drop_duplicates(subset=['col1', 'col2']) #   df['new_col'] = df['x'].rolling(window=10).mean() # \")"},{"path":"https://bbtheo.github.io/cuplyr/DEVELOPER_GUIDE.html","id":"dtplyr--datatable-interop","dir":"","previous_headings":"13. Interoperability","what":"dtplyr / data.table Interop","title":"cuplyr: GPU-Accelerated dplyr Backend via libcudf","text":"","code":"# R/dtplyr_interop.R  #' Convert between tbl_gpu and dtplyr lazy tables #' #' @param x A lazy_dt or tbl_gpu #' @return Converted object #' @export as_lazy_dt.tbl_gpu <- function(x, ...) {   if (!requireNamespace(\"dtplyr\", quietly = TRUE)) {     cli::cli_abort(\"Package 'dtplyr' is required\")   }    # Materialize and convert   df <- collect(x)   dtplyr::lazy_dt(data.table::as.data.table(df)) }  #' @export tbl_gpu.dtplyr_step <- function(data, ...) {   # Collect dtplyr result then transfer to GPU   df <- dplyr::collect(data)   tbl_gpu(as.data.frame(df)) }"},{"path":[]},{"path":"https://bbtheo.github.io/cuplyr/DEVELOPER_GUIDE.html","id":"recommended-license","dir":"","previous_headings":"14. Packaging, Distribution & Licensing","what":"Recommended License","title":"cuplyr: GPU-Accelerated dplyr Backend via libcudf","text":"Rationale: Apache 2.0 matches RAPIDS/libcudf licensing, ensuring compatibility allowing commercial use requiring attribution.","code":"# LICENSE file Apache License Version 2.0, January 2004 http://www.apache.org/licenses/  [Full Apache 2.0 license text]"},{"path":"https://bbtheo.github.io/cuplyr/DEVELOPER_GUIDE.html","id":"why-not-cran","dir":"","previous_headings":"14. Packaging, Distribution & Licensing","what":"Why Not CRAN","title":"cuplyr: GPU-Accelerated dplyr Backend via libcudf","text":"CRAN distribution recommended cuplyr : Binary dependencies: libcudf, CUDA runtime available CRAN build servers GPU requirement: CRAN check servers don’t GPUs Large binary size: libcudf 100+ MB Version coupling: Tight dependency CUDA/driver versions","code":""},{"path":[]},{"path":"https://bbtheo.github.io/cuplyr/DEVELOPER_GUIDE.html","id":"conda-recipe","dir":"","previous_headings":"14. Packaging, Distribution & Licensing","what":"Conda Recipe","title":"cuplyr: GPU-Accelerated dplyr Backend via libcudf","text":"","code":"# recipe/meta.yaml {% set version = \"0.1.0\" %}  package:   name: r-cuplyr   version: {{ version }}  source:   git_url: https://github.com/yourorg/cuplyr   git_rev: v{{ version }}  build:   number: 0   skip: true  # [not linux]   rpaths:     - lib/R/lib/     - lib/  requirements:   build:     - {{ compiler('c') }}     - {{ compiler('cxx') }}     - cmake     - make   host:     - r-base >=4.3     - r-rcpp >=1.0.12     - r-dplyr >=1.1.0     - r-rlang >=1.1.0     - r-vctrs >=0.6.0     - r-pillar >=1.9.0     - r-glue >=1.6.0     - r-cli >=3.6.0     - libcudf >=25.12     - cudatoolkit >=12.0   run:     - r-base >=4.3     - r-rcpp >=1.0.12     - r-dplyr >=1.1.0     - r-rlang >=1.1.0     - r-vctrs >=0.6.0     - r-pillar >=1.9.0     - r-glue >=1.6.0     - r-cli >=3.6.0     - libcudf >=25.12     - cudatoolkit >=12.0     - __cuda  # Virtual package for CUDA runtime  test:   commands:     - $R -e \"library(cuplyr)\"     - $R -e \"cuplyr::gpu_info()\"  # [gpu]  about:   home: https://github.com/yourorg/cuplyr   license: Apache-2.0   license_family: Apache   license_file: LICENSE   summary: GPU-accelerated dplyr backend using RAPIDS libcudf   description: |     cuplyr provides a dplyr-compatible interface for GPU-accelerated     data manipulation using NVIDIA's RAPIDS libcudf library.  extra:   recipe-maintainers:     - your-github-handle"},{"path":"https://bbtheo.github.io/cuplyr/DEVELOPER_GUIDE.html","id":"build-script-for-conda","dir":"","previous_headings":"14. Packaging, Distribution & Licensing","what":"Build Script for Conda","title":"cuplyr: GPU-Accelerated dplyr Backend via libcudf","text":"","code":"# recipe/build.sh #!/bin/bash set -ex  export CUDA_HOME=\"${PREFIX}\" export CUDF_HOME=\"${PREFIX}\"  # Run configure chmod +x configure ./configure  # Build and install R CMD INSTALL --build ."},{"path":"https://bbtheo.github.io/cuplyr/DEVELOPER_GUIDE.html","id":"release-checklist","dir":"","previous_headings":"14. Packaging, Distribution & Licensing","what":"Release Checklist","title":"cuplyr: GPU-Accelerated dplyr Backend via libcudf","text":"","code":"## Release Checklist for cuplyr v{VERSION}  ### Pre-release - [ ] All tests pass locally with GPU - [ ] Update version in DESCRIPTION - [ ] Update NEWS.md with changes - [ ] Update README.md if needed - [ ] Verify compatibility with latest RAPIDS version - [ ] Run benchmarks, update benchmark results  ### Release - [ ] Create git tag: `git tag -a v{VERSION} -m \"Release v{VERSION}\"` - [ ] Push tag: `git push origin v{VERSION}` - [ ] Create GitHub Release with changelog - [ ] Build source tarball: `R CMD build .` - [ ] Upload tarball to GitHub Release  ### Post-release - [ ] Build and push Docker image - [ ] Update conda-forge recipe (PR to feedstock) - [ ] Announce on relevant channels - [ ] Update documentation site"},{"path":[]},{"path":"https://bbtheo.github.io/cuplyr/DEVELOPER_GUIDE.html","id":"workflow-1-basic-data-analysis","dir":"","previous_headings":"15. Example User Workflows","what":"Workflow 1: Basic Data Analysis","title":"cuplyr: GPU-Accelerated dplyr Backend via libcudf","text":"Lowered libcudf calls (verbose mode):","code":"library(cuplyr) library(dplyr)  # Check GPU is available gpu_info() #> GPU Device Information #> ====================== #> Device:       NVIDIA A100-SXM4-40GB #> Compute Cap:  8.0 #> Memory Total: 42.50 GB #> Memory Free:  41.23 GB #> Memory Used:  1.27 GB #> Utilization:  3.0%  # Load data to GPU sales <- read.csv(\"sales_100M.csv\") sales_gpu <- tbl_gpu(sales)  # Familiar dplyr pipeline result <- sales_gpu %>%   filter(year >= 2020, amount > 0) %>%   mutate(     revenue = amount * price,     quarter = ceiling(month / 3)   ) %>%   group_by(region, quarter) %>%   summarise(     total_revenue = sum(revenue),     avg_order = mean(amount),     n_orders = n()   ) %>%   arrange(desc(total_revenue)) %>%   collect()  print(result) #> # A tibble: 80 x 5 #>    region  quarter total_revenue avg_order n_orders #>    <chr>     <dbl>         <dbl>     <dbl>    <int> #>  1 West          4    1234567890      45.2  2345678 #>  2 East          4    1198765432      42.1  2234567 #> # ... with 78 more rows [cuplyr] CUDF: binary_operation(col[year], scalar(2020), GREATER_EQUAL) -> mask1 [cuplyr] CUDF: binary_operation(col[amount], scalar(0), GREATER) -> mask2 [cuplyr] CUDF: binary_operation(mask1, mask2, BITWISE_AND) -> mask_combined [cuplyr] CUDF: apply_boolean_mask(table, mask_combined) [cuplyr] CUDF: binary_operation(col[amount], col[price], MUL) -> revenue_col [cuplyr] CUDF: binary_operation(col[month], scalar(3), DIV) -> temp [cuplyr] CUDF: unary_operation(temp, CEIL) -> quarter_col [cuplyr] CUDF: groupby::groupby(keys=[region, quarter]) [cuplyr] CUDF: groupby::aggregate([sum(revenue), mean(amount), count(*)]) [cuplyr] CUDF: sort(by=[total_revenue], order=[DESC])"},{"path":"https://bbtheo.github.io/cuplyr/DEVELOPER_GUIDE.html","id":"workflow-2-joining-large-tables","dir":"","previous_headings":"15. Example User Workflows","what":"Workflow 2: Joining Large Tables","title":"cuplyr: GPU-Accelerated dplyr Backend via libcudf","text":"","code":"# Two large tables customers_gpu <- tbl_gpu(customers_df)   # 50M rows orders_gpu <- tbl_gpu(orders_df)         # 200M rows  # Join and aggregate customer_summary <- orders_gpu %>%   inner_join(customers_gpu, by = \"customer_id\") %>%   group_by(customer_segment, region) %>%   summarise(     total_orders = n(),     total_value = sum(order_value),     avg_value = mean(order_value)   ) %>%   collect()  # Timing comparison library(bench)  bench::mark(   cpu = orders_df %>%     inner_join(customers_df, by = \"customer_id\") %>%     group_by(customer_segment, region) %>%     summarise(       total_orders = n(),       total_value = sum(order_value),       avg_value = mean(order_value),       .groups = \"drop\"     ),   gpu = orders_gpu %>%     inner_join(customers_gpu, by = \"customer_id\") %>%     group_by(customer_segment, region) %>%     summarise(       total_orders = n(),       total_value = sum(order_value),       avg_value = mean(order_value)     ) %>%     collect(),   check = FALSE,   min_iterations = 3 ) #> # A tibble: 2 x 6 #>   expression      min   median `itr/sec` mem_alloc `gc/sec` #>   <bch:expr> <bch:tm> <bch:tm>     <dbl> <bch:byt>    <dbl> #> 1 cpu           45.2s    47.8s    0.0209    12.4GB     1.23 #> 2 gpu           1.23s    1.45s    0.689     2.1GB      0.12"},{"path":"https://bbtheo.github.io/cuplyr/DEVELOPER_GUIDE.html","id":"workflow-3-time-series-with-window-functions","dir":"","previous_headings":"15. Example User Workflows","what":"Workflow 3: Time Series with Window Functions","title":"cuplyr: GPU-Accelerated dplyr Backend via libcudf","text":"","code":"# Stock price data prices_gpu <- tbl_gpu(stock_prices)  # 100M rows  # Calculate moving averages (when supported) with_indicators <- prices_gpu %>%   group_by(ticker) %>%   arrange(date) %>%   mutate(     ma_5 = mean(close, .window = 5),     ma_20 = mean(close, .window = 20),     returns = (close - lag(close, 1)) / lag(close, 1)   ) %>%   ungroup() %>%   collect()  # For unsupported operations, use Python bridge advanced_indicators <- gpu_python(prices_gpu, \" import cudf  # cuDF supports more window functions df['ema_12'] = df.groupby('ticker')['close'].transform(     lambda x: x.ewm(span=12).mean() ) df['rsi'] = df.groupby('ticker')['close'].transform(     lambda x: 100 - (100 / (1 + x.diff().clip(lower=0).rolling(14).mean() /                                  (-x.diff().clip(upper=0)).rolling(14).mean())) ) \")"},{"path":"https://bbtheo.github.io/cuplyr/DEVELOPER_GUIDE.html","id":"workflow-4-memory-profiling","dir":"","previous_headings":"15. Example User Workflows","what":"Workflow 4: Memory Profiling","title":"cuplyr: GPU-Accelerated dplyr Backend via libcudf","text":"","code":"# Monitor GPU memory during processing with_gpu_monitor({   big_df <- data.frame(     x = runif(1e8),     y = runif(1e8),     g = sample(letters, 1e8, replace = TRUE)   )    result <- tbl_gpu(big_df) %>%     filter(x > 0.5) %>%     group_by(g) %>%     summarise(mean_y = mean(y)) %>%     collect() }) #> #> GPU Memory Delta: #>   Before: 38.50 GB free #>   After:  36.89 GB free #>   Change: 1.61 GB"},{"path":[]},{"path":"https://bbtheo.github.io/cuplyr/DEVELOPER_GUIDE.html","id":"gpu-memory-exhaustion","dir":"","previous_headings":"16. Security & Safety Considerations","what":"GPU Memory Exhaustion","title":"cuplyr: GPU-Accelerated dplyr Backend via libcudf","text":"","code":"# R/safety.R  #' Safely execute GPU operations with memory limits #' #' @param expr Expression to evaluate #' @param max_memory_gb Maximum GPU memory to use (GB) #' @param fallback_to_cpu Fall back to CPU if memory exceeded #' @export gpu_safe <- function(expr, max_memory_gb = NULL, fallback_to_cpu = TRUE) {   info <- gpu_info()    if (!is.null(max_memory_gb)) {     max_bytes <- max_memory_gb * 1e9     if (info$memory_free < max_bytes * 0.1) {       if (fallback_to_cpu) {         cli::cli_warn(\"GPU memory low, falling back to CPU\")         return(eval(substitute(expr), envir = parent.frame()))       } else {         cli::cli_abort(\"Insufficient GPU memory: {format_bytes(info$memory_free)} available\")       }     }   }    tryCatch(     expr,     error = function(e) {       if (grepl(\"out of memory|CUDA_ERROR_OUT_OF_MEMORY\", e$message, ignore.case = TRUE)) {         if (fallback_to_cpu) {           cli::cli_warn(\"GPU out of memory, falling back to CPU\")           # Re-evaluate without GPU           # This requires detecting tbl_gpu and converting to df           eval(substitute(expr), envir = parent.frame())         } else {           cli::cli_abort(\"GPU out of memory: {e$message}\")         }       } else {         stop(e)       }     }   ) }"},{"path":"https://bbtheo.github.io/cuplyr/DEVELOPER_GUIDE.html","id":"input-validation","dir":"","previous_headings":"16. Security & Safety Considerations","what":"Input Validation","title":"cuplyr: GPU-Accelerated dplyr Backend via libcudf","text":"","code":"// src/validation.cpp #include <Rcpp.h> #include \"gpu_table.hpp\"  // Validate column index is in bounds void validate_column_index(int idx, int ncol) {     if (idx < 0 || idx >= ncol) {         Rcpp::stop(\"Column index %d out of bounds [0, %d)\", idx, ncol);     } }  // Validate numeric value is finite void validate_finite(double val, const char* param_name) {     if (!std::isfinite(val)) {         Rcpp::stop(\"Parameter '%s' must be finite, got %f\", param_name, val);     } }  // Validate string doesn't contain injection patterns bool is_safe_identifier(const std::string& s) {     // Only allow alphanumeric and underscore     for (char c : s) {         if (!std::isalnum(c) && c != '_') {             return false;         }     }     return !s.empty() && !std::isdigit(s[0]); }  void validate_column_name(const std::string& name) {     if (!is_safe_identifier(name)) {         Rcpp::stop(\"Invalid column name: '%s'. Names must be alphanumeric with underscores.\",                    name.c_str());     } }"},{"path":"https://bbtheo.github.io/cuplyr/DEVELOPER_GUIDE.html","id":"expression-sanitization","dir":"","previous_headings":"16. Security & Safety Considerations","what":"Expression Sanitization","title":"cuplyr: GPU-Accelerated dplyr Backend via libcudf","text":"","code":"# R/sanitize.R  # Allowlist of safe functions for GPU execution SAFE_FUNCTIONS <- c(   # Arithmetic   \"+\", \"-\", \"*\", \"/\", \"^\", \"%%\", \"%/%\",   # Comparison   \">\", \">=\", \"<\", \"<=\", \"==\", \"!=\",   # Logical   \"&\", \"|\", \"!\", \"xor\",   # Math  \"abs\", \"sqrt\", \"exp\", \"log\", \"log10\", \"log2\",   \"sin\", \"cos\", \"tan\", \"asin\", \"acos\", \"atan\",   \"ceiling\", \"floor\", \"round\", \"trunc\",   # Aggregation   \"sum\", \"mean\", \"min\", \"max\", \"sd\", \"var\", \"n\", \"median\",   \"first\", \"last\",   # String (subset)   \"nchar\", \"substr\", \"toupper\", \"tolower\",   # Special   \"is.na\", \"is.null\", \"ifelse\", \"case_when\", \"coalesce\",   # dplyr   \"desc\", \"lag\", \"lead\", \"row_number\", \"between\" )  validate_expression <- function(expr) {   if (is.symbol(expr) || is.atomic(expr)) {     return(TRUE)   }    if (is.call(expr)) {     fn_name <- as.character(expr[[1]])      # Check for forbidden patterns     if (fn_name %in% c(\"system\", \"system2\", \"shell\", \"eval\", \"parse\",                        \"source\", \"readLines\", \"writeLines\", \"file\",                        \".Call\", \".External\", \".C\", \".Fortran\")) {       cli::cli_abort(\"Function '{fn_name}' is not allowed in GPU expressions\")     }      # Warn for unknown functions     if (!fn_name %in% SAFE_FUNCTIONS && !fn_name %in% c(\"(\", \"c\")) {       cli::cli_warn(\"Function '{fn_name}' may not be supported on GPU\")     }      # Recursively validate arguments     for (i in seq_along(expr)[-1]) {       validate_expression(expr[[i]])     }   }    TRUE }"},{"path":[]},{"path":"https://bbtheo.github.io/cuplyr/DEVELOPER_GUIDE.html","id":"rapids-version-upgrade-process","dir":"","previous_headings":"17. Maintenance & Migration Notes","what":"RAPIDS Version Upgrade Process","title":"cuplyr: GPU-Accelerated dplyr Backend via libcudf","text":"","code":"## Upgrading RAPIDS libcudf Version  ### 1. Check Release Notes - Visit https://docs.rapids.ai/notices/rsn/ - Note API changes, deprecations, new features  ### 2. Update Build Configuration ```bash # Update Dockerfile base image sed -i 's/rapidsai\\/base:25.12/rapidsai\\/base:26.02/g' Dockerfile  # Update conda recipe # Edit recipe/meta.yaml: libcudf >=26.02"},{"path":"https://bbtheo.github.io/cuplyr/DEVELOPER_GUIDE.html","id":"id_3-test-compilation","dir":"","previous_headings":"17. Maintenance & Migration Notes","what":"3. Test Compilation","title":"cuplyr: GPU-Accelerated dplyr Backend via libcudf","text":"","code":"# In Docker environment ./configure R CMD build . R CMD check cuplyr_*.tar.gz"},{"path":"https://bbtheo.github.io/cuplyr/DEVELOPER_GUIDE.html","id":"id_4-run-full-test-suite","dir":"","previous_headings":"17. Maintenance & Migration Notes","what":"4. Run Full Test Suite","title":"cuplyr: GPU-Accelerated dplyr Backend via libcudf","text":"","code":"R -e \"testthat::test_package('cuplyr')\""},{"path":"https://bbtheo.github.io/cuplyr/DEVELOPER_GUIDE.html","id":"id_5-update-feature-detection","dir":"","previous_headings":"17. Maintenance & Migration Notes","what":"5. Update Feature Detection","title":"cuplyr: GPU-Accelerated dplyr Backend via libcudf","text":"new APIs available:","code":"# R/compat.R has_cudf_feature <- function(feature) {   switch(feature,     \"distinct_count\" = .Call(`_cuplyr_has_distinct_count`),     \"regex_replace\" = packageVersion(\"cuplyr\") >= \"0.2.0\",     FALSE   ) }"},{"path":"https://bbtheo.github.io/cuplyr/DEVELOPER_GUIDE.html","id":"id_6-document-changes","dir":"","previous_headings":"17. Maintenance & Migration Notes","what":"6. Document Changes","title":"cuplyr: GPU-Accelerated dplyr Backend via libcudf","text":"Update NEWS.md Update README new requirements Update DESCRIPTION SystemRequirements","code":"### CUDA Toolkit Support Matrix  ```r # R/compat.R  CUDA_SUPPORT_MATRIX <- list(   \"25.12\" = list(cuda_min = \"12.0\", cuda_max = \"12.5\", driver_min = \"525.60.13\"),   \"26.02\" = list(cuda_min = \"12.0\", cuda_max = \"12.6\", driver_min = \"535.54.03\") )  check_cuda_compat <- function(rapids_version = NULL) {   # Detect RAPIDS version if not specified   if (is.null(rapids_version)) {     rapids_version <- .Call(`_cuplyr_rapids_version`)   }    compat <- CUDA_SUPPORT_MATRIX[[rapids_version]]   if (is.null(compat)) {     cli::cli_warn(\"Unknown RAPIDS version: {rapids_version}\")     return(invisible(FALSE))   }    cuda_version <- .Call(`_cuplyr_cuda_version`)   driver_version <- .Call(`_cuplyr_driver_version`)    issues <- character()    if (compareVersion(cuda_version, compat$cuda_min) < 0) {     issues <- c(issues, glue::glue(       \"CUDA {cuda_version} is below minimum {compat$cuda_min}\"     ))   }    if (compareVersion(cuda_version, compat$cuda_max) > 0) {     issues <- c(issues, glue::glue(       \"CUDA {cuda_version} is above maximum {compat$cuda_max}\"     ))   }    if (length(issues) > 0) {     cli::cli_warn(c(\"Compatibility issues detected:\", issues))     return(invisible(FALSE))   }    cli::cli_alert_success(\"CUDA/RAPIDS compatibility OK\")   invisible(TRUE) }"},{"path":"https://bbtheo.github.io/cuplyr/DEVELOPER_GUIDE.html","id":"deprecation-policy","dir":"","previous_headings":"17. Maintenance & Migration Notes","what":"Deprecation Policy","title":"cuplyr: GPU-Accelerated dplyr Backend via libcudf","text":"","code":"# R/deprecated.R  #' @name cuplyr-deprecated #' @title Deprecated functions in cuplyr #' #' These functions are deprecated and will be removed in future versions. NULL  # Example deprecation wrapper gpu_table <- function(...) {   lifecycle::deprecate_warn(     when = \"0.2.0\",     what = \"gpu_table()\",     with = \"tbl_gpu()\"   )   tbl_gpu(...) }"},{"path":"https://bbtheo.github.io/cuplyr/DEVELOPER_GUIDE.html","id":"migration-guide-template-planned","dir":"","previous_headings":"17. Maintenance & Migration Notes","what":"Migration Guide Template (Planned)","title":"cuplyr: GPU-Accelerated dplyr Backend via libcudf","text":"Lazy evaluation default (planned): Operations become lazy default NA handling: Now follows R semantics closely filter(x > 10) excludes NA values (like R) Use filter(x > 10 | .na(x)) include NAs","code":"## Migrating from cuplyr 0.x to 1.0  ### Breaking Changes  1. **Function renamed**: `gpu_table()` → `tbl_gpu()`    ```r    # Old    gpu_table(df)    # New    tbl_gpu(df) # Old (eager) result <- tbl_gpu(df) %>% filter(x > 10) # result is immediately computed  # New (lazy) result <- tbl_gpu(df) %>% filter(x > 10) # result is lazy, call collect() or compute() result <- result %>% collect()"},{"path":"https://bbtheo.github.io/cuplyr/DEVELOPER_GUIDE.html","id":"new-features","dir":"","previous_headings":"17. Maintenance & Migration Notes","what":"New Features","title":"cuplyr: GPU-Accelerated dplyr Backend via libcudf","text":"Window functions: lag(), lead(), row_number() String operations: Full stringr compatibility Arrow interop: Zero-copy data exchange","code":""},{"path":"https://bbtheo.github.io/cuplyr/DEVELOPER_GUIDE.html","id":"deprecated","dir":"","previous_headings":"17. Maintenance & Migration Notes","what":"Deprecated","title":"cuplyr: GPU-Accelerated dplyr Backend via libcudf","text":".gpu.data.frame() - use tbl_gpu() instead gpu_collect() - use collect() instead cuplyr/ ├── DESCRIPTION # Package metadata ├── NAMESPACE # Exports imports ├── LICENSE # Apache 2.0 ├── configure # Build configuration script ├── configure.win # Windows stub (unsupported message) ├── README.md # Package README ├── NEWS.md # Changelog ├── .Rbuildignore # Build exclusions ├── R/ │ ├── zzz.R # Package hooks │ ├── tbl-gpu.R # Core class definition │ ├── collect.R # collect() implementation │ ├── filter.R # filter() implementation │ ├── mutate.R # mutate() implementation │ ├── select.R # select() implementation │ ├── group-.R # group_by/ungroup implementation │ ├── summarise.R # summarise() implementation │ ├── gpu.R # GPU availability/details │ ├── gpu-memory.R # Memory inspection/GC helpers │ ├── print.R # tbl_gpu printing │ └── utils.R # Utility functions ├── src/ │ ├── Makevars.# Build template │ ├── gpu_table.hpp # XPtr wrapper header │ ├── cuda_utils.hpp # CUDA error helpers │ ├── ops_common.hpp # Shared op helpers │ ├── transfer_io.cpp # R <-> GPU data transfer │ ├── ops_filter.cpp # Filter operations │ ├── ops_compare.cpp # Compare ops summarise temp cols │ ├── ops_mutate.cpp # Mutate operations │ ├── ops_select.cpp # Select operations │ ├── ops_groupby.cpp # Groupby/summarise ops │ ├── gpu_info.cpp # GPU info/availability │ └── RcppExports.cpp # Generated exports ├── inst/ │ ├── docker/ │ │ └── Dockerfile # Development container │ ├── run_benchmarks.R # Benchmark suite │ └── results/ # Benchmark output ├── tests/ │ ├── testthat.R # Test runner │ └── testthat/ │ ├── helper-cuplyr.R # Test helpers │ ├── test-basic.R # Basic functionality │ ├── test-filter.R # Filter tests │ ├── test-mutate.R # Mutate tests │ ├── test-arrange.R # Arrange tests │ ├── test-group.R # Group tests │ ├── test-join.R # Join tests │ ├── test-integration.R # Integration tests │ └── test-edge-cases.R # Edge case tests ├── man/ # Generated documentation ├── recipe/ │ ├── meta.yaml # Conda recipe │ └── build.sh # Conda build script └── .github/ └── workflows/ └── ci.yml # GitHub Actions CI","code":"## 18. Deliverables Checklist  ### Required Deliverables  | # | Deliverable | Status | Location | |---|-------------|--------|----------| | 1 | Developer Guide (this document) | ✓ | `DEVELOPER_GUIDE.md` | | 2 | R Package Skeleton | ✓ | `cuplyr/` directory | | 3 | Unit Tests (6+) | ✓ | `cuplyr/tests/testthat/` | | 4 | Integration Tests (2+) | ✓ | `cuplyr/tests/testthat/test-integration.R` | | 5 | GitHub Actions CI | ✓ | `cuplyr/.github/workflows/ci.yml` | | 6 | Benchmark Scripts | ✓ | `cuplyr/inst/benchmarks/` | | 7 | Conda Recipe | ✓ | `cuplyr/recipe/meta.yaml` | | 8 | Dockerfile | ✓ | `cuplyr/inst/docker/Dockerfile` |  ### Package File Inventory ### Test Coverage Requirements  | Test File | Tests | Coverage | |-----------|-------|----------| | test-basic.R | 4 | tbl_gpu creation, collect, print, dim | | test-filter.R | 4 | >, <, ==, multiple conditions, NA handling | | test-mutate.R | 3 | arithmetic, new columns, type preservation | | test-arrange.R | 2 | ascending, descending | | test-group.R | 3 | group_by, summarise, ungroup | | test-join.R | 2 | left_join, inner_join | | test-integration.R | 2 | complex pipelines, GPU vs CPU comparison | | test-edge-cases.R | 4 | empty tables, all NA, large data, type edge cases | | **Total** | **24** | |  ---  ## 19. Search Keywords & Primary Resources  ### Search Keywords for Research"},{"path":"https://bbtheo.github.io/cuplyr/DEVELOPER_GUIDE.html","id":"core-technology","dir":"","previous_headings":"","what":"Core Technology","title":"cuplyr: GPU-Accelerated dplyr Backend via libcudf","text":"libcudf API RAPIDS libcudf C API cudf cpp api cudf::table cudf::column cudf::groupby::groupby cudf::binary_operation cudf::apply_boolean_mask cudf::sort","code":""},{"path":"https://bbtheo.github.io/cuplyr/DEVELOPER_GUIDE.html","id":"r-integration","dir":"","previous_headings":"","what":"R Integration","title":"cuplyr: GPU-Accelerated dplyr Backend via libcudf","text":"Rcpp external pointer Rcpp XPtr libcudf Rcpp compiling external libs R package configure CUDA R CMD INSTALL CUDA cpp11 CUDA integration","code":""},{"path":"https://bbtheo.github.io/cuplyr/DEVELOPER_GUIDE.html","id":"dplyr-backend","dir":"","previous_headings":"","what":"dplyr Backend","title":"cuplyr: GPU-Accelerated dplyr Backend via libcudf","text":"dplyr backend implementation dbplyr translation dplyr S3 methods filter mutate vctrs R package pillar tbl_format","code":""},{"path":"https://bbtheo.github.io/cuplyr/DEVELOPER_GUIDE.html","id":"interoperability","dir":"","previous_headings":"","what":"Interoperability","title":"cuplyr: GPU-Accelerated dplyr Backend via libcudf","text":"Arrow C Data Interface nanoarrow R package reticulate RAPIDS cudf arrow integration","code":""},{"path":"https://bbtheo.github.io/cuplyr/DEVELOPER_GUIDE.html","id":"build-and-deploy","dir":"","previous_headings":"","what":"Build and Deploy","title":"cuplyr: GPU-Accelerated dplyr Backend via libcudf","text":"contrib build GPU packages R package GitHub Actions GPU nvidia container toolkit RAPIDS docker images conda-forge GPU packages","code":""},{"path":"https://bbtheo.github.io/cuplyr/DEVELOPER_GUIDE.html","id":"performance","dir":"","previous_headings":"","what":"Performance","title":"cuplyr: GPU-Accelerated dplyr Backend via libcudf","text":"cudf kernel fusion RAPIDS memory management RMM RAPIDS Memory Manager GPU DataFrame performance","code":"### Primary Documentation Resources  | Resource | URL | Use For | |----------|-----|---------| | libcudf API Docs | https://docs.rapids.ai/api/libcudf/stable/ | C++ API reference | | libcudf Developer Guide | https://docs.rapids.ai/api/libcudf/stable/developer_guide | Design patterns | | RAPIDS Installation | https://docs.rapids.ai/install/ | Version requirements | | RAPIDS Support Notices | https://docs.rapids.ai/notices/rsn/ | Compatibility | | cuDF GitHub | https://github.com/rapidsai/cudf | Source, examples | | dbplyr New Backend | https://dbplyr.tidyverse.org/articles/new-backend.html | dplyr backend guide | | dbplyr Translation | https://dbplyr.tidyverse.org/articles/translation-function.html | Expression translation | | fstplyr Implementation | https://krlmlr.github.io/fstplyr/articles/implement.html | Non-DB backend example | | Rcpp Documentation | https://dirk.eddelbuettel.com/code/rcpp/ | C++ integration | | Rcpp XPtr Reference | https://dirk.eddelbuettel.com/code/rcpp/html/classRcpp_1_1XPtr.html | External pointers | | nanoarrow R Package | https://arrow.apache.org/nanoarrow/latest/r/ | Arrow C interface | | Arrow C Data Interface | https://arrow.apache.org/docs/format/CDataInterface.html | Zero-copy spec | | vctrs Package | https://vctrs.r-lib.org/ | Type system | | rlang Package | https://rlang.r-lib.org/ | Quosures, expressions |  ### Example Projects to Study  | Project | URL | Relevance | |---------|-----|-----------| | cudf-python | https://github.com/rapidsai/cudf/tree/main/python | Python bindings pattern | | dbplyr | https://github.com/tidyverse/dbplyr | SQL translation | | dtplyr | https://github.com/tidyverse/dtplyr | data.table backend | | arrow-r | https://github.com/apache/arrow/tree/main/r | Arrow R bindings | | duckplyr | https://github.com/duckdb/duckplyr | DuckDB backend |  ### RAPIDS C++ Headers to Study  ```cpp // Essential headers to understand #include <cudf/table/table.hpp>          // cudf::table #include <cudf/table/table_view.hpp>     // cudf::table_view #include <cudf/column/column.hpp>        // cudf::column #include <cudf/column/column_view.hpp>   // cudf::column_view #include <cudf/types.hpp>                // type_id, data_type #include <cudf/copying.hpp>              // slice, gather, scatter #include <cudf/sorting.hpp>              // sort, sorted_order #include <cudf/stream_compaction.hpp>    // apply_boolean_mask, distinct #include <cudf/groupby.hpp>              // groupby::groupby #include <cudf/aggregation.hpp>          // make_*_aggregation #include <cudf/binaryop.hpp>             // binary_operation #include <cudf/unary.hpp>                // unary_operation #include <cudf/join.hpp>                 // left_join, inner_join #include <cudf/interop.hpp>              // Arrow interop #include <cudf/scalar/scalar.hpp>        // scalar types #include <cudf/scalar/scalar_factories.hpp> #include <rmm/device_buffer.hpp>         // GPU memory #include <rmm/mr/device/per_device_resource.hpp>"},{"path":[]},{"path":"https://bbtheo.github.io/cuplyr/DEVELOPER_GUIDE.html","id":"creating-gpu-tables","dir":"","previous_headings":"Appendix A: Quick Reference Card","what":"Creating GPU Tables","title":"cuplyr: GPU-Accelerated dplyr Backend via libcudf","text":"","code":"# From data.frame gpu_df <- tbl_gpu(df)  # From CSV (via Arrow for efficiency) gpu_df <- tbl_gpu(arrow::read_csv_arrow(\"data.csv\"))  # Check status is_tbl_gpu(gpu_df) dim(gpu_df) names(gpu_df)"},{"path":"https://bbtheo.github.io/cuplyr/DEVELOPER_GUIDE.html","id":"dplyr-verbs","dir":"","previous_headings":"Appendix A: Quick Reference Card","what":"dplyr Verbs","title":"cuplyr: GPU-Accelerated dplyr Backend via libcudf","text":"","code":"# All standard verbs work gpu_df %>%   filter(x > 10) %>%   select(x, y) %>%   mutate(z = x + y) %>%   arrange(desc(z)) %>%   group_by(category) %>%   summarise(     total = sum(z),     avg = mean(z),     n = n()   ) %>%   collect()"},{"path":"https://bbtheo.github.io/cuplyr/DEVELOPER_GUIDE.html","id":"joins","dir":"","previous_headings":"Appendix A: Quick Reference Card","what":"Joins","title":"cuplyr: GPU-Accelerated dplyr Backend via libcudf","text":"","code":"left_join(gpu_df1, gpu_df2, by = \"key\") inner_join(gpu_df1, gpu_df2, by = c(\"k1\" = \"k2\"))"},{"path":"https://bbtheo.github.io/cuplyr/DEVELOPER_GUIDE.html","id":"materialization","dir":"","previous_headings":"Appendix A: Quick Reference Card","what":"Materialization","title":"cuplyr: GPU-Accelerated dplyr Backend via libcudf","text":"","code":"# Execute and return to R collect(gpu_df)  # Execute and keep on GPU compute(gpu_df)"},{"path":"https://bbtheo.github.io/cuplyr/DEVELOPER_GUIDE.html","id":"diagnostics","dir":"","previous_headings":"Appendix A: Quick Reference Card","what":"Diagnostics","title":"cuplyr: GPU-Accelerated dplyr Backend via libcudf","text":"","code":"# GPU info gpu_info()  # Verbose mode options(cuplyr.verbose = TRUE)  # Memory monitoring with_gpu_monitor({   # operations })  # Dump AST dump_ast(lazy_gpu_df)"},{"path":"https://bbtheo.github.io/cuplyr/DEVELOPER_GUIDE.html","id":"safety","dir":"","previous_headings":"Appendix A: Quick Reference Card","what":"Safety","title":"cuplyr: GPU-Accelerated dplyr Backend via libcudf","text":"","code":"# Memory-safe execution gpu_safe({   tbl_gpu(big_df) %>% filter(x > 10) %>% collect() }, max_memory_gb = 10, fallback_to_cpu = TRUE)"},{"path":[]},{"path":[]},{"path":"https://bbtheo.github.io/cuplyr/DEVELOPER_GUIDE.html","id":"diagnostic-commands","dir":"","previous_headings":"Appendix B: Troubleshooting","what":"Diagnostic Commands","title":"cuplyr: GPU-Accelerated dplyr Backend via libcudf","text":"","code":"# Check CUDA nvidia-smi nvcc --version  # Check libcudf ldconfig -p | grep libcudf pkg-config --libs cudf  # Check R can find library R -e \".Call('_cuplyr_check_gpu')\"  # Full diagnostics R -e \"cuplyr::gpu_info()\""},{"path":"https://bbtheo.github.io/cuplyr/DEVELOPER_GUIDE.html","id":"memory-debugging","dir":"","previous_headings":"Appendix B: Troubleshooting","what":"Memory Debugging","title":"cuplyr: GPU-Accelerated dplyr Backend via libcudf","text":"","code":"# Track allocations options(cuplyr.verbose = TRUE)  # Force garbage collection gc()  # Check GPU memory gpu_info()$memory_free  # Use smaller chunks result <- gpu_chunked(big_df, chunk_size = 1e6, function(chunk) {   chunk %>% filter(x > 10) %>% collect() })"},{"path":"https://bbtheo.github.io/cuplyr/DEVELOPER_GUIDE.html","id":"appendix-c-performance-tips","dir":"","previous_headings":"","what":"Appendix C: Performance Tips","title":"cuplyr: GPU-Accelerated dplyr Backend via libcudf","text":"Filter early: Reduce data size expensive operations Stay GPU: Chain operations without collecting Use lazy mode: Let optimizer fuse operations Pre-sort possible: Tell groupby keys sorted Avoid strings possible: Numeric operations faster Chunk large data: Process batches memory-constrained Profile first: Use verbose mode identify bottlenecks End Developer Guide Document Version: 1.0.0 Last Updated: 2025 RAPIDS Target: 25.12+ Maintainer: [Name] §","code":"# Example optimized pipeline result <- tbl_gpu(df) %>%   filter(year >= 2020) %>%          # Filter first   select(year, region, amount) %>%   # Project only needed columns   mutate(amount_adj = amount * 1.1) %>%   group_by(year, region) %>%   summarise(total = sum(amount_adj)) %>%   collect()                          # Single collect at end"},{"path":"https://bbtheo.github.io/cuplyr/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"Apache License","title":"Apache License","text":"Version 2.0, January 2004 <http://www.apache.org/licenses/>","code":""},{"path":[]},{"path":"https://bbtheo.github.io/cuplyr/LICENSE.html","id":"id_1-definitions","dir":"","previous_headings":"Terms and Conditions for use, reproduction, and distribution","what":"1. Definitions","title":"Apache License","text":"“License” shall mean terms conditions use, reproduction, distribution defined Sections 1 9 document. “Licensor” shall mean copyright owner entity authorized copyright owner granting License. “Legal Entity” shall mean union acting entity entities control, controlled , common control entity. purposes definition, “control” means () power, direct indirect, cause direction management entity, whether contract otherwise, (ii) ownership fifty percent (50%) outstanding shares, (iii) beneficial ownership entity. “” (“”) shall mean individual Legal Entity exercising permissions granted License. “Source” form shall mean preferred form making modifications, including limited software source code, documentation source, configuration files. “Object” form shall mean form resulting mechanical transformation translation Source form, including limited compiled object code, generated documentation, conversions media types. “Work” shall mean work authorship, whether Source Object form, made available License, indicated copyright notice included attached work (example provided Appendix ). “Derivative Works” shall mean work, whether Source Object form, based (derived ) Work editorial revisions, annotations, elaborations, modifications represent, whole, original work authorship. purposes License, Derivative Works shall include works remain separable , merely link (bind name) interfaces , Work Derivative Works thereof. “Contribution” shall mean work authorship, including original version Work modifications additions Work Derivative Works thereof, intentionally submitted Licensor inclusion Work copyright owner individual Legal Entity authorized submit behalf copyright owner. purposes definition, “submitted” means form electronic, verbal, written communication sent Licensor representatives, including limited communication electronic mailing lists, source code control systems, issue tracking systems managed , behalf , Licensor purpose discussing improving Work, excluding communication conspicuously marked otherwise designated writing copyright owner “Contribution.” “Contributor” shall mean Licensor individual Legal Entity behalf Contribution received Licensor subsequently incorporated within Work.","code":""},{"path":"https://bbtheo.github.io/cuplyr/LICENSE.html","id":"id_2-grant-of-copyright-license","dir":"","previous_headings":"Terms and Conditions for use, reproduction, and distribution","what":"2. Grant of Copyright License","title":"Apache License","text":"Subject terms conditions License, Contributor hereby grants perpetual, worldwide, non-exclusive, -charge, royalty-free, irrevocable copyright license reproduce, prepare Derivative Works , publicly display, publicly perform, sublicense, distribute Work Derivative Works Source Object form.","code":""},{"path":"https://bbtheo.github.io/cuplyr/LICENSE.html","id":"id_3-grant-of-patent-license","dir":"","previous_headings":"Terms and Conditions for use, reproduction, and distribution","what":"3. Grant of Patent License","title":"Apache License","text":"Subject terms conditions License, Contributor hereby grants perpetual, worldwide, non-exclusive, -charge, royalty-free, irrevocable (except stated section) patent license make, made, use, offer sell, sell, import, otherwise transfer Work, license applies patent claims licensable Contributor necessarily infringed Contribution(s) alone combination Contribution(s) Work Contribution(s) submitted. institute patent litigation entity (including cross-claim counterclaim lawsuit) alleging Work Contribution incorporated within Work constitutes direct contributory patent infringement, patent licenses granted License Work shall terminate date litigation filed.","code":""},{"path":"https://bbtheo.github.io/cuplyr/LICENSE.html","id":"id_4-redistribution","dir":"","previous_headings":"Terms and Conditions for use, reproduction, and distribution","what":"4. Redistribution","title":"Apache License","text":"may reproduce distribute copies Work Derivative Works thereof medium, without modifications, Source Object form, provided meet following conditions: () must give recipients Work Derivative Works copy License; (b) must cause modified files carry prominent notices stating changed files; (c) must retain, Source form Derivative Works distribute, copyright, patent, trademark, attribution notices Source form Work, excluding notices pertain part Derivative Works; (d) Work includes “NOTICE” text file part distribution, Derivative Works distribute must include readable copy attribution notices contained within NOTICE file, excluding notices pertain part Derivative Works, least one following places: within NOTICE text file distributed part Derivative Works; within Source form documentation, provided along Derivative Works; , within display generated Derivative Works, wherever third-party notices normally appear. contents NOTICE file informational purposes modify License. may add attribution notices within Derivative Works distribute, alongside addendum NOTICE text Work, provided additional attribution notices construed modifying License. may add copyright statement modifications may provide additional different license terms conditions use, reproduction, distribution modifications, Derivative Works whole, provided use, reproduction, distribution Work otherwise complies conditions stated License.","code":""},{"path":"https://bbtheo.github.io/cuplyr/LICENSE.html","id":"id_5-submission-of-contributions","dir":"","previous_headings":"Terms and Conditions for use, reproduction, and distribution","what":"5. Submission of Contributions","title":"Apache License","text":"Unless explicitly state otherwise, Contribution intentionally submitted inclusion Work Licensor shall terms conditions License, without additional terms conditions. Notwithstanding , nothing herein shall supersede modify terms separate license agreement may executed Licensor regarding Contributions.","code":""},{"path":"https://bbtheo.github.io/cuplyr/LICENSE.html","id":"id_6-trademarks","dir":"","previous_headings":"Terms and Conditions for use, reproduction, and distribution","what":"6. Trademarks","title":"Apache License","text":"License grant permission use trade names, trademarks, service marks, product names Licensor, except required reasonable customary use describing origin Work reproducing content NOTICE file.","code":""},{"path":"https://bbtheo.github.io/cuplyr/LICENSE.html","id":"id_7-disclaimer-of-warranty","dir":"","previous_headings":"Terms and Conditions for use, reproduction, and distribution","what":"7. Disclaimer of Warranty","title":"Apache License","text":"Unless required applicable law agreed writing, Licensor provides Work (Contributor provides Contributions) “” BASIS, WITHOUT WARRANTIES CONDITIONS KIND, either express implied, including, without limitation, warranties conditions TITLE, NON-INFRINGEMENT, MERCHANTABILITY, FITNESS PARTICULAR PURPOSE. solely responsible determining appropriateness using redistributing Work assume risks associated exercise permissions License.","code":""},{"path":"https://bbtheo.github.io/cuplyr/LICENSE.html","id":"id_8-limitation-of-liability","dir":"","previous_headings":"Terms and Conditions for use, reproduction, and distribution","what":"8. Limitation of Liability","title":"Apache License","text":"event legal theory, whether tort (including negligence), contract, otherwise, unless required applicable law (deliberate grossly negligent acts) agreed writing, shall Contributor liable damages, including direct, indirect, special, incidental, consequential damages character arising result License use inability use Work (including limited damages loss goodwill, work stoppage, computer failure malfunction, commercial damages losses), even Contributor advised possibility damages.","code":""},{"path":"https://bbtheo.github.io/cuplyr/LICENSE.html","id":"id_9-accepting-warranty-or-additional-liability","dir":"","previous_headings":"Terms and Conditions for use, reproduction, and distribution","what":"9. Accepting Warranty or Additional Liability","title":"Apache License","text":"redistributing Work Derivative Works thereof, may choose offer, charge fee , acceptance support, warranty, indemnity, liability obligations /rights consistent License. However, accepting obligations, may act behalf sole responsibility, behalf Contributor, agree indemnify, defend, hold Contributor harmless liability incurred , claims asserted , Contributor reason accepting warranty additional liability. END TERMS CONDITIONS","code":""},{"path":"https://bbtheo.github.io/cuplyr/LICENSE.html","id":"appendix-how-to-apply-the-apache-license-to-your-work","dir":"","previous_headings":"","what":"APPENDIX: How to apply the Apache License to your work","title":"Apache License","text":"apply Apache License work, attach following boilerplate notice, fields enclosed brackets [] replaced identifying information. (Don’t include brackets!) text enclosed appropriate comment syntax file format. also recommend file class name description purpose included “printed page” copyright notice easier identification within third-party archives.","code":"Copyright [yyyy] [name of copyright owner]  Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at    http://www.apache.org/licenses/LICENSE-2.0  Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."},{"path":"https://bbtheo.github.io/cuplyr/articles/complex-analysis.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Complex Data Analysis with cuplyr","text":"vignette demonstrates use cuplyr real-world data analysis workflows. ’ll cover multi-step analytical pipelines, branching analyses, working different data types, patterns handling large datasets efficiently.","code":"library(cuplyr) library(dplyr)"},{"path":"https://bbtheo.github.io/cuplyr/articles/complex-analysis.html","id":"building-analytical-workflows","dir":"Articles","previous_headings":"","what":"Building Analytical Workflows","title":"Complex Data Analysis with cuplyr","text":"Real analysis rarely consists single operation. Let’s walk progressively complex workflows.","code":""},{"path":"https://bbtheo.github.io/cuplyr/articles/complex-analysis.html","id":"example-dataset","dir":"Articles","previous_headings":"Building Analytical Workflows","what":"Example Dataset","title":"Complex Data Analysis with cuplyr","text":"’ll create synthetic sales dataset demonstrate patterns:","code":"set.seed(42) n <- 10000  sales_data <- data.frame(  transaction_id = seq_len(n),  date = as.Date(\"2023-01-01\") + sample(0:364, n, replace = TRUE),  customer_id = sample(1:500, n, replace = TRUE),  product_category = sample(c(\"Electronics\", \"Clothing\", \"Food\", \"Home\", \"Sports\"),                            n, replace = TRUE),  region = sample(c(\"North\", \"South\", \"East\", \"West\"), n, replace = TRUE),  quantity = sample(1:10, n, replace = TRUE),  unit_price = round(runif(n, 5, 500), 2),  discount_pct = sample(c(0, 5, 10, 15, 20), n, replace = TRUE,                        prob = c(0.5, 0.2, 0.15, 0.1, 0.05)) )  # Transfer to GPU gpu_sales <- tbl_gpu(sales_data, lazy = TRUE)"},{"path":"https://bbtheo.github.io/cuplyr/articles/complex-analysis.html","id":"multi-step-revenue-analysis","dir":"Articles","previous_headings":"Building Analytical Workflows","what":"Multi-Step Revenue Analysis","title":"Complex Data Analysis with cuplyr","text":"Let’s compute revenue discounts applied, analyze multiple dimensions:","code":"revenue_analysis <- gpu_sales |>  # Step 1: Calculate derived metrics  mutate(    gross_amount = quantity * unit_price,    discount_amount = gross_amount * discount_pct / 100,    net_revenue = gross_amount - discount_amount  ) |>  # Step 2: Filter to significant transactions  filter(net_revenue > 50) |>  # Step 3: Aggregate by category and region  group_by(product_category, region) |>  summarise(    total_revenue = sum(net_revenue),    total_transactions = n(),    avg_transaction = mean(net_revenue),    total_quantity = sum(quantity)  ) |>  # Step 4: Sort by revenue  arrange(desc(total_revenue)) |>  collect()  head(revenue_analysis, 10)"},{"path":"https://bbtheo.github.io/cuplyr/articles/complex-analysis.html","id":"calculating-metrics-across-groups","dir":"Articles","previous_headings":"Building Analytical Workflows","what":"Calculating Metrics Across Groups","title":"Complex Data Analysis with cuplyr","text":"Compute group-level statistics compare overall metrics:","code":"# Overall metrics overall_stats <- gpu_sales |>  mutate(revenue = quantity * unit_price * (1 - discount_pct/100)) |>  summarise(    total_revenue = sum(revenue),    avg_revenue = mean(revenue),    total_orders = n()  ) |>  collect()  # Per-category metrics category_stats <- gpu_sales |>  mutate(revenue = quantity * unit_price * (1 - discount_pct/100)) |>  group_by(product_category) |>  summarise(    category_revenue = sum(revenue),    category_avg = mean(revenue),    category_orders = n()  ) |>  arrange(desc(category_revenue)) |>  collect()  # Display results overall_stats category_stats"},{"path":"https://bbtheo.github.io/cuplyr/articles/complex-analysis.html","id":"branching-analyses","dir":"Articles","previous_headings":"","what":"Branching Analyses","title":"Complex Data Analysis with cuplyr","text":"Often need run multiple analyses common base. Use compute() materialize intermediate results branch efficiently.","code":""},{"path":"https://bbtheo.github.io/cuplyr/articles/complex-analysis.html","id":"creating-a-shared-base","dir":"Articles","previous_headings":"Branching Analyses","what":"Creating a Shared Base","title":"Complex Data Analysis with cuplyr","text":"","code":"# Prepare base data (filter and add computed columns) base_analysis <- gpu_sales |>  mutate(    revenue = quantity * unit_price * (1 - discount_pct/100),    is_high_value = unit_price > 200,    is_bulk = quantity >= 5  ) |>  filter(revenue > 0) |>  compute()  # Materialize on GPU  # Now branch into different analyses"},{"path":"https://bbtheo.github.io/cuplyr/articles/complex-analysis.html","id":"branch-1-regional-performance","dir":"Articles","previous_headings":"Branching Analyses","what":"Branch 1: Regional Performance","title":"Complex Data Analysis with cuplyr","text":"","code":"regional_performance <- base_analysis |>  group_by(region) |>  summarise(    revenue = sum(revenue),    orders = n(),    high_value_orders = sum(is_high_value),    bulk_orders = sum(is_bulk)  ) |>  mutate(    high_value_pct = high_value_orders * 100 / orders,    bulk_pct = bulk_orders * 100 / orders  ) |>  arrange(desc(revenue)) |>  collect()  regional_performance"},{"path":"https://bbtheo.github.io/cuplyr/articles/complex-analysis.html","id":"branch-2-category-deep-dive","dir":"Articles","previous_headings":"Branching Analyses","what":"Branch 2: Category Deep-Dive","title":"Complex Data Analysis with cuplyr","text":"","code":"category_analysis <- base_analysis |>  group_by(product_category) |>  summarise(    revenue = sum(revenue),    avg_price = mean(unit_price),    avg_quantity = mean(quantity),    orders = n()  ) |>  mutate(    revenue_per_order = revenue / orders  ) |>  arrange(desc(revenue_per_order)) |>  collect()  category_analysis"},{"path":"https://bbtheo.github.io/cuplyr/articles/complex-analysis.html","id":"branch-3-discount-effectiveness","dir":"Articles","previous_headings":"Branching Analyses","what":"Branch 3: Discount Effectiveness","title":"Complex Data Analysis with cuplyr","text":"","code":"discount_analysis <- base_analysis |>  group_by(discount_pct) |>  summarise(    orders = n(),    total_revenue = sum(revenue),    avg_quantity = mean(quantity)  ) |>  mutate(    revenue_share = total_revenue * 100 / sum(total_revenue)  ) |>  arrange(discount_pct) |>  collect()  discount_analysis"},{"path":"https://bbtheo.github.io/cuplyr/articles/complex-analysis.html","id":"working-with-dates","dir":"Articles","previous_headings":"","what":"Working with Dates","title":"Complex Data Analysis with cuplyr","text":"cuplyr supports Date POSIXct columns. ’s work temporal data.","code":""},{"path":"https://bbtheo.github.io/cuplyr/articles/complex-analysis.html","id":"date-based-filtering","dir":"Articles","previous_headings":"Working with Dates","what":"Date-Based Filtering","title":"Complex Data Analysis with cuplyr","text":"","code":"# Filter to Q1 2023 q1_sales <- gpu_sales |>  filter(    date >= as.Date(\"2023-01-01\"),    date < as.Date(\"2023-04-01\")  ) |>  collect()  nrow(q1_sales)"},{"path":"https://bbtheo.github.io/cuplyr/articles/complex-analysis.html","id":"extracting-date-components","dir":"Articles","previous_headings":"Working with Dates","what":"Extracting Date Components","title":"Complex Data Analysis with cuplyr","text":"date component extraction (year, month, day), compute R transferring use integer arithmetic:","code":"# Add date components in R, then transfer sales_with_dates <- sales_data |>  mutate(    month = as.integer(format(date, \"%m\")),    quarter = ceiling(month / 3),    day_of_week = as.integer(format(date, \"%u\"))  # 1=Monday, 7=Sunday  )  # Now analyze on GPU monthly_trend <- tbl_gpu(sales_with_dates, lazy = TRUE) |>  mutate(revenue = quantity * unit_price * (1 - discount_pct/100)) |>  group_by(month) |>  summarise(    monthly_revenue = sum(revenue),    orders = n()  ) |>  arrange(month) |>  collect()  monthly_trend"},{"path":"https://bbtheo.github.io/cuplyr/articles/complex-analysis.html","id":"quarterly-analysis","dir":"Articles","previous_headings":"Working with Dates","what":"Quarterly Analysis","title":"Complex Data Analysis with cuplyr","text":"","code":"quarterly_analysis <- tbl_gpu(sales_with_dates, lazy = TRUE) |>  mutate(revenue = quantity * unit_price * (1 - discount_pct/100)) |>  group_by(quarter, region) |>  summarise(    revenue = sum(revenue),    orders = n()  ) |>  arrange(quarter, desc(revenue)) |>  collect()  quarterly_analysis"},{"path":[]},{"path":"https://bbtheo.github.io/cuplyr/articles/complex-analysis.html","id":"customer-segmentation-by-purchase-behavior","dir":"Articles","previous_headings":"Segmentation Analysis","what":"Customer Segmentation by Purchase Behavior","title":"Complex Data Analysis with cuplyr","text":"","code":"customer_segments <- gpu_sales |>  mutate(revenue = quantity * unit_price * (1 - discount_pct/100)) |>  group_by(customer_id) |>  summarise(    total_spent = sum(revenue),    order_count = n(),    avg_order_value = mean(revenue),    total_items = sum(quantity)  ) |>  collect()  # Segment in R (for complex logic) customer_segments <- customer_segments |>  mutate(    segment = case_when(      total_spent > 5000 & order_count > 20 ~ \"VIP\",      total_spent > 2000 | order_count > 10 ~ \"Regular\",      order_count > 5 ~ \"Occasional\",      TRUE ~ \"New\"    )  )  # Summary by segment table(customer_segments$segment)"},{"path":"https://bbtheo.github.io/cuplyr/articles/complex-analysis.html","id":"product-performance-tiers","dir":"Articles","previous_headings":"Segmentation Analysis","what":"Product Performance Tiers","title":"Complex Data Analysis with cuplyr","text":"","code":"category_performance <- gpu_sales |>  mutate(revenue = quantity * unit_price * (1 - discount_pct/100)) |>  group_by(product_category) |>  summarise(    revenue = sum(revenue),    units_sold = sum(quantity),    avg_price = mean(unit_price),    transactions = n()  ) |>  mutate(    revenue_per_unit = revenue / units_sold  ) |>  arrange(desc(revenue)) |>  collect()  category_performance"},{"path":[]},{"path":"https://bbtheo.github.io/cuplyr/articles/complex-analysis.html","id":"beforeafter-comparison","dir":"Articles","previous_headings":"Comparative Analysis","what":"Before/After Comparison","title":"Complex Data Analysis with cuplyr","text":"Compare metrics across time periods:","code":"# Add period indicator in R sales_with_period <- sales_data |>  mutate(    period = ifelse(date < as.Date(\"2023-07-01\"), \"H1\", \"H2\")  )  period_comparison <- tbl_gpu(sales_with_period, lazy = TRUE) |>  mutate(revenue = quantity * unit_price * (1 - discount_pct/100)) |>  group_by(period, product_category) |>  summarise(    revenue = sum(revenue),    orders = n(),    avg_order = mean(revenue)  ) |>  arrange(product_category, period) |>  collect()  period_comparison"},{"path":"https://bbtheo.github.io/cuplyr/articles/complex-analysis.html","id":"region-to-region-comparison","dir":"Articles","previous_headings":"Comparative Analysis","what":"Region-to-Region Comparison","title":"Complex Data Analysis with cuplyr","text":"","code":"region_metrics <- gpu_sales |>  mutate(revenue = quantity * unit_price * (1 - discount_pct/100)) |>  group_by(region) |>  summarise(    total_revenue = sum(revenue),    total_orders = n(),    avg_order_value = mean(revenue),    avg_quantity = mean(quantity),    avg_discount = mean(discount_pct)  ) |>  collect()  # Calculate indices relative to mean overall_avg <- mean(region_metrics$total_revenue) region_metrics$revenue_index <- region_metrics$total_revenue / overall_avg * 100  region_metrics"},{"path":[]},{"path":"https://bbtheo.github.io/cuplyr/articles/complex-analysis.html","id":"memory-efficient-patterns","dir":"Articles","previous_headings":"Handling Large Datasets","what":"Memory-Efficient Patterns","title":"Complex Data Analysis with cuplyr","text":"working large data, minimize memory usage:","code":"# Pattern 1: Filter early, select only needed columns result <- tbl_gpu(huge_data, lazy = TRUE) |>  filter(status == \"active\") |>      # Reduce rows first  select(id, date, amount, category) |>  # Then reduce columns  mutate(amount_adj = amount * 1.1) |>  group_by(category) |>  summarise(total = sum(amount_adj)) |>  collect()  # Pattern 2: Process in logical segments base <- tbl_gpu(huge_data, lazy = TRUE) |>  filter(date >= start_date, date < end_date) |>  select(required_columns) |>  compute()  # Checkpoint: clear intermediate memory  result <- base |>  # Continue analysis on reduced data  group_by(segment) |>  summarise(metrics) |>  collect()"},{"path":"https://bbtheo.github.io/cuplyr/articles/complex-analysis.html","id":"monitoring-memory-usage","dir":"Articles","previous_headings":"Handling Large Datasets","what":"Monitoring Memory Usage","title":"Complex Data Analysis with cuplyr","text":"","code":"# Check GPU memory state gpu_memory_state()  # After large operations, clean up gpu_gc()"},{"path":"https://bbtheo.github.io/cuplyr/articles/complex-analysis.html","id":"multi-pass-analysis","dir":"Articles","previous_headings":"","what":"Multi-Pass Analysis","title":"Complex Data Analysis with cuplyr","text":"analyses require multiple passes data. Structure efficiently:","code":""},{"path":"https://bbtheo.github.io/cuplyr/articles/complex-analysis.html","id":"pass-1-compute-aggregates","dir":"Articles","previous_headings":"Multi-Pass Analysis","what":"Pass 1: Compute Aggregates","title":"Complex Data Analysis with cuplyr","text":"","code":"# First pass: get category totals category_totals <- gpu_sales |>  mutate(revenue = quantity * unit_price * (1 - discount_pct/100)) |>  group_by(product_category) |>  summarise(category_total = sum(revenue)) |>  collect()  category_totals"},{"path":"https://bbtheo.github.io/cuplyr/articles/complex-analysis.html","id":"pass-2-detailed-analysis-with-context","dir":"Articles","previous_headings":"Multi-Pass Analysis","what":"Pass 2: Detailed Analysis with Context","title":"Complex Data Analysis with cuplyr","text":"","code":"# Add category totals back to data (in R) sales_enriched <- sales_data |>  left_join(category_totals, by = \"product_category\")  # Second pass: analyze with category context regional_share <- tbl_gpu(sales_enriched, lazy = TRUE) |>  mutate(revenue = quantity * unit_price * (1 - discount_pct/100)) |>  group_by(product_category, region) |>  summarise(    region_revenue = sum(revenue),    category_total = max(category_total)  # Same value per group  ) |>  mutate(    region_share = region_revenue * 100 / category_total  ) |>  arrange(product_category, desc(region_share)) |>  collect()  regional_share"},{"path":"https://bbtheo.github.io/cuplyr/articles/complex-analysis.html","id":"building-reusable-analysis-functions","dir":"Articles","previous_headings":"","what":"Building Reusable Analysis Functions","title":"Complex Data Analysis with cuplyr","text":"Encapsulate common patterns functions:","code":"#' Calculate revenue metrics by grouping columns #' #' @param gpu_data A tbl_gpu object with sales data #' @param ... Grouping columns #' @return Collected data frame with revenue metrics calculate_revenue_metrics <- function(gpu_data, ...) {  gpu_data |>    mutate(      gross = quantity * unit_price,      net = gross * (1 - discount_pct/100)    ) |>    group_by(...) |>    summarise(      gross_revenue = sum(gross),      net_revenue = sum(net),      total_discount = sum(gross) - sum(net),      order_count = n(),      avg_order = mean(net)    ) |>    mutate(      discount_rate = total_discount * 100 / gross_revenue    ) |>    arrange(desc(net_revenue)) |>    collect() }  # Use the function by_category <- calculate_revenue_metrics(gpu_sales, product_category) by_region <- calculate_revenue_metrics(gpu_sales, region) by_both <- calculate_revenue_metrics(gpu_sales, product_category, region)  head(by_both, 10)"},{"path":"https://bbtheo.github.io/cuplyr/articles/complex-analysis.html","id":"parameterized-analysis","dir":"Articles","previous_headings":"Building Reusable Analysis Functions","what":"Parameterized Analysis","title":"Complex Data Analysis with cuplyr","text":"","code":"#' Analyze high-value transactions #' #' @param gpu_data A tbl_gpu object #' @param min_value Minimum transaction value #' @param group_col Column to group by analyze_high_value <- function(gpu_data, min_value = 100, group_col) {  group_col <- rlang::enquo(group_col)   gpu_data |>    mutate(transaction_value = quantity * unit_price * (1 - discount_pct/100)) |>    filter(transaction_value >= min_value) |>    group_by(!!group_col) |>    summarise(      high_value_revenue = sum(transaction_value),      high_value_count = n(),      avg_high_value = mean(transaction_value)    ) |>    arrange(desc(high_value_revenue)) |>    collect() }  # Different thresholds high_value_100 <- analyze_high_value(gpu_sales, 100, product_category) high_value_500 <- analyze_high_value(gpu_sales, 500, product_category)  high_value_100 high_value_500"},{"path":"https://bbtheo.github.io/cuplyr/articles/complex-analysis.html","id":"combining-gpu-and-cpu-processing","dir":"Articles","previous_headings":"","what":"Combining GPU and CPU Processing","title":"Complex Data Analysis with cuplyr","text":"operations better suited R. Use hybrid approach:","code":""},{"path":"https://bbtheo.github.io/cuplyr/articles/complex-analysis.html","id":"gpu-for-heavy-lifting","dir":"Articles","previous_headings":"Combining GPU and CPU Processing","what":"GPU for Heavy Lifting","title":"Complex Data Analysis with cuplyr","text":"","code":"# Heavy aggregation on GPU aggregated <- gpu_sales |>  mutate(revenue = quantity * unit_price * (1 - discount_pct/100)) |>  group_by(product_category, region, discount_pct) |>  summarise(    revenue = sum(revenue),    orders = n(),    quantity = sum(quantity)  ) |>  collect()  nrow(aggregated)  # Much smaller than original"},{"path":"https://bbtheo.github.io/cuplyr/articles/complex-analysis.html","id":"r-for-complex-logic","dir":"Articles","previous_headings":"Combining GPU and CPU Processing","what":"R for Complex Logic","title":"Complex Data Analysis with cuplyr","text":"","code":"# Complex categorization in R final_analysis <- aggregated |>  mutate(    performance = case_when(      revenue > quantile(revenue, 0.9) ~ \"Top 10%\",      revenue > quantile(revenue, 0.5) ~ \"Above Average\",      revenue > quantile(revenue, 0.25) ~ \"Below Average\",      TRUE ~ \"Bottom 25%\"    ),    discount_tier = case_when(      discount_pct == 0 ~ \"Full Price\",      discount_pct <= 10 ~ \"Light Discount\",      discount_pct <= 15 ~ \"Moderate Discount\",      TRUE ~ \"Heavy Discount\"    )  ) |>  group_by(performance, discount_tier) |>  summarise(    total_revenue = sum(revenue),    segments = n(),    .groups = \"drop\"  )  final_analysis"},{"path":"https://bbtheo.github.io/cuplyr/articles/complex-analysis.html","id":"error-handling-in-analysis-pipelines","dir":"Articles","previous_headings":"","what":"Error Handling in Analysis Pipelines","title":"Complex Data Analysis with cuplyr","text":"Robust pipelines handle edge cases:","code":"safe_analysis <- function(data, min_rows = 100) {  # Validate input  if (!is.data.frame(data)) {    stop(\"Input must be a data frame\")  }   if (nrow(data) < min_rows) {    warning(\"Dataset has fewer than \", min_rows, \" rows\")  }   # Check required columns  required <- c(\"quantity\", \"unit_price\", \"discount_pct\")  missing <- setdiff(required, names(data))  if (length(missing) > 0) {    stop(\"Missing required columns: \", paste(missing, collapse = \", \"))  }   # Perform analysis  tryCatch({    tbl_gpu(data, lazy = TRUE) |>      mutate(revenue = quantity * unit_price * (1 - discount_pct/100)) |>      filter(revenue > 0) |>      summarise(        total = sum(revenue),        avg = mean(revenue),        n = n()      ) |>      collect()  }, error = function(e) {    message(\"Analysis failed: \", e$message)    data.frame(total = NA, avg = NA, n = 0)  }) }  # Test with valid data safe_analysis(sales_data)"},{"path":"https://bbtheo.github.io/cuplyr/articles/complex-analysis.html","id":"summary-statistics-dashboard","dir":"Articles","previous_headings":"","what":"Summary Statistics Dashboard","title":"Complex Data Analysis with cuplyr","text":"Create comprehensive summary:","code":"create_sales_dashboard <- function(gpu_data) {  # Overall metrics  overall <- gpu_data |>    mutate(revenue = quantity * unit_price * (1 - discount_pct/100)) |>    summarise(      total_revenue = sum(revenue),      total_orders = n(),      total_units = sum(quantity),      avg_order_value = mean(revenue),      avg_discount = mean(discount_pct)    ) |>    collect()   # Top categories  top_categories <- gpu_data |>    mutate(revenue = quantity * unit_price * (1 - discount_pct/100)) |>    group_by(product_category) |>    summarise(revenue = sum(revenue), orders = n()) |>    arrange(desc(revenue)) |>    collect()   # Regional breakdown  regional <- gpu_data |>    mutate(revenue = quantity * unit_price * (1 - discount_pct/100)) |>    group_by(region) |>    summarise(revenue = sum(revenue), orders = n()) |>    arrange(desc(revenue)) |>    collect()   list(    overall = overall,    by_category = top_categories,    by_region = regional,    generated_at = Sys.time()  ) }  dashboard <- create_sales_dashboard(gpu_sales)  cat(\"=== Sales Dashboard ===\\n\\n\") cat(\"Overall Metrics:\\n\") print(dashboard$overall) cat(\"\\nBy Category:\\n\") print(dashboard$by_category) cat(\"\\nBy Region:\\n\") print(dashboard$by_region)"},{"path":"https://bbtheo.github.io/cuplyr/articles/complex-analysis.html","id":"performance-comparison","dir":"Articles","previous_headings":"","what":"Performance Comparison","title":"Complex Data Analysis with cuplyr","text":"Compare GPU vs CPU performance data: small datasets like example, CPU may faster due transfer overhead. GPU advantage becomes clear millions rows.","code":"library(bench)  # Benchmark: GPU vs CPU for aggregation comparison <- bench::mark(  gpu = {    tbl_gpu(sales_data, lazy = TRUE) |>      mutate(revenue = quantity * unit_price * (1 - discount_pct/100)) |>      group_by(product_category, region) |>      summarise(        total = sum(revenue),        avg = mean(revenue),        n = n()      ) |>      collect()  },  cpu = {    sales_data |>      mutate(revenue = quantity * unit_price * (1 - discount_pct/100)) |>      group_by(product_category, region) |>      summarise(        total = sum(revenue),        avg = mean(revenue),        n = n(),        .groups = \"drop\"      )  },  check = FALSE,  min_iterations = 5 )  comparison"},{"path":"https://bbtheo.github.io/cuplyr/articles/complex-analysis.html","id":"next-steps","dir":"Articles","previous_headings":"","what":"Next Steps","title":"Complex Data Analysis with cuplyr","text":"vignette(\"getting-started\") - Basic cuplyr usage vignette(\"query-optimization\") - Understanding optimizer Package documentation specific functions","code":""},{"path":"https://bbtheo.github.io/cuplyr/articles/complex-analysis.html","id":"best-practices-summary","dir":"Articles","previous_headings":"","what":"Best Practices Summary","title":"Complex Data Analysis with cuplyr","text":"Filter select early reduce data size Use lazy mode complex multi-step pipelines Use compute() checkpoint branching Prepare date components R transfer Use hybrid GPU/CPU - GPU aggregation, R complex logic Monitor memory gpu_memory_state() gpu_gc() Encapsulate patterns reusable functions Handle errors gracefully production pipelines","code":""},{"path":"https://bbtheo.github.io/cuplyr/articles/getting-started.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Getting Started with cuplyr","text":"cuplyr dplyr backend executes data manipulation operations NVIDIA GPUs using RAPIDS cuDF library. know dplyr, already know cuplyr - verbs work syntax, just faster large datasets.","code":"library(cuplyr) library(dplyr)"},{"path":"https://bbtheo.github.io/cuplyr/articles/getting-started.html","id":"when-to-use-gpu-acceleration","dir":"Articles","previous_headings":"","what":"When to Use GPU Acceleration","title":"Getting Started with cuplyr","text":"GPU acceleration shines : data millions rows (typically >10M clear benefits) Operations computationally intensive (aggregations, sorting, filtering) ’re exploratory analysis repeated queries small datasets (<100K rows), overhead transferring data GPU often outweighs speedup. Stick regular dplyr cases.","code":""},{"path":"https://bbtheo.github.io/cuplyr/articles/getting-started.html","id":"basic-workflow","dir":"Articles","previous_headings":"","what":"Basic Workflow","title":"Getting Started with cuplyr","text":"typical cuplyr workflow three steps: Transfer data GPU tbl_gpu() Process dplyr verbs (filter, mutate, summarise, etc.) Bring results back collect()","code":""},{"path":"https://bbtheo.github.io/cuplyr/articles/getting-started.html","id":"creating-a-gpu-table","dir":"Articles","previous_headings":"Basic Workflow","what":"Creating a GPU Table","title":"Getting Started with cuplyr","text":"data now GPU memory. original R data frame unchanged.","code":"# Transfer a data frame to GPU memory gpu_cars <- tbl_gpu(mtcars)  # Check that it's on the GPU gpu_cars"},{"path":"https://bbtheo.github.io/cuplyr/articles/getting-started.html","id":"using-dplyr-verbs","dir":"Articles","previous_headings":"Basic Workflow","what":"Using dplyr Verbs","title":"Getting Started with cuplyr","text":"Use familiar dplyr verbs exactly normally:","code":"# Filter rows efficient_cars <- gpu_cars |>   filter(mpg > 25)  # Add computed columns with_kpl <- gpu_cars |>   mutate(kpl = mpg * 0.425144)  # Select specific columns subset <- gpu_cars |>   select(mpg, cyl, hp)  # Sort rows sorted <- gpu_cars |>   arrange(desc(mpg))  # Group and summarize by_cyl <- gpu_cars |>   group_by(cyl) |>   summarise(     avg_mpg = mean(mpg),     avg_hp = mean(hp),     count = n()   )"},{"path":"https://bbtheo.github.io/cuplyr/articles/getting-started.html","id":"collecting-results","dir":"Articles","previous_headings":"Basic Workflow","what":"Collecting Results","title":"Getting Started with cuplyr","text":"Operations build GPU. Use collect() bring results back R:","code":"# Bring the grouped summary back to R result <- by_cyl |>   collect()  result"},{"path":"https://bbtheo.github.io/cuplyr/articles/getting-started.html","id":"a-complete-example","dir":"Articles","previous_headings":"","what":"A Complete Example","title":"Getting Started with cuplyr","text":"’s realistic workflow analyzing mtcars dataset:","code":"analysis <- tbl_gpu(mtcars) |>   # Keep only cars with reasonable fuel economy    filter(mpg > 15) |>   # Calculate power-to-weight ratio   mutate(     power_to_weight = hp / wt,     is_efficient = mpg > 20   ) |>   # Group by number of cylinders   group_by(cyl) |>   # Calculate summary statistics   summarise(     n_cars = n(),     avg_mpg = mean(mpg),     avg_power_ratio = mean(power_to_weight),     best_mpg = max(mpg)   ) |>   # Sort by average MPG descending   arrange(desc(avg_mpg)) |>   # Bring back to R   collect()  analysis"},{"path":"https://bbtheo.github.io/cuplyr/articles/getting-started.html","id":"chaining-multiple-operations","dir":"Articles","previous_headings":"","what":"Chaining Multiple Operations","title":"Getting Started with cuplyr","text":"can chain many operations needed. cuplyr handles execution efficiently:","code":"# Complex pipeline result <- tbl_gpu(mtcars) |>   filter(cyl %in% c(4, 6)) |>   mutate(     efficiency_score = mpg / hp * 100,     weight_class = wt * 1000   ) |>   filter(efficiency_score > 5) |>   select(mpg, cyl, hp, efficiency_score, weight_class) |>   arrange(desc(efficiency_score)) |>   collect()  head(result)"},{"path":[]},{"path":"https://bbtheo.github.io/cuplyr/articles/getting-started.html","id":"filter","dir":"Articles","previous_headings":"Supported Operations","what":"filter()","title":"Getting Started with cuplyr","text":"Filter rows based conditions:","code":"# Comparison operators filter(x > 10) filter(x >= 10) filter(x < 10) filter(x <= 10) filter(x == 10) filter(x != 10)  # Multiple conditions (combined with AND) filter(x > 10, y < 5)  # Column-to-column comparisons filter(col_a > col_b)"},{"path":"https://bbtheo.github.io/cuplyr/articles/getting-started.html","id":"select","dir":"Articles","previous_headings":"Supported Operations","what":"select()","title":"Getting Started with cuplyr","text":"Select reorder columns:","code":"# By name select(mpg, cyl, hp)  # Exclude columns select(-disp, -drat)  # Rename while selecting select(fuel_economy = mpg, cylinders = cyl)  # Helper functions select(starts_with(\"d\")) select(ends_with(\"t\")) select(contains(\"p\"))"},{"path":"https://bbtheo.github.io/cuplyr/articles/getting-started.html","id":"mutate","dir":"Articles","previous_headings":"Supported Operations","what":"mutate()","title":"Getting Started with cuplyr","text":"Create modify columns:","code":"# Arithmetic operations mutate(kpl = mpg * 0.425) mutate(power_ratio = hp / wt) mutate(hp_squared = hp ^ 2)  # Multiple columns at once mutate(   a = x + y,   b = x - y,   c = a * 2  # Can reference newly created columns )  # Replace existing columns mutate(mpg = mpg * 0.425)  # Converts to km/L in place"},{"path":"https://bbtheo.github.io/cuplyr/articles/getting-started.html","id":"arrange","dir":"Articles","previous_headings":"Supported Operations","what":"arrange()","title":"Getting Started with cuplyr","text":"Sort rows:","code":"# Ascending (default) arrange(mpg)  # Descending arrange(desc(mpg))  # Multiple columns arrange(cyl, desc(mpg))"},{"path":"https://bbtheo.github.io/cuplyr/articles/getting-started.html","id":"group_by-summarise","dir":"Articles","previous_headings":"Supported Operations","what":"group_by() + summarise()","title":"Getting Started with cuplyr","text":"Grouped aggregations:","code":"# Available aggregation functions group_by(cyl) |>   summarise(     total = sum(mpg),     average = mean(mpg),     minimum = min(mpg),     maximum = max(mpg),     count = n(),     std_dev = sd(mpg),     variance = var(mpg)   )  # Multiple grouping columns group_by(cyl, gear) |>   summarise(avg_mpg = mean(mpg))"},{"path":"https://bbtheo.github.io/cuplyr/articles/getting-started.html","id":"supported-column-types","dir":"Articles","previous_headings":"","what":"Supported Column Types","title":"Getting Started with cuplyr","text":"cuplyr handles R types:","code":""},{"path":"https://bbtheo.github.io/cuplyr/articles/getting-started.html","id":"execution-modes-eager-vs-lazy","dir":"Articles","previous_headings":"","what":"Execution Modes: Eager vs Lazy","title":"Getting Started with cuplyr","text":"cuplyr supports two execution modes:","code":""},{"path":"https://bbtheo.github.io/cuplyr/articles/getting-started.html","id":"eager-mode-default","dir":"Articles","previous_headings":"Execution Modes: Eager vs Lazy","what":"Eager Mode (Default)","title":"Getting Started with cuplyr","text":"Operations execute immediately. Simple predictable:","code":"# Default: eager execution eager_tbl <- tbl_gpu(mtcars) is_lazy(eager_tbl)  # FALSE  # Each operation runs immediately result <- eager_tbl |>   filter(mpg > 20) |>   # Executes now    mutate(x = hp * 2) |> # Executes now   collect()"},{"path":"https://bbtheo.github.io/cuplyr/articles/getting-started.html","id":"lazy-mode","dir":"Articles","previous_headings":"Execution Modes: Eager vs Lazy","what":"Lazy Mode","title":"Getting Started with cuplyr","text":"Operations deferred optimized execution: Lazy mode enables query optimization like filter pushdown operation fusion. See vignette(\"query-optimization\") details.","code":"# Enable lazy execution lazy_tbl <- tbl_gpu(mtcars, lazy = TRUE) is_lazy(lazy_tbl)  # TRUE  # Operations build an AST without executing pipeline <- lazy_tbl |>   filter(mpg > 20) |>   mutate(x = hp * 2) |>   filter(cyl == 4)  # Check pending operations has_pending_ops(pipeline)  # TRUE  # Execute everything at once (optimized) result <- pipeline |> collect()"},{"path":[]},{"path":"https://bbtheo.github.io/cuplyr/articles/getting-started.html","id":"compute","dir":"Articles","previous_headings":"Controlling Execution","what":"compute()","title":"Getting Started with cuplyr","text":"Execute pending operations keep data GPU:","code":"# Useful when branching into multiple analyses base_data <- tbl_gpu(mtcars, lazy = TRUE) |>   filter(mpg > 15) |>   mutate(power_ratio = hp / wt) |>   compute()  # Execute and materialize on GPU  # Now branch without re-running the filter/mutate analysis_a <- base_data |> filter(cyl == 4) |> collect() analysis_b <- base_data |> filter(cyl == 6) |> collect()"},{"path":"https://bbtheo.github.io/cuplyr/articles/getting-started.html","id":"show_query","dir":"Articles","previous_headings":"Controlling Execution","what":"show_query()","title":"Getting Started with cuplyr","text":"Inspect pending operations lazy mode:","code":"lazy_pipeline <- tbl_gpu(mtcars, lazy = TRUE) |>   filter(mpg > 20) |>   mutate(x = hp * 2)  show_query(lazy_pipeline)"},{"path":"https://bbtheo.github.io/cuplyr/articles/getting-started.html","id":"memory-management","dir":"Articles","previous_headings":"","what":"Memory Management","title":"Getting Started with cuplyr","text":"GPU memory managed automatically R’s garbage collector. tbl_gpu object longer referenced, GPU memory freed. Check GPU memory usage: Force garbage collection needed:","code":"# Current memory state gpu_memory_state() # Clean up unreferenced GPU objects gpu_gc()"},{"path":"https://bbtheo.github.io/cuplyr/articles/getting-started.html","id":"best-practices","dir":"Articles","previous_headings":"","what":"Best Practices","title":"Getting Started with cuplyr","text":"Filter early - Reduce data size expensive operations Select needed columns - Less data process Use lazy mode complex pipelines - Enables optimization Keep data GPU - Avoid repeated transfers compute() Collect late - transfer final results R","code":"# Good: filter and select early result <- tbl_gpu(mtcars, lazy = TRUE) |>   filter(mpg > 20) |>                    # Reduce rows first   select(mpg, cyl, hp, wt) |>            # Reduce columns   mutate(power_ratio = hp / wt) |>       # Now compute   group_by(cyl) |>   summarise(avg_ratio = mean(power_ratio)) |>   collect()                               # Transfer only final result"},{"path":"https://bbtheo.github.io/cuplyr/articles/getting-started.html","id":"error-handling","dir":"Articles","previous_headings":"","what":"Error Handling","title":"Getting Started with cuplyr","text":"cuplyr validates operations provides informative errors:","code":"# Referencing non-existent column try({   tbl_gpu(mtcars) |>     filter(nonexistent_column > 5) })  # Type mismatches are caught try({   tbl_gpu(mtcars) |>     filter(mpg > \"not a number\") })"},{"path":"https://bbtheo.github.io/cuplyr/articles/getting-started.html","id":"next-steps","dir":"Articles","previous_headings":"","what":"Next Steps","title":"Getting Started with cuplyr","text":"vignette(\"query-optimization\") - Deep dive AST optimizer vignette(\"performance-tips\") - Maximizing GPU performance Package documentation: ?tbl_gpu, ?compute, ?gpu_memory_state","code":""},{"path":"https://bbtheo.github.io/cuplyr/articles/getting-started.html","id":"system-requirements","dir":"Articles","previous_headings":"","what":"System Requirements","title":"Getting Started with cuplyr","text":"NVIDIA GPU CUDA support (Compute Capability >= 6.0) CUDA Toolkit >= 12.0 RAPIDS cuDF >= 25.12 R >= 4.3.0","code":""},{"path":"https://bbtheo.github.io/cuplyr/articles/query-optimization.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Query Optimization in cuplyr","text":"use cuplyr lazy mode, operations aren’t executed immediately. Instead, build Abstract Syntax Tree (AST) represents query. execution, AST passes optimizer rewrites query better performance. vignette explains: AST represents operations six optimization passes applied queries filter pushdown works detail optimization matters","code":"library(cuplyr) library(dplyr)"},{"path":"https://bbtheo.github.io/cuplyr/articles/query-optimization.html","id":"the-abstract-syntax-tree-ast","dir":"Articles","previous_headings":"","what":"The Abstract Syntax Tree (AST)","title":"Query Optimization in cuplyr","text":"write dplyr pipeline lazy mode, operation creates node AST. tree grows bottom (source data) top (final operation).","code":"# Create a lazy pipeline pipeline <- tbl_gpu(mtcars, lazy = TRUE) |>   filter(mpg > 20) |>   mutate(power_ratio = hp / wt) |>   select(mpg, cyl, power_ratio) |>   arrange(desc(mpg))  # View the AST show_query(pipeline)"},{"path":"https://bbtheo.github.io/cuplyr/articles/query-optimization.html","id":"ast-node-types","dir":"Articles","previous_headings":"The Abstract Syntax Tree (AST)","what":"AST Node Types","title":"Query Optimization in cuplyr","text":"dplyr verb creates specific node type:","code":""},{"path":"https://bbtheo.github.io/cuplyr/articles/query-optimization.html","id":"how-the-ast-grows","dir":"Articles","previous_headings":"The Abstract Syntax Tree (AST)","what":"How the AST Grows","title":"Query Optimization in cuplyr","text":"operation wraps previous one: source node bottom. Operations stack top. executed, tree traversed bottom top.","code":"# This pipeline: tbl_gpu(mtcars, lazy = TRUE) |>   filter(mpg > 20) |>   mutate(x = hp * 2)  # Creates this AST structure: # mutate[x] #   filter[1 predicates] #     source[11 cols]"},{"path":"https://bbtheo.github.io/cuplyr/articles/query-optimization.html","id":"the-optimization-pipeline","dir":"Articles","previous_headings":"","what":"The Optimization Pipeline","title":"Query Optimization in cuplyr","text":"execution, AST passes six optimization passes order: Projection Pruning - Remove unused columns early Mutate Fusion - Combine consecutive mutates Dead Column Pruning - Remove unused computed columns Filter Pushdown - Move filters closer source Filter Reordering - Cheapest filters first Filter Fusion - Combine simple filters one kernel","code":""},{"path":"https://bbtheo.github.io/cuplyr/articles/query-optimization.html","id":"why-order-matters","dir":"Articles","previous_headings":"The Optimization Pipeline","what":"Why Order Matters","title":"Query Optimization in cuplyr","text":"passes carefully ordered: Projection pruning runs first reduce data width Mutate fusion happens filter pushdown create larger blocks Dead column pruning cleans projection changes Filter passes run last since earlier passes may create new opportunities","code":""},{"path":"https://bbtheo.github.io/cuplyr/articles/query-optimization.html","id":"pass-1-projection-pruning","dir":"Articles","previous_headings":"","what":"Pass 1: Projection Pruning","title":"Query Optimization in cuplyr","text":"pass pushes column selections tree reduce data width early.","code":""},{"path":"https://bbtheo.github.io/cuplyr/articles/query-optimization.html","id":"before-optimization","dir":"Articles","previous_headings":"Pass 1: Projection Pruning","what":"Before Optimization","title":"Query Optimization in cuplyr","text":"","code":"# User writes: tbl_gpu(mtcars, lazy = TRUE) |>   mutate(power_ratio = hp / wt) |>   select(mpg, power_ratio) |>   collect()  # Unoptimized AST processes all 11 columns through mutate"},{"path":"https://bbtheo.github.io/cuplyr/articles/query-optimization.html","id":"after-optimization","dir":"Articles","previous_headings":"Pass 1: Projection Pruning","what":"After Optimization","title":"Query Optimization in cuplyr","text":"optimizer inserts select node mutate fetch columns needed (mpg, hp, wt):","code":"# Optimized execution order: # 1. Select only mpg, hp, wt from source # 2. Compute power_ratio = hp / wt # 3. Select mpg, power_ratio for output  # Benefit: 11 columns -> 3 columns early"},{"path":"https://bbtheo.github.io/cuplyr/articles/query-optimization.html","id":"impact","dir":"Articles","previous_headings":"Pass 1: Projection Pruning","what":"Impact","title":"Query Optimization in cuplyr","text":"wide tables, projection pruning dramatically reduces memory bandwidth. Instead copying columns every operation, needed columns flow pipeline.","code":""},{"path":"https://bbtheo.github.io/cuplyr/articles/query-optimization.html","id":"pass-2-mutate-fusion","dir":"Articles","previous_headings":"","what":"Pass 2: Mutate Fusion","title":"Query Optimization in cuplyr","text":"Consecutive mutate() calls combined safe.","code":""},{"path":"https://bbtheo.github.io/cuplyr/articles/query-optimization.html","id":"before-optimization-1","dir":"Articles","previous_headings":"Pass 2: Mutate Fusion","what":"Before Optimization","title":"Query Optimization in cuplyr","text":"","code":"# User writes (or code generates): tbl_gpu(mtcars, lazy = TRUE) |>   mutate(a = hp + 10) |>   mutate(b = wt * 2) |>   mutate(c = a + b) |>   collect()  # Three separate mutate nodes = three intermediate tables"},{"path":"https://bbtheo.github.io/cuplyr/articles/query-optimization.html","id":"after-optimization-1","dir":"Articles","previous_headings":"Pass 2: Mutate Fusion","what":"After Optimization","title":"Query Optimization in cuplyr","text":"","code":"# Fused into single mutate: # mutate(a = hp + 10, b = wt * 2, c = a + b)  # One intermediate table instead of three"},{"path":"https://bbtheo.github.io/cuplyr/articles/query-optimization.html","id":"fusion-guards","dir":"Articles","previous_headings":"Pass 2: Mutate Fusion","what":"Fusion Guards","title":"Query Optimization in cuplyr","text":"Fusion blocked : Combined expressions exceed 8 (memory bandwidth tradeoff) Circular dependencies exist many intermediate columns reused (>4 intermediates >3 uses )","code":""},{"path":"https://bbtheo.github.io/cuplyr/articles/query-optimization.html","id":"dependency-handling","dir":"Articles","previous_headings":"Pass 2: Mutate Fusion","what":"Dependency Handling","title":"Query Optimization in cuplyr","text":"fusing creates dependencies, expressions topologically sorted:","code":"# Input expressions: #   c = a + b #   a = hp + 10 #   b = wt * 2  # After topological sort: #   a = hp + 10    (no deps) #   b = wt * 2     (no deps) #   c = a + b      (depends on a, b)"},{"path":"https://bbtheo.github.io/cuplyr/articles/query-optimization.html","id":"pass-3-dead-column-pruning","dir":"Articles","previous_headings":"","what":"Pass 3: Dead Column Pruning","title":"Query Optimization in cuplyr","text":"projection pushdown mutate fusion, computed columns may longer used. pass removes .","code":""},{"path":"https://bbtheo.github.io/cuplyr/articles/query-optimization.html","id":"example","dir":"Articles","previous_headings":"Pass 3: Dead Column Pruning","what":"Example","title":"Query Optimization in cuplyr","text":"pass walks backward AST, tracking columns actually required downstream operations.","code":"# User writes: tbl_gpu(mtcars, lazy = TRUE) |>   mutate(     a = hp + 10,     b = wt * 2,     c = mpg * 2   ) |>   select(mpg, a) |>  # Only using 'a', not 'b' or 'c'   collect()  # After dead column pruning: # mutate(a = hp + 10) only - 'b' and 'c' are never computed"},{"path":"https://bbtheo.github.io/cuplyr/articles/query-optimization.html","id":"pass-4-filter-pushdown","dir":"Articles","previous_headings":"","what":"Pass 4: Filter Pushdown","title":"Query Optimization in cuplyr","text":"Filter pushdown one impactful optimizations. moves filter() operations closer data source, reducing number rows processed subsequent operations.","code":""},{"path":"https://bbtheo.github.io/cuplyr/articles/query-optimization.html","id":"the-core-principle","dir":"Articles","previous_headings":"Pass 4: Filter Pushdown","what":"The Core Principle","title":"Query Optimization in cuplyr","text":"Fewer rows = faster everything. filtering early: Less data flows mutate computations Less data sort arrange Less memory bandwidth consumed","code":""},{"path":"https://bbtheo.github.io/cuplyr/articles/query-optimization.html","id":"when-pushdown-happens","dir":"Articles","previous_headings":"Pass 4: Filter Pushdown","what":"When Pushdown Happens","title":"Query Optimization in cuplyr","text":"filter can pushed mutate filter’s predicate columns produced mutate.","code":""},{"path":"https://bbtheo.github.io/cuplyr/articles/query-optimization.html","id":"can-push","dir":"Articles","previous_headings":"Pass 4: Filter Pushdown > When Pushdown Happens","what":"Can Push","title":"Query Optimization in cuplyr","text":"","code":"# This filter can be pushed down: pipeline <- tbl_gpu(mtcars, lazy = TRUE) |>   mutate(power_ratio = hp / wt) |>   filter(mpg > 20) |>  # mpg exists before mutate   collect()  # Optimized order: # 1. filter(mpg > 20) - removes rows first # 2. mutate(power_ratio) - computed on fewer rows"},{"path":"https://bbtheo.github.io/cuplyr/articles/query-optimization.html","id":"cannot-push","dir":"Articles","previous_headings":"Pass 4: Filter Pushdown > When Pushdown Happens","what":"Cannot Push","title":"Query Optimization in cuplyr","text":"","code":"# This filter cannot be pushed: pipeline <- tbl_gpu(mtcars, lazy = TRUE) |>   mutate(power_ratio = hp / wt) |>   filter(power_ratio > 50) |>  # power_ratio created by mutate   collect()  # Must stay in order: # 1. mutate(power_ratio) - creates the column # 2. filter(power_ratio > 50) - uses it"},{"path":"https://bbtheo.github.io/cuplyr/articles/query-optimization.html","id":"pushdown-across-select","dir":"Articles","previous_headings":"Pass 4: Filter Pushdown","what":"Pushdown Across Select","title":"Query Optimization in cuplyr","text":"Filters can also push select() select keeps predicate columns:","code":"# Original: tbl_gpu(data, lazy = TRUE) |>   select(a, b, c) |>   filter(a > 10)  # If select keeps 'a', filter pushes below: # filter(a > 10) # select(a, b, c)"},{"path":"https://bbtheo.github.io/cuplyr/articles/query-optimization.html","id":"the-algorithm","dir":"Articles","previous_headings":"Pass 4: Filter Pushdown","what":"The Algorithm","title":"Query Optimization in cuplyr","text":"filter pushdown algorithm: Recursively process AST root leaves Extract columns used predicates Check input mutate node mutate’s output columns don’t overlap predicate columns, swap Repeat pushdowns possible","code":"# Implementation sketch (from optimizer.R): push_down_filters <- function(ast) {   # Get columns used in filter predicates   filter_cols <- get_predicate_columns(ast$predicates)    if (ast$input$type == \"mutate\") {     mutate_outputs <- get_output_columns(ast$input$expressions)      # Can push if no overlap     if (length(intersect(filter_cols, mutate_outputs)) == 0) {       # Swap: filter goes below mutate       new_filter <- ast_filter(ast$input$input, ast$predicates)       ast$input$input <- new_filter       return(ast$input)  # mutate is now on top     }   }    ast }"},{"path":"https://bbtheo.github.io/cuplyr/articles/query-optimization.html","id":"real-world-impact","dir":"Articles","previous_headings":"Pass 4: Filter Pushdown","what":"Real-World Impact","title":"Query Optimization in cuplyr","text":"Consider 100-million row dataset filter(x > threshold) keeps 10% rows: Wait - total? quite. critical difference memory: Without pushdown: mutate allocates 100M-row output, filter pushdown: filter first (minimal allocation), mutate allocates 10M-row output memory savings compound pipeline. multiple mutates filters, pushdown can reduce peak memory 10x .","code":""},{"path":"https://bbtheo.github.io/cuplyr/articles/query-optimization.html","id":"pass-5-filter-reordering","dir":"Articles","previous_headings":"","what":"Pass 5: Filter Reordering","title":"Query Optimization in cuplyr","text":"multiple filter predicates exist, ’re reordered estimated cost.","code":""},{"path":[]},{"path":"https://bbtheo.github.io/cuplyr/articles/query-optimization.html","id":"example-1","dir":"Articles","previous_headings":"Pass 5: Filter Reordering","what":"Example","title":"Query Optimization in cuplyr","text":"running cheaper filters first, rows eliminated expensive comparisons.","code":"# User writes: filter(expensive_col > other_col, cheap_col > 10)  # Reordered to: filter(cheap_col > 10, expensive_col > other_col)"},{"path":"https://bbtheo.github.io/cuplyr/articles/query-optimization.html","id":"safety-check","dir":"Articles","previous_headings":"Pass 5: Filter Reordering","what":"Safety Check","title":"Query Optimization in cuplyr","text":"Non-deterministic predicates reordered preserve correctness.","code":""},{"path":"https://bbtheo.github.io/cuplyr/articles/query-optimization.html","id":"pass-6-filter-fusion","dir":"Articles","previous_headings":"","what":"Pass 6: Filter Fusion","title":"Query Optimization in cuplyr","text":"Simple scalar predicates can fused single GPU kernel call.","code":""},{"path":"https://bbtheo.github.io/cuplyr/articles/query-optimization.html","id":"before-fusion","dir":"Articles","previous_headings":"Pass 6: Filter Fusion","what":"Before Fusion","title":"Query Optimization in cuplyr","text":"","code":"# Multiple filter conditions: filter(a > 10, b < 20, c == 5)  # Without fusion: three separate filter kernel calls"},{"path":"https://bbtheo.github.io/cuplyr/articles/query-optimization.html","id":"after-fusion","dir":"Articles","previous_headings":"Pass 6: Filter Fusion","what":"After Fusion","title":"Query Optimization in cuplyr","text":"","code":"# Fused: single kernel with AND-mask  # One kernel computes: # mask = (a > 10) & (b < 20) & (c == 5) # apply_boolean_mask(data, mask)"},{"path":"https://bbtheo.github.io/cuplyr/articles/query-optimization.html","id":"fusion-criteria","dir":"Articles","previous_headings":"Pass 6: Filter Fusion","what":"Fusion Criteria","title":"Query Optimization in cuplyr","text":"Filters fused conditions met: predicates simple scalar comparisons (column--column) Operators basic comparisons: ==, !=, >, >=, <, <= 4 predicates (GPU register limits) Column--column comparisons complex expressions remain separate.","code":""},{"path":"https://bbtheo.github.io/cuplyr/articles/query-optimization.html","id":"optimization-barriers","dir":"Articles","previous_headings":"","what":"Optimization Barriers","title":"Query Optimization in cuplyr","text":"operations act barriers prevent optimization across : arrange() - Sort order must respected head() - Row limit must apply specific point summarise() - Aggregation changes row count collapse() - Explicit user barrier","code":""},{"path":"https://bbtheo.github.io/cuplyr/articles/query-optimization.html","id":"why-barriers-exist","dir":"Articles","previous_headings":"Optimization Barriers","what":"Why Barriers Exist","title":"Query Optimization in cuplyr","text":"Consider: Pushing filter past arrange change rows remain.","code":"tbl_gpu(data, lazy = TRUE) |>   arrange(x) |>           # Barrier: establishes order   mutate(rank = row_number()) |>  # Depends on order   filter(rank <= 10)      # Cannot push past arrange!"},{"path":"https://bbtheo.github.io/cuplyr/articles/query-optimization.html","id":"segment-optimization","dir":"Articles","previous_headings":"Optimization Barriers","what":"Segment Optimization","title":"Query Optimization in cuplyr","text":"optimizer handles barriers : Splitting AST barrier points Optimizing segment independently Reconnecting optimized segments","code":"# Pipeline with barrier: tbl_gpu(data, lazy = TRUE) |>   filter(a > 10) |>   mutate(b = a + 1) |>   arrange(b) |>           # Barrier here   filter(c > 5) |>   mutate(d = c + 1)  # Optimized as two segments: # Segment 1: source -> filter(a>10) -> mutate(b) # Segment 2: arrange(b) -> filter(c>5) -> mutate(d)"},{"path":[]},{"path":"https://bbtheo.github.io/cuplyr/articles/query-optimization.html","id":"show_query","dir":"Articles","previous_headings":"Inspecting Optimization","what":"show_query()","title":"Query Optimization in cuplyr","text":"View pending AST optimization:","code":"pipeline <- tbl_gpu(mtcars, lazy = TRUE) |>   mutate(a = hp + 10) |>   filter(mpg > 20) |>   mutate(b = a + wt)  show_query(pipeline)"},{"path":"https://bbtheo.github.io/cuplyr/articles/query-optimization.html","id":"understanding-the-output","dir":"Articles","previous_headings":"Inspecting Optimization","what":"Understanding the Output","title":"Query Optimization in cuplyr","text":"show_query() output shows: Node type key metadata Tree structure via indentation AST depth (number levels) Node count (total operations)","code":""},{"path":[]},{"path":"https://bbtheo.github.io/cuplyr/articles/query-optimization.html","id":"example-1-filter-pushdown-in-action","dir":"Articles","previous_headings":"Practical Examples","what":"Example 1: Filter Pushdown in Action","title":"Query Optimization in cuplyr","text":"","code":"# Without lazy mode: operations execute in written order eager_result <- tbl_gpu(mtcars) |>   mutate(     a = hp + 10,     b = wt * 2,     c = mpg * 3   ) |>   filter(cyl == 4) |>  # Filters after computing all mutates   collect()  # With lazy mode: filter pushes down lazy_result <- tbl_gpu(mtcars, lazy = TRUE) |>   mutate(     a = hp + 10,     b = wt * 2,     c = mpg * 3   ) |>   filter(cyl == 4) |>  # Optimizer moves this before mutate   collect()  # Same result, but lazy version filters first identical(eager_result, lazy_result)"},{"path":"https://bbtheo.github.io/cuplyr/articles/query-optimization.html","id":"example-2-complex-pipeline-optimization","dir":"Articles","previous_headings":"Practical Examples","what":"Example 2: Complex Pipeline Optimization","title":"Query Optimization in cuplyr","text":"example, optimizer: Pushes filter(cyl %% c(4,6), mpg > 18) first mutate Reorders filter predicates (scalar comparisons first) Fuses two filter predicates one kernel Prunes computed columns used downstream","code":"# A realistic analytics query result <- tbl_gpu(mtcars, lazy = TRUE) |>   # Step 1: Feature engineering   mutate(     power_to_weight = hp / wt,     fuel_efficiency = mpg / cyl,     is_powerful = hp > 150   ) |>   # Step 2: Filter to interesting subset   filter(     cyl %in% c(4, 6),     # Can push down (cyl exists)     mpg > 18              # Can push down (mpg exists)   ) |>   # Step 3: More features using filtered data   mutate(     efficiency_score = fuel_efficiency * power_to_weight   ) |>   # Step 4: Aggregate   group_by(cyl) |>   summarise(     avg_score = mean(efficiency_score),     count = n()   ) |>   # Step 5: Final ordering   arrange(desc(avg_score)) |>   collect()  result"},{"path":"https://bbtheo.github.io/cuplyr/articles/query-optimization.html","id":"example-3-when-pushdown-doesnt-help","dir":"Articles","previous_headings":"Practical Examples","what":"Example 3: When Pushdown Doesn’t Help","title":"Query Optimization in cuplyr","text":"","code":"# Filter depends on computed column - cannot push result <- tbl_gpu(mtcars, lazy = TRUE) |>   mutate(power_ratio = hp / wt) |>   filter(power_ratio > 50) |>  # Must stay after mutate   collect()  # This is fine - the optimizer recognizes the dependency nrow(result)"},{"path":[]},{"path":"https://bbtheo.github.io/cuplyr/articles/query-optimization.html","id":"use-lazy-mode-for-complex-pipelines","dir":"Articles","previous_headings":"Performance Tips","what":"1. Use Lazy Mode for Complex Pipelines","title":"Query Optimization in cuplyr","text":"","code":"# Enable lazy mode for optimization benefits tbl_gpu(data, lazy = TRUE) |>   # ... complex pipeline ...   collect()"},{"path":"https://bbtheo.github.io/cuplyr/articles/query-optimization.html","id":"filter-on-source-columns-when-possible","dir":"Articles","previous_headings":"Performance Tips","what":"2. Filter on Source Columns When Possible","title":"Query Optimization in cuplyr","text":"","code":"# Good: filter uses source columns tbl_gpu(data, lazy = TRUE) |>   filter(status == \"active\", date > cutoff) |>  # Can push down   mutate(computed = complex_calculation(a, b))  # Less optimal: filter uses computed column tbl_gpu(data, lazy = TRUE) |>   mutate(computed = complex_calculation(a, b)) |>   filter(computed > threshold)  # Cannot push down"},{"path":"https://bbtheo.github.io/cuplyr/articles/query-optimization.html","id":"let-the-optimizer-reorder","dir":"Articles","previous_headings":"Performance Tips","what":"3. Let the Optimizer Reorder","title":"Query Optimization in cuplyr","text":"Write filters logical order. optimizer reorder cost:","code":"# Write for readability filter(   department == \"Engineering\",   # May be expensive   is_active == TRUE,             # Cheap   salary > 50000                 # Cheap )  # Optimizer reorders to: is_active, salary, department"},{"path":"https://bbtheo.github.io/cuplyr/articles/query-optimization.html","id":"use-collapse-for-control","dir":"Articles","previous_headings":"Performance Tips","what":"4. Use collapse() for Control","title":"Query Optimization in cuplyr","text":"need prevent optimization across boundary:","code":"tbl_gpu(data, lazy = TRUE) |>   filter(x > 10) |>   mutate(y = f(x)) |>   collapse() |>            # Barrier: optimize above and below separately   filter(z > 5) |>   collect()"},{"path":"https://bbtheo.github.io/cuplyr/articles/query-optimization.html","id":"conclusion","dir":"Articles","previous_headings":"","what":"Conclusion","title":"Query Optimization in cuplyr","text":"cuplyr’s query optimizer automatically improves pipelines : Projection pruning: process needed columns Mutate fusion: Reduce intermediate allocations Dead column pruning: Skip unnecessary computations Filter pushdown: Process fewer rows earlier Filter reordering: Cheap filters first Filter fusion: Combine filters single kernels workloads, simply use lazy mode write natural dplyr code. optimizer handles rest.","code":"# Just write natural dplyr: result <- tbl_gpu(big_data, lazy = TRUE) |>   mutate(derived = complex_expr) |>   filter(source_col > threshold) |>  # Automatically pushed down   group_by(category) |>   summarise(total = sum(derived)) |>   collect()"},{"path":"https://bbtheo.github.io/cuplyr/articles/query-optimization.html","id":"further-reading","dir":"Articles","previous_headings":"","what":"Further Reading","title":"Query Optimization in cuplyr","text":"vignette(\"getting-started\") - Basic cuplyr usage ?optimize_ast - Internal optimizer documentation RAPIDS cuDF documentation GPU-specific optimizations","code":""},{"path":"https://bbtheo.github.io/cuplyr/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Theo Blauberg. Author, maintainer. RAPIDS Team. Copyright holder.           libcudf library","code":""},{"path":"https://bbtheo.github.io/cuplyr/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Blauberg T (2026). cuplyr: GPU-Accelerated Data Manipulation dplyr Syntax. R package version 0.1.0, https://github.com/bbtheo/cuplyr.","code":"@Manual{,   title = {cuplyr: GPU-Accelerated Data Manipulation with dplyr Syntax},   author = {Theo Blauberg},   year = {2026},   note = {R package version 0.1.0},   url = {https://github.com/bbtheo/cuplyr}, }"},{"path":[]},{"path":"https://bbtheo.github.io/cuplyr/index.html","id":"dplyr-backend-for-gpu-acceleration-via-rapids-cudf","dir":"","previous_headings":"","what":"dplyr backend for GPU acceleration via RAPIDS cuDF","title":"cuplyr","text":"cuplyr implements dplyr backend powered RAPIDS cuDF, NVIDIA’s GPU DataFrame library. Write standard dplyr code, execute GPU hardware.","code":"library(cuplyr)  tbl_gpu(sales_data, lazy = TRUE) |>   filter(year >= 2020, amount > 0) |>   mutate(revenue = amount * price) |>   group_by(region, quarter) |>   summarise(total = sum(revenue)) |>   inner_join(regions, by = \"region\") |>   arrange(desc(total)) |>   collect()"},{"path":"https://bbtheo.github.io/cuplyr/index.html","id":"about","dir":"","previous_headings":"","what":"About","title":"cuplyr","text":"cuplyr translates dplyr operations cuDF execution NVIDIA GPUs. follows backend pattern dbplyr: write standard R code, execute GPU hardware. approach can provide significant speedups larger datasets (typically >1M rows) without requiring major code changes. Built RAPIDS cuDF: cuDF open-source GPU DataFrame library developed NVIDIA’s RAPIDS team. provides optimized CUDA kernels data manipulation operations, backed Apache Arrow’s columnar memory format. cuplyr provides R interface execution engine.","code":""},{"path":"https://bbtheo.github.io/cuplyr/index.html","id":"status","dir":"","previous_headings":"","what":"Status","title":"cuplyr","text":"v0.1.0 experimental software active development. Breaking changes expected.","code":""},{"path":"https://bbtheo.github.io/cuplyr/index.html","id":"supported-operations","dir":"","previous_headings":"Status","what":"Supported operations","title":"cuplyr","text":"Data manipulation - filter() – row filtering comparison logical operators - select() – column selection reordering - mutate() – column transformations arithmetic - arrange() – row sorting desc() support, NA handling follows dplyr conventions - group_by() + summarise() – grouped aggregations (sum, mean, min, max, n) - left_join(), right_join(), inner_join(), full_join() – GPU joins key columns - collect() – transfer results back R - compute() – execute lazy operations, keep GPU - tbl_gpu(..., lazy = TRUE) – enable lazy evaluation AST optimization","code":""},{"path":"https://bbtheo.github.io/cuplyr/index.html","id":"lazy-evaluation","dir":"","previous_headings":"Status","what":"Lazy evaluation","title":"cuplyr","text":"Lazy mode defers execution collect() compute(), enabling automatic optimizations: - Projection pruning (drop unused columns early) - Filter pushdown (move filters closer data sources) - Mutate fusion (combine consecutive transformations)","code":"# Enable globally options(cuplyr.exec_mode = \"lazy\")  # Or per-table tbl_gpu(data, lazy = TRUE)"},{"path":[]},{"path":"https://bbtheo.github.io/cuplyr/index.html","id":"not-yet-implemented","dir":"","previous_headings":"Status","what":"Not yet implemented","title":"cuplyr","text":"Complex joins join_by() Window functions String operations Multi-GPU support Contributions feedback welcome.","code":""},{"path":"https://bbtheo.github.io/cuplyr/index.html","id":"architecture","dir":"","previous_headings":"","what":"Architecture","title":"cuplyr","text":"R layer: S3 methods implementing dplyr generics AST optimizer: Projection pruning, filter pushdown, operation fusion Native bindings: Rcpp interface libcudf C++ API Execution: cuDF GPU kernels via libcudf Memory: GPU-resident data automatic cleanup via R garbage collection","code":""},{"path":[]},{"path":"https://bbtheo.github.io/cuplyr/index.html","id":"requirements","dir":"","previous_headings":"Installation","what":"Requirements","title":"cuplyr","text":"NVIDIA GPU Compute Capability >= 6.0 CUDA Toolkit >= 12.0 RAPIDS libcudf >= 25.12 R >= 4.3","code":""},{"path":"https://bbtheo.github.io/cuplyr/index.html","id":"using-pixi-recommended","dir":"","previous_headings":"Installation","what":"Using pixi (recommended)","title":"cuplyr","text":"","code":"# Install pixi if not already installed (https://pixi.sh) # curl -fsSL https://pixi.sh/install.sh | bash  git clone https://github.com/bbtheo/cuplyr.git cd cuplyr pixi run install"},{"path":"https://bbtheo.github.io/cuplyr/index.html","id":"from-source","dir":"","previous_headings":"Installation","what":"From source","title":"cuplyr","text":"","code":"git clone https://github.com/bbtheo/cuplyr.git cd cuplyr  # Ensure CUDA and cuDF are available, then: R CMD INSTALL ."},{"path":"https://bbtheo.github.io/cuplyr/index.html","id":"performance","dir":"","previous_headings":"","what":"Performance","title":"cuplyr","text":"Benchmark code lives benchmark/benchmark.R. Benchmarks 25 million rows (synthetic taxi data, median 10 iterations): Complete workflow: filter + mutate + group_by + summarise Hardware: Intel Core i9-12900K (16 cores), NVIDIA RTX 5070 (12 GB VRAM) End--end workflow including materialization/transfer: GPU acceleration benefits grow data size compute intensity. transfer-heavy workloads smaller datasets, CPU-based engines can still faster.","code":""},{"path":"https://bbtheo.github.io/cuplyr/index.html","id":"acknowledgments","dir":"","previous_headings":"","what":"Acknowledgments","title":"cuplyr","text":"project built RAPIDS cuDF NVIDIA RAPIDS AI team. License: Apache 2.0 Maintainer: @bbtheo Documentation: DEVELOPER_GUIDE.md","code":""},{"path":"https://bbtheo.github.io/cuplyr/reference/as_tbl_gpu.html","id":null,"dir":"Reference","previous_headings":"","what":"Coerce to a GPU table — as_tbl_gpu","title":"Coerce to a GPU table — as_tbl_gpu","text":"Converts data frame compatible object tbl_gpu object, transferring data GPU memory.","code":""},{"path":"https://bbtheo.github.io/cuplyr/reference/as_tbl_gpu.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Coerce to a GPU table — as_tbl_gpu","text":"","code":"as_tbl_gpu(x, ...)"},{"path":"https://bbtheo.github.io/cuplyr/reference/as_tbl_gpu.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Coerce to a GPU table — as_tbl_gpu","text":"x data frame object coercible data frame. ... Additional arguments passed tbl_gpu().","code":""},{"path":"https://bbtheo.github.io/cuplyr/reference/as_tbl_gpu.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Coerce to a GPU table — as_tbl_gpu","text":"tbl_gpu object data stored GPU.","code":""},{"path":[]},{"path":"https://bbtheo.github.io/cuplyr/reference/as_tbl_gpu.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Coerce to a GPU table — as_tbl_gpu","text":"","code":"if (has_gpu()) {   gpu_df <- as_tbl_gpu(iris)   print(gpu_df) } #> Rows: 150 #> Columns: 5 #> $ Sepal.Length <dbl> 5.1, 4.9, 4.7, 4.6, 5, 5.4, 4.6, 5, 4.4, 4.9 #> $ Sepal.Width  <dbl> 3.5, 3, 3.2, 3.1, 3.6, 3.9, 3.4, 3.4, 2.9, 3.1 #> $ Petal.Length <dbl> 1.4, 1.4, 1.3, 1.5, 1.4, 1.7, 1.4, 1.5, 1.4, 1.5 #> $ Petal.Width  <dbl> 0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.3, 0.2, 0.2, 0.1 #> $ Species      <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1"},{"path":"https://bbtheo.github.io/cuplyr/reference/collect.tbl_gpu.html","id":null,"dir":"Reference","previous_headings":"","what":"Transfer GPU table data back to R — collect.tbl_gpu","title":"Transfer GPU table data back to R — collect.tbl_gpu","text":"Copies data GPU memory back R tibble. typically final step GPU data manipulation pipeline, filtering, mutating, selecting data need.","code":""},{"path":"https://bbtheo.github.io/cuplyr/reference/collect.tbl_gpu.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Transfer GPU table data back to R — collect.tbl_gpu","text":"","code":"# S3 method for class 'tbl_gpu' collect(x, ...)"},{"path":"https://bbtheo.github.io/cuplyr/reference/collect.tbl_gpu.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Transfer GPU table data back to R — collect.tbl_gpu","text":"x tbl_gpu object created tbl_gpu(). ... Additional arguments (ignored, included compatibility).","code":""},{"path":"https://bbtheo.github.io/cuplyr/reference/collect.tbl_gpu.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Transfer GPU table data back to R — collect.tbl_gpu","text":"tibble::tibble containing data GPU table. Column types converted back R types: FLOAT64/FLOAT32 -> numeric (double) INT32/INT64 -> integer numeric STRING -> character BOOL8 -> integer (0/1)","code":""},{"path":[]},{"path":"https://bbtheo.github.io/cuplyr/reference/collect.tbl_gpu.html","id":"memory-considerations","dir":"Reference","previous_headings":"","what":"Memory considerations","title":"Transfer GPU table data back to R — collect.tbl_gpu","text":"Collecting transfers data GPU CPU memory. large datasets, can slow memory-intensive. Best practice : Filter rows reduce data volume Select needed columns collect results","code":""},{"path":"https://bbtheo.github.io/cuplyr/reference/collect.tbl_gpu.html","id":"performance","dir":"Reference","previous_headings":"","what":"Performance","title":"Transfer GPU table data back to R — collect.tbl_gpu","text":"Data transfer GPU CPU limited PCIe bandwidth (typically 16-32 GB/s). 1 GB dataset, expect ~50-100ms transfer time.","code":""},{"path":[]},{"path":"https://bbtheo.github.io/cuplyr/reference/collect.tbl_gpu.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Transfer GPU table data back to R — collect.tbl_gpu","text":"","code":"if (has_gpu()) {   gpu_mtcars <- tbl_gpu(mtcars)    # Process on GPU, then collect   result <- gpu_mtcars |>     filter(mpg > 20) |>     mutate(kpl = mpg * 0.425) |>     select(mpg, kpl, hp) |>     collect()    # Result is a regular tibble   class(result)   print(result) } #> Error in collect(select(mutate(filter(gpu_mtcars, mpg > 20), kpl = mpg *     0.425), mpg, kpl, hp)): could not find function \"collect\""},{"path":"https://bbtheo.github.io/cuplyr/reference/dim.tbl_gpu.html","id":null,"dir":"Reference","previous_headings":"","what":"Get dimensions of a GPU table — dim.tbl_gpu","title":"Get dimensions of a GPU table — dim.tbl_gpu","text":"Returns number rows columns GPU table.","code":""},{"path":"https://bbtheo.github.io/cuplyr/reference/dim.tbl_gpu.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get dimensions of a GPU table — dim.tbl_gpu","text":"","code":"# S3 method for class 'tbl_gpu' dim(x)"},{"path":"https://bbtheo.github.io/cuplyr/reference/dim.tbl_gpu.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get dimensions of a GPU table — dim.tbl_gpu","text":"x tbl_gpu object.","code":""},{"path":"https://bbtheo.github.io/cuplyr/reference/dim.tbl_gpu.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get dimensions of a GPU table — dim.tbl_gpu","text":"integer vector length 2: c(nrow, ncol). Returns `c(NA, ncol)","code":""},{"path":"https://bbtheo.github.io/cuplyr/reference/dim.tbl_gpu.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get dimensions of a GPU table — dim.tbl_gpu","text":"","code":"if (has_gpu()) {    } #> NULL"},{"path":"https://bbtheo.github.io/cuplyr/reference/filter.tbl_gpu.html","id":null,"dir":"Reference","previous_headings":"","what":"Filter rows of a GPU table — filter.tbl_gpu","title":"Filter rows of a GPU table — filter.tbl_gpu","text":"Selects rows GPU table conditions TRUE, similar dplyr::filter(). Filtering performed entirely GPU maximum performance large datasets.","code":""},{"path":"https://bbtheo.github.io/cuplyr/reference/filter.tbl_gpu.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Filter rows of a GPU table — filter.tbl_gpu","text":"","code":"# S3 method for class 'tbl_gpu' filter(.data, ..., .preserve = FALSE)"},{"path":"https://bbtheo.github.io/cuplyr/reference/filter.tbl_gpu.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Filter rows of a GPU table — filter.tbl_gpu","text":".data tbl_gpu object created tbl_gpu(). ... Logical expressions filter . expression comparison form column <op> value column <op> column. Multiple conditions combined (must TRUE). .preserve Ignored. Included compatibility dplyr generic.","code":""},{"path":"https://bbtheo.github.io/cuplyr/reference/filter.tbl_gpu.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Filter rows of a GPU table — filter.tbl_gpu","text":"tbl_gpu object containing rows conditions TRUE. GPU memory filtered result newly allocated.","code":""},{"path":[]},{"path":"https://bbtheo.github.io/cuplyr/reference/filter.tbl_gpu.html","id":"supported-comparison-operators","dir":"Reference","previous_headings":"","what":"Supported comparison operators","title":"Filter rows of a GPU table — filter.tbl_gpu","text":"== - equal != - equal > - greater >= - greater equal < - less <= - less equal ","code":""},{"path":"https://bbtheo.github.io/cuplyr/reference/filter.tbl_gpu.html","id":"current-limitations","dir":"Reference","previous_headings":"","what":"Current limitations","title":"Filter rows of a GPU table — filter.tbl_gpu","text":"simple comparisons supported (column op value/column) Compound expressions & | yet supported String comparisons yet implemented numeric scalar values right-hand side","code":""},{"path":"https://bbtheo.github.io/cuplyr/reference/filter.tbl_gpu.html","id":"performance","dir":"Reference","previous_headings":"","what":"Performance","title":"Filter rows of a GPU table — filter.tbl_gpu","text":"Filtering GPU highly parallel can process billions rows per second. best performance, chain multiple filter conditions rather using compound expressions.","code":""},{"path":[]},{"path":"https://bbtheo.github.io/cuplyr/reference/filter.tbl_gpu.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Filter rows of a GPU table — filter.tbl_gpu","text":"","code":"if (has_gpu()) {   gpu_mtcars <- tbl_gpu(mtcars)    # Filter with single condition   efficient_cars <- gpu_mtcars |>     filter(mpg > 25)    # Multiple conditions (combined with AND)   result <- gpu_mtcars |>     filter(mpg > 20) |>     filter(cyl == 4) |>     collect()    # Compare two columns   gpu_cars <- tbl_gpu(cars)   fast_stops <- gpu_cars |>     filter(dist < speed) |>     collect() } #> Error in storage.mode(x) <- \"double\": 'list' object cannot be coerced to type 'double'"},{"path":"https://bbtheo.github.io/cuplyr/reference/gpu_details.html","id":null,"dir":"Reference","previous_headings":"","what":"Get detailed GPU information — gpu_details","title":"Get detailed GPU information — gpu_details","text":"Retrieves comprehensive information available GPU including device name, compute capability, memory capacity, multiprocessor count.","code":""},{"path":"https://bbtheo.github.io/cuplyr/reference/gpu_details.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get detailed GPU information — gpu_details","text":"","code":"gpu_details()"},{"path":"https://bbtheo.github.io/cuplyr/reference/gpu_details.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get detailed GPU information — gpu_details","text":"named list GPU details: available Logical: TRUE GPU available device_count Number CUDA devices device_id ID current device (0-indexed) name GPU model name (e.g., \"NVIDIA GeForce RTX 4090\") compute_capability CUDA compute capability (e.g., \"8.9\") total_memory Total GPU memory bytes free_memory Currently available GPU memory bytes multiprocessors Number streaming multiprocessors (SMs) GPU available, returns list(available = FALSE, device_count = 0).","code":""},{"path":[]},{"path":"https://bbtheo.github.io/cuplyr/reference/gpu_details.html","id":"compute-capability","dir":"Reference","previous_headings":"","what":"Compute capability","title":"Get detailed GPU information — gpu_details","text":"compute capability indicates GPU architecture supported features: 7.x - Volta/Turing (V100, RTX 20 series) 8.x - Ampere (A100, RTX 30 series) 8.9 - Ada Lovelace (RTX 40 series) 9.x - Hopper (H100) 10.x+ - Blackwell newer","code":""},{"path":"https://bbtheo.github.io/cuplyr/reference/gpu_details.html","id":"memory","dir":"Reference","previous_headings":"","what":"Memory","title":"Get detailed GPU information — gpu_details","text":"free_memory value reflects memory available time call. applications CUDA contexts may using GPU memory.","code":""},{"path":[]},{"path":"https://bbtheo.github.io/cuplyr/reference/gpu_details.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get detailed GPU information — gpu_details","text":"","code":"info <- gpu_details() if (info$available) {   cat(\"GPU:\", info$name, \"\\n\")   cat(\"Memory:\", round(info$total_memory / 1e9, 1), \"GB\\n\")   cat(\"Compute:\", info$compute_capability, \"\\n\") } #> GPU: NVIDIA GeForce RTX 5070  #> Memory: 12.3 GB #> Compute: 12.0"},{"path":"https://bbtheo.github.io/cuplyr/reference/gpu_memory_state.html","id":null,"dir":"Reference","previous_headings":"","what":"Get GPU memory snapshot — gpu_memory_state","title":"Get GPU memory snapshot — gpu_memory_state","text":"Returns current GPU memory state including total, free, used memory. Useful monitoring GPU memory usage operations.","code":""},{"path":"https://bbtheo.github.io/cuplyr/reference/gpu_memory_state.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get GPU memory snapshot — gpu_memory_state","text":"","code":"gpu_memory_state()"},{"path":"https://bbtheo.github.io/cuplyr/reference/gpu_memory_state.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get GPU memory snapshot — gpu_memory_state","text":"list : available Logical: TRUE GPU available total_bytes Total GPU memory bytes free_bytes Free GPU memory bytes used_bytes Used GPU memory bytes total_gb Total GPU memory gigabytes free_gb Free GPU memory gigabytes used_gb Used GPU memory gigabytes","code":""},{"path":[]},{"path":"https://bbtheo.github.io/cuplyr/reference/gpu_memory_state.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get GPU memory snapshot — gpu_memory_state","text":"","code":"if (has_gpu()) {   # Check memory before allocation   before <- gpu_memory_state()    # Allocate some GPU data   gpu_df <- tbl_gpu(data.frame(x = runif(1000000)))    # Check memory after allocation   after <- gpu_memory_state()    cat(\"Memory used:\", after$used_gb - before$used_gb, \"GB\\n\") } #> Memory used: 0.008388608 GB"},{"path":"https://bbtheo.github.io/cuplyr/reference/gpu_memory_usage.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate GPU memory usage of a tbl_gpu object — gpu_memory_usage","title":"Estimate GPU memory usage of a tbl_gpu object — gpu_memory_usage","text":"Calculates estimated GPU memory footprint GPU table based dimensions column types. useful understanding memory requirements working large datasets.","code":""},{"path":"https://bbtheo.github.io/cuplyr/reference/gpu_memory_usage.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate GPU memory usage of a tbl_gpu object — gpu_memory_usage","text":"","code":"gpu_memory_usage(x)"},{"path":"https://bbtheo.github.io/cuplyr/reference/gpu_memory_usage.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate GPU memory usage of a tbl_gpu object — gpu_memory_usage","text":"x tbl_gpu object.","code":""},{"path":"https://bbtheo.github.io/cuplyr/reference/gpu_memory_usage.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate GPU memory usage of a tbl_gpu object — gpu_memory_usage","text":"estimated memory usage bytes (numeric), NA object valid tbl_gpu data GPU.","code":""},{"path":"https://bbtheo.github.io/cuplyr/reference/gpu_memory_usage.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Estimate GPU memory usage of a tbl_gpu object — gpu_memory_usage","text":"estimate includes: Column data (varies type: 8 bytes FLOAT64, 4 bytes INT32, etc.) Validity bitmasks NA handling (1 bit per row per column) String columns use average estimate 32 bytes per element, may vary significantly based actual string lengths. estimate actual GPU memory usage may higher due : Memory alignment requirements RMM memory pool overhead Temporary allocations","code":""},{"path":[]},{"path":"https://bbtheo.github.io/cuplyr/reference/gpu_memory_usage.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimate GPU memory usage of a tbl_gpu object — gpu_memory_usage","text":"","code":"if (has_gpu()) {   gpu_mtcars <- tbl_gpu(mtcars)   size <- gpu_memory_usage(gpu_mtcars)   cat(\"Estimated GPU memory:\", round(size / 1024, 1), \"KB\\n\") } #> Estimated GPU memory: 2.8 KB"},{"path":"https://bbtheo.github.io/cuplyr/reference/gpu_object_info.html","id":null,"dir":"Reference","previous_headings":"","what":"Get detailed information about a GPU table object — gpu_object_info","title":"Get detailed information about a GPU table object — gpu_object_info","text":"Returns comprehensive information tbl_gpu object including dimensions, column types, estimated memory usage, verification data resides GPU.","code":""},{"path":"https://bbtheo.github.io/cuplyr/reference/gpu_object_info.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get detailed information about a GPU table object — gpu_object_info","text":"","code":"gpu_object_info(x)"},{"path":"https://bbtheo.github.io/cuplyr/reference/gpu_object_info.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get detailed information about a GPU table object — gpu_object_info","text":"x tbl_gpu object.","code":""},{"path":"https://bbtheo.github.io/cuplyr/reference/gpu_object_info.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get detailed information about a GPU table object — gpu_object_info","text":"list following components: valid Logical: TRUE object valid tbl_gpu GPU data nrow Number rows ncol Number columns column_names Character vector column names column_types Character vector GPU column types estimated_gpu_bytes Estimated GPU memory usage bytes estimated_gpu_mb Estimated GPU memory usage megabytes r_object_bytes Size R object (small) data_on_gpu Logical: TRUE data verified GPU pointer_valid Logical: TRUE external pointer valid","code":""},{"path":[]},{"path":"https://bbtheo.github.io/cuplyr/reference/gpu_object_info.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get detailed information about a GPU table object — gpu_object_info","text":"","code":"if (has_gpu()) {   gpu_mtcars <- tbl_gpu(mtcars)   info <- gpu_object_info(gpu_mtcars)   cat(\"Rows:\", info$nrow, \"\\n\")   cat(\"GPU memory:\", round(info$estimated_gpu_mb, 2), \"MB\\n\")   cat(\"Data on GPU:\", info$data_on_gpu, \"\\n\") } #> Rows: 32  #> GPU memory: 0 MB #> Data on GPU: TRUE"},{"path":"https://bbtheo.github.io/cuplyr/reference/gpu_size_comparison.html","id":null,"dir":"Reference","previous_headings":"","what":"Compare R object size vs GPU data size — gpu_size_comparison","title":"Compare R object size vs GPU data size — gpu_size_comparison","text":"Computes ratio GPU memory usage R object size tbl_gpu object. high ratio confirms data stored GPU, R.","code":""},{"path":"https://bbtheo.github.io/cuplyr/reference/gpu_size_comparison.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compare R object size vs GPU data size — gpu_size_comparison","text":"","code":"gpu_size_comparison(x)"},{"path":"https://bbtheo.github.io/cuplyr/reference/gpu_size_comparison.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compare R object size vs GPU data size — gpu_size_comparison","text":"x tbl_gpu object.","code":""},{"path":"https://bbtheo.github.io/cuplyr/reference/gpu_size_comparison.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compare R object size vs GPU data size — gpu_size_comparison","text":"list : r_bytes Size R object bytes gpu_bytes Estimated GPU memory bytes ratio GPU size divided R size (> 1 data GPU)","code":""},{"path":[]},{"path":"https://bbtheo.github.io/cuplyr/reference/gpu_size_comparison.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compare R object size vs GPU data size — gpu_size_comparison","text":"","code":"if (has_gpu()) {   # Create a larger dataset   df <- data.frame(matrix(runif(10000), ncol = 10))   gpu_df <- tbl_gpu(df)    comparison <- gpu_size_comparison(gpu_df)   cat(\"R object:\", round(comparison$r_bytes / 1024, 1), \"KB\\n\")   cat(\"GPU data:\", round(comparison$gpu_bytes / 1024, 1), \"KB\\n\")   cat(\"Ratio:\", round(comparison$ratio, 1), \"x\\n\") } #> R object: 3.2 KB #> GPU data: 79.3 KB #> Ratio: 24.8 x"},{"path":"https://bbtheo.github.io/cuplyr/reference/group_by.tbl_gpu.html","id":null,"dir":"Reference","previous_headings":"","what":"Group a GPU table by one or more columns — group_by.tbl_gpu","title":"Group a GPU table by one or more columns — group_by.tbl_gpu","text":"Marks columns group subsequent operations like dplyr::summarise(). grouping stored metadata perform computation aggregation requested.","code":""},{"path":"https://bbtheo.github.io/cuplyr/reference/group_by.tbl_gpu.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Group a GPU table by one or more columns — group_by.tbl_gpu","text":"","code":"# S3 method for class 'tbl_gpu' group_by(.data, ..., .add = FALSE, .drop = TRUE)"},{"path":"https://bbtheo.github.io/cuplyr/reference/group_by.tbl_gpu.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Group a GPU table by one or more columns — group_by.tbl_gpu","text":".data tbl_gpu object created tbl_gpu(). ... Column names group . Can unquoted column names tidyselect expressions. .add FALSE (default), override existing groups. TRUE, add existing groups. .drop Ignored. Included compatibility dplyr generic.","code":""},{"path":"https://bbtheo.github.io/cuplyr/reference/group_by.tbl_gpu.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Group a GPU table by one or more columns — group_by.tbl_gpu","text":"grouped tbl_gpu object. object data grouping columns recorded use dplyr::summarise().","code":""},{"path":"https://bbtheo.github.io/cuplyr/reference/group_by.tbl_gpu.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Group a GPU table by one or more columns — group_by.tbl_gpu","text":"Unlike operations like dplyr::filter() dplyr::mutate(), group_by() perform GPU computation. simply records columns used grouping subsequent aggregation operations. actual groupby computation happens call dplyr::summarise() grouped table. lazy approach allows chain multiple operations executing expensive groupby operation.","code":""},{"path":[]},{"path":"https://bbtheo.github.io/cuplyr/reference/group_by.tbl_gpu.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Group a GPU table by one or more columns — group_by.tbl_gpu","text":"","code":"if (has_gpu()) {   gpu_mtcars <- tbl_gpu(mtcars)    # Group by a single column   by_cyl <- gpu_mtcars |>     group_by(cyl)    # Group by multiple columns   by_cyl_gear <- gpu_mtcars |>     group_by(cyl, gear)    # Use with summarise for aggregation   result <- gpu_mtcars |>     group_by(cyl) |>     summarise(mean_mpg = mean(mpg)) |>     collect() } #> Error in group_by(gpu_mtcars, cyl): could not find function \"group_by\""},{"path":"https://bbtheo.github.io/cuplyr/reference/group_vars.tbl_gpu.html","id":null,"dir":"Reference","previous_headings":"","what":"Get grouping variables from a GPU table — group_vars.tbl_gpu","title":"Get grouping variables from a GPU table — group_vars.tbl_gpu","text":"Returns names columns used grouping.","code":""},{"path":"https://bbtheo.github.io/cuplyr/reference/group_vars.tbl_gpu.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get grouping variables from a GPU table — group_vars.tbl_gpu","text":"","code":"# S3 method for class 'tbl_gpu' group_vars(x)"},{"path":"https://bbtheo.github.io/cuplyr/reference/group_vars.tbl_gpu.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get grouping variables from a GPU table — group_vars.tbl_gpu","text":"x tbl_gpu object.","code":""},{"path":"https://bbtheo.github.io/cuplyr/reference/group_vars.tbl_gpu.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get grouping variables from a GPU table — group_vars.tbl_gpu","text":"character vector grouping column names.","code":""},{"path":"https://bbtheo.github.io/cuplyr/reference/group_vars.tbl_gpu.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get grouping variables from a GPU table — group_vars.tbl_gpu","text":"","code":"if (has_gpu()) {   gpu_mtcars <- tbl_gpu(mtcars)    grouped <- gpu_mtcars |>     group_by(cyl, gear)    group_vars(grouped)  # c(\"cyl\", \"gear\") } #> Error in group_by(gpu_mtcars, cyl, gear): could not find function \"group_by\""},{"path":"https://bbtheo.github.io/cuplyr/reference/groups.tbl_gpu.html","id":null,"dir":"Reference","previous_headings":"","what":"Get grouping information from a GPU table — groups.tbl_gpu","title":"Get grouping information from a GPU table — groups.tbl_gpu","text":"Returns list symbols representing grouping columns.","code":""},{"path":"https://bbtheo.github.io/cuplyr/reference/groups.tbl_gpu.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get grouping information from a GPU table — groups.tbl_gpu","text":"","code":"# S3 method for class 'tbl_gpu' groups(x)"},{"path":"https://bbtheo.github.io/cuplyr/reference/groups.tbl_gpu.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get grouping information from a GPU table — groups.tbl_gpu","text":"x tbl_gpu object.","code":""},{"path":"https://bbtheo.github.io/cuplyr/reference/groups.tbl_gpu.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get grouping information from a GPU table — groups.tbl_gpu","text":"list symbols grouping columns.","code":""},{"path":"https://bbtheo.github.io/cuplyr/reference/groups.tbl_gpu.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get grouping information from a GPU table — groups.tbl_gpu","text":"","code":"if (has_gpu()) {   gpu_mtcars <- tbl_gpu(mtcars)    grouped <- gpu_mtcars |>     group_by(cyl)    groups(grouped)  # list(as.symbol(\"cyl\")) } #> Error in group_by(gpu_mtcars, cyl): could not find function \"group_by\""},{"path":"https://bbtheo.github.io/cuplyr/reference/has_gpu.html","id":null,"dir":"Reference","previous_headings":"","what":"Check GPU availability — has_gpu","title":"Check GPU availability — has_gpu","text":"Tests whether CUDA-capable GPU available accessible. function useful conditional code run GPU acceleration possible.","code":""},{"path":"https://bbtheo.github.io/cuplyr/reference/has_gpu.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check GPU availability — has_gpu","text":"","code":"has_gpu()"},{"path":"https://bbtheo.github.io/cuplyr/reference/has_gpu.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check GPU availability — has_gpu","text":"TRUE GPU available CUDA properly configured, FALSE otherwise. Returns FALSE (error) CUDA libraries found.","code":""},{"path":"https://bbtheo.github.io/cuplyr/reference/has_gpu.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Check GPU availability — has_gpu","text":"function checks: CUDA driver loaded least one CUDA device present Device accessible (exclusive mode another process)","code":""},{"path":[]},{"path":"https://bbtheo.github.io/cuplyr/reference/has_gpu.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check GPU availability — has_gpu","text":"","code":"if (has_gpu()) {   message(\"GPU acceleration available!\")   gpu_df <- tbl_gpu(mtcars) } else {   message(\"No GPU found, using CPU\") } #> GPU acceleration available!"},{"path":"https://bbtheo.github.io/cuplyr/reference/is_tbl_gpu.html","id":null,"dir":"Reference","previous_headings":"","what":"Test if an object is a GPU table — is_tbl_gpu","title":"Test if an object is a GPU table — is_tbl_gpu","text":"Checks whether object inherits tbl_gpu class.","code":""},{"path":"https://bbtheo.github.io/cuplyr/reference/is_tbl_gpu.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Test if an object is a GPU table — is_tbl_gpu","text":"","code":"is_tbl_gpu(x)"},{"path":"https://bbtheo.github.io/cuplyr/reference/is_tbl_gpu.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Test if an object is a GPU table — is_tbl_gpu","text":"x R object test.","code":""},{"path":"https://bbtheo.github.io/cuplyr/reference/is_tbl_gpu.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Test if an object is a GPU table — is_tbl_gpu","text":"TRUE x tbl_gpu object, FALSE otherwise.","code":""},{"path":"https://bbtheo.github.io/cuplyr/reference/is_tbl_gpu.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Test if an object is a GPU table — is_tbl_gpu","text":"","code":"if (has_gpu()) {   gpu_df <- tbl_gpu(mtcars)   is_tbl_gpu(gpu_df)   is_tbl_gpu(mtcars) } #> [1] FALSE"},{"path":"https://bbtheo.github.io/cuplyr/reference/mutate.tbl_gpu.html","id":null,"dir":"Reference","previous_headings":"","what":"Create or modify columns in a GPU table — mutate.tbl_gpu","title":"Create or modify columns in a GPU table — mutate.tbl_gpu","text":"Adds new columns modifies existing columns GPU table using arithmetic expressions, similar dplyr::mutate(). computations performed GPU maximum performance.","code":""},{"path":"https://bbtheo.github.io/cuplyr/reference/mutate.tbl_gpu.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create or modify columns in a GPU table — mutate.tbl_gpu","text":"","code":"# S3 method for class 'tbl_gpu' mutate(.data, ...)"},{"path":"https://bbtheo.github.io/cuplyr/reference/mutate.tbl_gpu.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create or modify columns in a GPU table — mutate.tbl_gpu","text":".data tbl_gpu object created tbl_gpu(). ... Name-value pairs expressions. name gives column name (new existing), value arithmetic expression involving existing columns /scalar values.","code":""},{"path":"https://bbtheo.github.io/cuplyr/reference/mutate.tbl_gpu.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create or modify columns in a GPU table — mutate.tbl_gpu","text":"tbl_gpu object new modified columns. column name already exists, replaced. New columns appended.","code":""},{"path":[]},{"path":"https://bbtheo.github.io/cuplyr/reference/mutate.tbl_gpu.html","id":"supported-arithmetic-operators","dir":"Reference","previous_headings":"","what":"Supported arithmetic operators","title":"Create or modify columns in a GPU table — mutate.tbl_gpu","text":"+ - addition - - subtraction * - multiplication / - division ^ - exponentiation (power)","code":""},{"path":"https://bbtheo.github.io/cuplyr/reference/mutate.tbl_gpu.html","id":"column-replacement-behavior","dir":"Reference","previous_headings":"","what":"Column replacement behavior","title":"Create or modify columns in a GPU table — mutate.tbl_gpu","text":"output column name matches existing column, existing column replaced -place (preserving column order). example, mutate(x = x + 1) modify x rather creating duplicate.","code":""},{"path":"https://bbtheo.github.io/cuplyr/reference/mutate.tbl_gpu.html","id":"current-limitations","dir":"Reference","previous_headings":"","what":"Current limitations","title":"Create or modify columns in a GPU table — mutate.tbl_gpu","text":"binary operations supported (col op value col op col) Complex expressions like (x + y) * z yet supported Functions like sqrt(), log(), abs() yet implemented Result type always FLOAT64 (double precision)","code":""},{"path":"https://bbtheo.github.io/cuplyr/reference/mutate.tbl_gpu.html","id":"performance","dir":"Reference","previous_headings":"","what":"Performance","title":"Create or modify columns in a GPU table — mutate.tbl_gpu","text":"GPU arithmetic operations highly vectorized can process billions elements per second. Memory bandwidth typically limiting factor, compute.","code":""},{"path":[]},{"path":"https://bbtheo.github.io/cuplyr/reference/mutate.tbl_gpu.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create or modify columns in a GPU table — mutate.tbl_gpu","text":"","code":"if (has_gpu()) {   gpu_mtcars <- tbl_gpu(mtcars)    # Add a new column   result <- gpu_mtcars |>     mutate(kpl = mpg * 0.425) |>     collect()    # Modify an existing column   adjusted <- gpu_mtcars |>     mutate(mpg = mpg + 5) |>     collect()    # Combine two columns   gpu_cars <- tbl_gpu(cars)   result <- gpu_cars |>     mutate(ratio = dist / speed) |>     collect()    # Chain multiple mutations   result <- gpu_mtcars |>     mutate(power_weight = hp / wt) |>     mutate(efficiency = mpg * power_weight) |>     collect() } #> Error in collect(mutate(gpu_mtcars, kpl = mpg * 0.425)): could not find function \"collect\""},{"path":"https://bbtheo.github.io/cuplyr/reference/names-set-.tbl_gpu.html","id":null,"dir":"Reference","previous_headings":"","what":"Set column names of a GPU table — names<-.tbl_gpu","title":"Set column names of a GPU table — names<-.tbl_gpu","text":"Set column names GPU table","code":""},{"path":"https://bbtheo.github.io/cuplyr/reference/names-set-.tbl_gpu.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set column names of a GPU table — names<-.tbl_gpu","text":"","code":"# S3 method for class 'tbl_gpu' names(x) <- value"},{"path":"https://bbtheo.github.io/cuplyr/reference/names-set-.tbl_gpu.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set column names of a GPU table — names<-.tbl_gpu","text":"x tbl_gpu object. value character vector new column names.","code":""},{"path":"https://bbtheo.github.io/cuplyr/reference/names-set-.tbl_gpu.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Set column names of a GPU table — names<-.tbl_gpu","text":"modified tbl_gpu object.","code":""},{"path":"https://bbtheo.github.io/cuplyr/reference/names.tbl_gpu.html","id":null,"dir":"Reference","previous_headings":"","what":"Get column names of a GPU table — names.tbl_gpu","title":"Get column names of a GPU table — names.tbl_gpu","text":"Get column names GPU table","code":""},{"path":"https://bbtheo.github.io/cuplyr/reference/names.tbl_gpu.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get column names of a GPU table — names.tbl_gpu","text":"","code":"# S3 method for class 'tbl_gpu' names(x)"},{"path":"https://bbtheo.github.io/cuplyr/reference/names.tbl_gpu.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get column names of a GPU table — names.tbl_gpu","text":"x tbl_gpu object.","code":""},{"path":"https://bbtheo.github.io/cuplyr/reference/names.tbl_gpu.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get column names of a GPU table — names.tbl_gpu","text":"character vector column names.","code":""},{"path":"https://bbtheo.github.io/cuplyr/reference/select.tbl_gpu.html","id":null,"dir":"Reference","previous_headings":"","what":"Select columns from a GPU table — select.tbl_gpu","title":"Select columns from a GPU table — select.tbl_gpu","text":"Keeps specified columns GPU table, similar dplyr::select(). Supports tidyselect syntax flexible column selection.","code":""},{"path":"https://bbtheo.github.io/cuplyr/reference/select.tbl_gpu.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Select columns from a GPU table — select.tbl_gpu","text":"","code":"# S3 method for class 'tbl_gpu' select(.data, ...)"},{"path":"https://bbtheo.github.io/cuplyr/reference/select.tbl_gpu.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Select columns from a GPU table — select.tbl_gpu","text":".data tbl_gpu object created tbl_gpu(). ... Column names tidyselect expressions specifying columns keep. Supports: Column names: select(x, y, z) Negative selection: select(-x) (yet supported) Range: select(x:z) (yet supported) Helpers: starts_with(), ends_with(), contains(), etc.","code":""},{"path":"https://bbtheo.github.io/cuplyr/reference/select.tbl_gpu.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Select columns from a GPU table — select.tbl_gpu","text":"tbl_gpu object containing selected columns. Column order matches order specified selection.","code":""},{"path":"https://bbtheo.github.io/cuplyr/reference/select.tbl_gpu.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Select columns from a GPU table — select.tbl_gpu","text":"Column selection creates new GPU table selected columns. original data remains GPU memory garbage collected.","code":""},{"path":"https://bbtheo.github.io/cuplyr/reference/select.tbl_gpu.html","id":"performance","dir":"Reference","previous_headings":"","what":"Performance","title":"Select columns from a GPU table — select.tbl_gpu","text":"Select operations involve copying column data new table structure. wide tables, selecting fewer columns can significantly reduce memory usage improve performance subsequent operations.","code":""},{"path":[]},{"path":"https://bbtheo.github.io/cuplyr/reference/select.tbl_gpu.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Select columns from a GPU table — select.tbl_gpu","text":"","code":"if (has_gpu()) {   gpu_mtcars <- tbl_gpu(mtcars)    # Select specific columns   result <- gpu_mtcars |>     select(mpg, cyl, hp) |>     collect()    # Select with tidyselect helpers   result <- gpu_mtcars |>     select(starts_with(\"d\")) |>     collect()    # Reorder columns   result <- gpu_mtcars |>     select(hp, mpg, wt) |>     collect() } #> Error in collect(select(gpu_mtcars, mpg, cyl, hp)): could not find function \"collect\""},{"path":"https://bbtheo.github.io/cuplyr/reference/show_gpu.html","id":null,"dir":"Reference","previous_headings":"","what":"Display GPU information — show_gpu","title":"Display GPU information — show_gpu","text":"Prints formatted information available GPU console. Useful verifying GPU setup checking available resources.","code":""},{"path":"https://bbtheo.github.io/cuplyr/reference/show_gpu.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Display GPU information — show_gpu","text":"","code":"show_gpu()"},{"path":"https://bbtheo.github.io/cuplyr/reference/show_gpu.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Display GPU information — show_gpu","text":"Invisibly returns GPU info list (gpu_details()).","code":""},{"path":"https://bbtheo.github.io/cuplyr/reference/show_gpu.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Display GPU information — show_gpu","text":"Output includes: Device name compute capability Total, free, used memory Number streaming multiprocessors","code":""},{"path":[]},{"path":"https://bbtheo.github.io/cuplyr/reference/show_gpu.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Display GPU information — show_gpu","text":"","code":"show_gpu() #> GPU Information #> ----------------------------------------  #> Device:       NVIDIA GeForce RTX 5070  #> Compute:      12.0  #> Memory:       12.3 GB total #>               11.2 GB free #>               1.2 GB used #> SMs:          1"},{"path":"https://bbtheo.github.io/cuplyr/reference/summarise.tbl_gpu.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarise groups in a GPU table — summarise.tbl_gpu","title":"Summarise groups in a GPU table — summarise.tbl_gpu","text":"Computes aggregations groups defined dplyr::group_by(). Operations performed entirely GPU maximum performance.","code":""},{"path":"https://bbtheo.github.io/cuplyr/reference/summarise.tbl_gpu.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarise groups in a GPU table — summarise.tbl_gpu","text":"","code":"# S3 method for class 'tbl_gpu' summarise(.data, ..., .groups = \"drop\")  # S3 method for class 'tbl_gpu' summarize(.data, ..., .groups = \"drop\")"},{"path":"https://bbtheo.github.io/cuplyr/reference/summarise.tbl_gpu.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarise groups in a GPU table — summarise.tbl_gpu","text":".data grouped tbl_gpu object created dplyr::group_by(). ... Name-value pairs summary functions. name name variable result. value must single aggregation expression form fun(column). .groups Controls grouping structure result. Currently \"drop\" supported (default).","code":""},{"path":"https://bbtheo.github.io/cuplyr/reference/summarise.tbl_gpu.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summarise groups in a GPU table — summarise.tbl_gpu","text":"tbl_gpu object one row per group containing grouping columns computed aggregations.","code":""},{"path":[]},{"path":"https://bbtheo.github.io/cuplyr/reference/summarise.tbl_gpu.html","id":"supported-aggregation-functions","dir":"Reference","previous_headings":"","what":"Supported aggregation functions","title":"Summarise groups in a GPU table — summarise.tbl_gpu","text":"sum(x) - Sum values mean(x) - Arithmetic mean min(x) - Minimum value max(x) - Maximum value n() - Count rows group sd(x) - Standard deviation var(x) - Variance","code":""},{"path":"https://bbtheo.github.io/cuplyr/reference/summarise.tbl_gpu.html","id":"na-handling","dir":"Reference","previous_headings":"","what":"NA handling","title":"Summarise groups in a GPU table — summarise.tbl_gpu","text":"default, NA values excluded aggregations. matches default behavior R's base aggregation functions.","code":""},{"path":"https://bbtheo.github.io/cuplyr/reference/summarise.tbl_gpu.html","id":"ungrouped-summarise","dir":"Reference","previous_headings":"","what":"Ungrouped summarise","title":"Summarise groups in a GPU table — summarise.tbl_gpu","text":".data grouped, summarise compute aggregations rows, returning single-row table.","code":""},{"path":[]},{"path":"https://bbtheo.github.io/cuplyr/reference/summarise.tbl_gpu.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summarise groups in a GPU table — summarise.tbl_gpu","text":"","code":"if (has_gpu()) {   gpu_mtcars <- tbl_gpu(mtcars)    # Simple aggregation over all rows   total <- gpu_mtcars |>     summarise(avg_mpg = mean(mpg)) |>     collect()    # Grouped aggregation   by_cyl <- gpu_mtcars |>     group_by(cyl) |>     summarise(       avg_mpg = mean(mpg),       max_hp = max(hp),       count = n()     ) |>     collect()    # Multiple grouping columns   by_cyl_gear <- gpu_mtcars |>     group_by(cyl, gear) |>     summarise(       mean_mpg = mean(mpg),       min_wt = min(wt)     ) |>     collect() } #> Error in collect(summarise(gpu_mtcars, avg_mpg = mean(mpg))): could not find function \"collect\""},{"path":"https://bbtheo.github.io/cuplyr/reference/tbl_gpu.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a GPU-backed data frame — tbl_gpu","title":"Create a GPU-backed data frame — tbl_gpu","text":"Transfers R data frame GPU memory using NVIDIA's libcudf library, enabling high-performance data manipulation operations. resulting tbl_gpu object can used dplyr verbs like filter(), mutate(), select(), collected back R collect().","code":""},{"path":"https://bbtheo.github.io/cuplyr/reference/tbl_gpu.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a GPU-backed data frame — tbl_gpu","text":"","code":"tbl_gpu(data, ...)  # S3 method for class 'data.frame' tbl_gpu(data, ...)  # S3 method for class 'tbl_gpu' tbl_gpu(data, ...)"},{"path":"https://bbtheo.github.io/cuplyr/reference/tbl_gpu.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a GPU-backed data frame — tbl_gpu","text":"data data frame tibble transfer GPU memory. Supported column types include: numeric (double), integer, character, logical. ... Additional arguments passed methods (currently unused).","code":""},{"path":"https://bbtheo.github.io/cuplyr/reference/tbl_gpu.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a GPU-backed data frame — tbl_gpu","text":"tbl_gpu object containing: ptr - External pointer GPU table schema - List column names types lazy_ops - Pending operations (future lazy evaluation) groups - Grouping variables (future group_by support)","code":""},{"path":"https://bbtheo.github.io/cuplyr/reference/tbl_gpu.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create a GPU-backed data frame — tbl_gpu","text":"data immediately copied GPU memory tbl_gpu() called. GPU memory automatically freed R object garbage collected. Column type mappings R GPU: numeric -> FLOAT64 integer -> INT32 character -> STRING logical -> BOOL8 (stored INT32) Date -> TIMESTAMP_DAYS POSIXct -> TIMESTAMP_MICROSECONDS","code":""},{"path":[]},{"path":"https://bbtheo.github.io/cuplyr/reference/tbl_gpu.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a GPU-backed data frame — tbl_gpu","text":"","code":"if (has_gpu()) {   # Transfer mtcars to GPU   gpu_mtcars <- tbl_gpu(mtcars)   print(gpu_mtcars)    # Chain operations   result <- gpu_mtcars |>     filter(mpg > 20) |>     mutate(kpl = mpg * 0.425) |>     collect() } #> Rows: 32 #> Columns: 11 #> $ mpg  <dbl> 21, 21, 22.8, 21.4, 18.7, 18.1, 14.3, 24.4, 22.8, 19.2 #> $ cyl  <dbl> 6, 6, 4, 6, 8, 6, 8, 4, 4, 6 #> $ disp <dbl> 160, 160, 108, 258, 360, 225, 360, 146.7, 140.8, 167.6 #> $ hp   <dbl> 110, 110, 93, 110, 175, 105, 245, 62, 95, 123 #> $ drat <dbl> 3.9, 3.9, 3.85, 3.08, 3.15, 2.76, 3.21, 3.69, 3.92, 3.92 #> $ wt   <dbl> 2.62, 2.875, 2.32, 3.215, 3.44, 3.46, 3.57, 3.19, 3.15, 3.44 #> $ qsec <dbl> 16.46, 17.02, 18.61, 19.44, 17.02, 20.22, 15.84, 20, 22.9, 18.3 #> $ vs   <dbl> 0, 0, 1, 1, 0, 1, 0, 1, 1, 1 #> $ am   <dbl> 1, 1, 1, 0, 0, 0, 0, 0, 0, 0 #> $ gear <dbl> 4, 4, 4, 3, 3, 3, 3, 4, 4, 4 #> $ carb <dbl> 4, 4, 1, 1, 2, 1, 4, 2, 2, 4 #> Error in collect(mutate(filter(gpu_mtcars, mpg > 20), kpl = mpg * 0.425)): could not find function \"collect\""},{"path":"https://bbtheo.github.io/cuplyr/reference/ungroup.tbl_gpu.html","id":null,"dir":"Reference","previous_headings":"","what":"Remove grouping from a GPU table — ungroup.tbl_gpu","title":"Remove grouping from a GPU table — ungroup.tbl_gpu","text":"Removes grouping information grouped tbl_gpu object.","code":""},{"path":"https://bbtheo.github.io/cuplyr/reference/ungroup.tbl_gpu.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Remove grouping from a GPU table — ungroup.tbl_gpu","text":"","code":"# S3 method for class 'tbl_gpu' ungroup(x, ...)"},{"path":"https://bbtheo.github.io/cuplyr/reference/ungroup.tbl_gpu.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Remove grouping from a GPU table — ungroup.tbl_gpu","text":"x tbl_gpu object. ... Ignored. Included compatibility dplyr generic.","code":""},{"path":"https://bbtheo.github.io/cuplyr/reference/ungroup.tbl_gpu.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Remove grouping from a GPU table — ungroup.tbl_gpu","text":"ungrouped tbl_gpu object.","code":""},{"path":"https://bbtheo.github.io/cuplyr/reference/ungroup.tbl_gpu.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Remove grouping from a GPU table — ungroup.tbl_gpu","text":"","code":"if (has_gpu()) {   gpu_mtcars <- tbl_gpu(mtcars)    grouped <- gpu_mtcars |>     group_by(cyl)    # Remove grouping   ungrouped <- grouped |>     ungroup()    # Verify groups are removed   length(group_vars(ungrouped))  # 0 } #> Error in group_by(gpu_mtcars, cyl): could not find function \"group_by\""},{"path":"https://bbtheo.github.io/cuplyr/reference/verify_gpu_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Verify that data resides on GPU — verify_gpu_data","title":"Verify that data resides on GPU — verify_gpu_data","text":"Performs checks confirm tbl_gpu object data stored GPU, R memory. useful debugging ensuring GPU operations working correctly.","code":""},{"path":"https://bbtheo.github.io/cuplyr/reference/verify_gpu_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Verify that data resides on GPU — verify_gpu_data","text":"","code":"verify_gpu_data(x)"},{"path":"https://bbtheo.github.io/cuplyr/reference/verify_gpu_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Verify that data resides on GPU — verify_gpu_data","text":"x tbl_gpu object.","code":""},{"path":"https://bbtheo.github.io/cuplyr/reference/verify_gpu_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Verify that data resides on GPU — verify_gpu_data","text":"TRUE checks pass data verified GPU, FALSE otherwise.","code":""},{"path":"https://bbtheo.github.io/cuplyr/reference/verify_gpu_data.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Verify that data resides on GPU — verify_gpu_data","text":"function performs multiple verification steps: Object tbl_gpu class Object valid external pointer GPU operations (dim, types) work pointer R object small (data copy R memory)","code":""},{"path":[]},{"path":"https://bbtheo.github.io/cuplyr/reference/verify_gpu_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Verify that data resides on GPU — verify_gpu_data","text":"","code":"if (has_gpu()) {   gpu_mtcars <- tbl_gpu(mtcars)    # Should return TRUE   verify_gpu_data(gpu_mtcars)    # Regular data frames return FALSE   verify_gpu_data(mtcars) } #> [1] FALSE"},{"path":[]},{"path":"https://bbtheo.github.io/cuplyr/news/index.html","id":"lazy-evaluation-0-1-0","dir":"Changelog","previous_headings":"","what":"Lazy evaluation","title":"cuplyr 0.1.0","text":"tbl_gpu() gains lazy argument enable deferred execution. Operations build AST (Abstract Syntax Tree) optimized executed collect() compute() called. Set globally options(cuplyr.exec_mode = \"lazy\") CUPLYR_EXEC_MODE=lazy environment variable. Added AST optimizer applies multiple optimization passes execution: Projection pruning: push column selection close data sources Mutate fusion: combine consecutive mutate operations Dead column pruning: remove unused intermediate columns Filter pushdown: move filters earlier pipeline, including across joins Filter reordering: execute cheaper filters first Filter fusion: combine multiple filters single GPU kernel compute() executes pending lazy operations keeps result GPU. collapse() inserts optimization barrier without executing. as_lazy() as_eager() switch execution modes mid-pipeline. is_lazy() has_pending_ops() check current execution state. show_query() displays pending operation tree debugging.","code":""},{"path":"https://bbtheo.github.io/cuplyr/news/index.html","id":"join-operations-0-1-0","dir":"Changelog","previous_headings":"","what":"Join operations","title":"cuplyr 0.1.0","text":"Added inner_join(), left_join(), right_join(), full_join() combining GPU tables (#2). Joins support automatic key detection (natural join), named vectors different key names, suffix column name conflicts, keep retaining join keys, copy auto-transfer data frames GPU.","code":""},{"path":"https://bbtheo.github.io/cuplyr/news/index.html","id":"bind-operations-0-1-0","dir":"Changelog","previous_headings":"","what":"Bind operations","title":"cuplyr 0.1.0","text":"Added bind_rows() vertically combining GPU tables automatic schema unification type promotion. Added bind_cols() horizontally combining GPU tables .name_repair duplicate column handling. bind functions automatically materialize lazy tables binding.","code":""},{"path":"https://bbtheo.github.io/cuplyr/news/index.html","id":"cuplyr-001","dir":"Changelog","previous_headings":"","what":"cuplyr 0.0.1","title":"cuplyr 0.0.1","text":"Initial release cuplyr, GPU-accelerated dplyr backend using NVIDIA’s libcudf library.","code":""},{"path":"https://bbtheo.github.io/cuplyr/news/index.html","id":"core-functionality-0-0-1","dir":"Changelog","previous_headings":"","what":"Core functionality","title":"cuplyr 0.0.1","text":"tbl_gpu() transfers R data frames GPU memory, returning tbl_gpu object works dplyr verbs. collect() transfers GPU data back R tibble. as_tbl_gpu() coerces data frames GPU tables. is_tbl_gpu() tests object GPU table.","code":""},{"path":"https://bbtheo.github.io/cuplyr/news/index.html","id":"dplyr-verbs-0-0-1","dir":"Changelog","previous_headings":"","what":"dplyr verbs","title":"cuplyr 0.0.1","text":"filter() supports scalar comparisons (x > 5, x == \"\") column--column comparisons (x > y). Supports boolean vectors filter masks. select() supports column selection name, position, tidyselect helpers. mutate() supports arithmetic operations (+, -, *, /, ^) scalars columns. Supports left-associative chains (e.g., + b + c). arrange() sorts one columns desc() support descending order. Supports .by_group = TRUE grouped tables. group_by() sets grouping metadata subsequent aggregation. ungroup() removes grouping. summarise() computes grouped aggregations support sum(), mean(), min(), max(), n(), sd(), var(). Supports expressions inside aggregation functions (e.g., sum(x > 0)).","code":""},{"path":"https://bbtheo.github.io/cuplyr/news/index.html","id":"type-support-0-0-1","dir":"Changelog","previous_headings":"","what":"Type support","title":"cuplyr 0.0.1","text":"Supported R types: numeric (FLOAT64), integer (INT32), character (STRING), logical (BOOL8), Date (TIMESTAMP_DAYS), POSIXct (TIMESTAMP_MICROSECONDS). factor columns converted INT32 codes. integer64 columns converted FLOAT64 warning precision loss values exceeding 2^53.","code":""},{"path":"https://bbtheo.github.io/cuplyr/news/index.html","id":"gpu-memory-utilities-0-0-1","dir":"Changelog","previous_headings":"","what":"GPU memory utilities","title":"cuplyr 0.0.1","text":"gpu_memory_usage() estimates GPU memory footprint tbl_gpu object. gpu_memory_state() returns current GPU memory usage (total, free, used). gpu_gc() forces garbage collection free GPU memory unreferenced tables. gpu_object_info() returns detailed information GPU table. verify_gpu_data() confirms data resides GPU, R memory. gpu_size_comparison() compares R object size vs GPU data size.","code":""},{"path":"https://bbtheo.github.io/cuplyr/news/index.html","id":"gpu-information-0-0-1","dir":"Changelog","previous_headings":"","what":"GPU information","title":"cuplyr 0.0.1","text":"has_gpu() checks compatible GPU available. gpu_details() returns GPU device information (name, compute capability, memory).","code":""}]
